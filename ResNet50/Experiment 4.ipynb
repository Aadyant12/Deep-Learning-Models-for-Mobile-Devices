{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment 4.ipynb","provenance":[{"file_id":"1qQ_0RaSDUXo_uEbw1vvx3nPGsLtg7iBu","timestamp":1623870104154},{"file_id":"1cGXeoDEMw72Qwq_JddSrkccvR6jR01V_","timestamp":1622991507291}],"collapsed_sections":[],"mount_file_id":"1APv8g4nIE2MKC0M6XFGqwZ6uscwbhGvP","authorship_tag":"ABX9TyMALFBfuAeUYNkau8VszJhW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EhRVl-j9XISJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626694373976,"user_tz":-330,"elapsed":15737,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"93a394b1-f4c0-45fa-dee9-c8b0881611dc"},"source":["from tensorflow.keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSpWlE_jfAFQ","executionInfo":{"status":"ok","timestamp":1626694378167,"user_tz":-330,"elapsed":4194,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"4c415b4d-8c1c-4613-9444-8c73244af42a"},"source":["# example of loading the MobileNet model\n","from keras.applications.resnet50 import ResNet50\n","model = ResNet50(include_top=False, weights= None, input_shape=(32, 32, 3))\n","# summarize the model\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"resnet50\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n","==================================================================================================\n","Total params: 23,587,712\n","Trainable params: 23,534,592\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWPVP0KFNY_P","executionInfo":{"status":"ok","timestamp":1626694378167,"user_tz":-330,"elapsed":20,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"31148369-4b5b-4a2e-a6cf-fa264ab06d35"},"source":["len(model.layers)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["175"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"6enOD5B6OAiZ"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYrda208Nh56"},"source":["exits = [6, 38, 60, 80, 112, 142]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p9tH_ROcvkFj"},"source":["## **ADDITION OF EXIT NETWORK**"]},{"cell_type":"code","metadata":{"id":"5AzuwnTDSOSf"},"source":["exit_layer1 = model.layers[6]\n","exit_layer2 = model.layers[38]\n","exit_layer3 = model.layers[60]\n","exit_layer4 = model.layers[80]\n","exit_layer5 = model.layers[112]\n","exit_layer6 = model.layers[142]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vII6zf4pNIK"},"source":["exit_models = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gz-OYNBTdRO","executionInfo":{"status":"ok","timestamp":1626694378169,"user_tz":-330,"elapsed":10,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"db109a3f-f165-4aae-a610-fe01b6368ae2"},"source":["conv1 = Conv2D(128, (3,3), padding='same', activation='relu')(exit_layer1.output)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((3,3), strides=(3,3))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model1 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model1)\n","exit_model1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1_pad (ZeroPadding2D)    (None, 38, 38, 3)         0         \n","_________________________________________________________________\n","conv1_conv (Conv2D)          (None, 16, 16, 64)        9472      \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv1_relu (Activation)      (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","pool1_pad (ZeroPadding2D)    (None, 18, 18, 64)        0         \n","_________________________________________________________________\n","pool1_pool (MaxPooling2D)    (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 8, 8, 128)         73856     \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               65664     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 150,538\n","Trainable params: 150,410\n","Non-trainable params: 128\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5OL3CceSEEL","executionInfo":{"status":"ok","timestamp":1626694378984,"user_tz":-330,"elapsed":823,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"020f9ba0-940a-4ec7-ba97-b80d98a9973f"},"source":["pool1 = MaxPooling2D((3,3), strides=(3,3))(exit_layer2.output)\n","conv1 = Conv2D(512, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model2 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model2)\n","exit_model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 2, 2, 256)    0           conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 2, 2, 512)    1180160     max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 512)          0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 128)          65664       flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 10)           1290        dense_2[0][0]                    \n","==================================================================================================\n","Total params: 1,476,874\n","Trainable params: 1,473,930\n","Non-trainable params: 2,944\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jW--RdXSSfj","executionInfo":{"status":"ok","timestamp":1626694378985,"user_tz":-330,"elapsed":52,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"651c4ee0-d7cd-4e36-c3d1-25cd3061a695"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer3.output)\n","conv1 = Conv2D(1024, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(512, activation='relu')(flat1)\n","class2 = Dense(128, activation='relu')(class1)\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","exit_model3 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model3)\n","exit_model3.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 512)    0           conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 2, 2, 1024)   4719616     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 1024)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 1024)         0           max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 128)          65664       dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 10)           1290        dense_5[0][0]                    \n","==================================================================================================\n","Total params: 6,206,730\n","Trainable params: 6,199,690\n","Non-trainable params: 7,040\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XwmZ_Ntorkl","executionInfo":{"status":"ok","timestamp":1626694378985,"user_tz":-330,"elapsed":43,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"702b66d0-be8b-4169-b51e-a16da6cd605b"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer4.output)\n","conv1 = Conv2D(1024, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(512, activation='relu')(flat1)\n","class2 = Dense(128, activation='relu')(class1)\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","exit_model4 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model4)\n","exit_model4.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 512)    0           conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 2, 2, 1024)   4719616     max_pooling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 1024)   0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 1024)         0           max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 512)          524800      flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 128)          65664       dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 10)           1290        dense_8[0][0]                    \n","==================================================================================================\n","Total params: 6,771,466\n","Trainable params: 6,761,354\n","Non-trainable params: 10,112\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmhVkLSSlVl9","executionInfo":{"status":"ok","timestamp":1626694378986,"user_tz":-330,"elapsed":37,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"22f8b403-f62b-4a4d-e6d0-dcf3e1a62cb7"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer5.output)\n","#conv1 = Conv2D(1024, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","#pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool1)\n","class1 = Dense(512, activation='relu')(flat1)\n","class2 = Dense(128, activation='relu')(class1)\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","exit_model5 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model5)\n","exit_model5.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 1024)   0           conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 1024)         0           max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 512)          524800      flatten_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 128)          65664       dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 10)           1290        dense_11[0][0]                   \n","==================================================================================================\n","Total params: 5,815,562\n","Trainable params: 5,794,186\n","Non-trainable params: 21,376\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Po-stW4XlVbE","executionInfo":{"status":"ok","timestamp":1626694378986,"user_tz":-330,"elapsed":27,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"1f6df7b2-9c96-47fa-bb75-b5d83558d1e6"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer6.output)\n","#conv1 = Conv2D(1024, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","#pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool1)\n","class1 = Dense(512, activation='relu')(flat1)\n","class2 = Dense(128, activation='relu')(class1)\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","exit_model6 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model6)\n","exit_model6.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 1024)   0           conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","flatten_5 (Flatten)             (None, 1024)         0           max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","dense_13 (Dense)                (None, 512)          524800      flatten_5[0][0]                  \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 128)          65664       dense_13[0][0]                   \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 10)           1290        dense_14[0][0]                   \n","==================================================================================================\n","Total params: 9,180,938\n","Trainable params: 9,150,346\n","Non-trainable params: 30,592\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDdgNEwKpf_8","executionInfo":{"status":"ok","timestamp":1626694378986,"user_tz":-330,"elapsed":16,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"a28d5835-046f-4696-ee16-1ac5acd14c82"},"source":["exit_models"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tensorflow.python.keras.engine.functional.Functional at 0x7fe9b5592a10>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7fe9b55ad110>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7fe9b5547550>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7fe9b55b4350>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7fe9b554a310>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7fe9b54c3090>]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"qs5OkuHGkCcX"},"source":["for model in exit_models:\n","  model.compile(\n","          optimizer='adam',\n","          loss='sparse_categorical_crossentropy',\n","          metrics=['accuracy']\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zli8ksJdikcO"},"source":["import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5GvpA1ElIqe","executionInfo":{"status":"ok","timestamp":1626700086826,"user_tz":-330,"elapsed":5613825,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"fb559432-7351-40f9-92a7-50af57e91df6"},"source":["accuracies_time = []\n","\n","for i in range(len(exits)):\n","  model = exit_models[i]\n","  model.load_weights(f\"/ResNet50/Main_till_exit{i+1}_weights.h5\", by_name=True)\n","  for layer in range(exits[i] + 1):\n","    model.layers[layer].trainable = False\n","  accuracies_time.append('-----------------------------------------')\n","  start = time.time()\n","  history = model.fit(\n","      x=x_train,\n","      y=y_train,\n","      epochs=100,\n","      verbose=1,\n","      validation_data=(x_test, y_test),\n","      batch_size=128\n","  )\n","  end = time.time()\n","  accuracies_time.append(((history.history.get('val_accuracy')[19]), (end-start)*2/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[29]), (end-start)*3/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[39]), (end-start)*4/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[49]), (end-start)*5/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[59]), (end-start)*6/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[69]), (end-start)*7/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[79]), (end-start)*8/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[89]), (end-start)*9/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[99]), (end-start)*10/10))\n","  print(f\"Accuracy of model {i+1}: \", history.history.get('val_accuracy')[len(history.history.get('val_accuracy')) - 1])\n","  i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.8820 - accuracy: 0.6926 - val_loss: 1.1544 - val_accuracy: 0.6152\n","Epoch 2/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.8005 - accuracy: 0.7222 - val_loss: 0.9388 - val_accuracy: 0.6773\n","Epoch 3/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.7533 - accuracy: 0.7368 - val_loss: 1.0143 - val_accuracy: 0.6647\n","Epoch 4/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.7081 - accuracy: 0.7519 - val_loss: 0.9232 - val_accuracy: 0.6824\n","Epoch 5/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.6772 - accuracy: 0.7617 - val_loss: 0.9697 - val_accuracy: 0.6673\n","Epoch 6/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.6460 - accuracy: 0.7731 - val_loss: 0.9356 - val_accuracy: 0.6822\n","Epoch 7/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.6149 - accuracy: 0.7818 - val_loss: 1.1329 - val_accuracy: 0.6445\n","Epoch 8/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.5848 - accuracy: 0.7930 - val_loss: 0.9001 - val_accuracy: 0.7038\n","Epoch 9/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.5578 - accuracy: 0.8046 - val_loss: 0.9768 - val_accuracy: 0.6783\n","Epoch 10/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.5335 - accuracy: 0.8131 - val_loss: 0.9990 - val_accuracy: 0.6859\n","Epoch 11/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.5157 - accuracy: 0.8173 - val_loss: 1.0215 - val_accuracy: 0.6722\n","Epoch 12/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4815 - accuracy: 0.8300 - val_loss: 0.9381 - val_accuracy: 0.7105\n","Epoch 13/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4600 - accuracy: 0.8370 - val_loss: 0.9221 - val_accuracy: 0.7190\n","Epoch 14/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4394 - accuracy: 0.8431 - val_loss: 1.1089 - val_accuracy: 0.6693\n","Epoch 15/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4254 - accuracy: 0.8499 - val_loss: 0.9968 - val_accuracy: 0.7064\n","Epoch 16/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4004 - accuracy: 0.8569 - val_loss: 1.1087 - val_accuracy: 0.6834\n","Epoch 17/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3812 - accuracy: 0.8647 - val_loss: 1.0094 - val_accuracy: 0.7046\n","Epoch 18/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.3548 - accuracy: 0.8764 - val_loss: 0.9919 - val_accuracy: 0.7228\n","Epoch 19/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.3378 - accuracy: 0.8797 - val_loss: 1.0628 - val_accuracy: 0.7034\n","Epoch 20/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3290 - accuracy: 0.8830 - val_loss: 1.0801 - val_accuracy: 0.7072\n","Epoch 21/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2992 - accuracy: 0.8925 - val_loss: 1.0778 - val_accuracy: 0.7112\n","Epoch 22/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2946 - accuracy: 0.8941 - val_loss: 1.3716 - val_accuracy: 0.6700\n","Epoch 23/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2749 - accuracy: 0.9014 - val_loss: 1.1177 - val_accuracy: 0.7052\n","Epoch 24/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2722 - accuracy: 0.9026 - val_loss: 1.2909 - val_accuracy: 0.6749\n","Epoch 25/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2536 - accuracy: 0.9089 - val_loss: 1.2270 - val_accuracy: 0.7000\n","Epoch 26/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2308 - accuracy: 0.9172 - val_loss: 1.3486 - val_accuracy: 0.6844\n","Epoch 27/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2242 - accuracy: 0.9195 - val_loss: 1.2439 - val_accuracy: 0.7058\n","Epoch 28/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2201 - accuracy: 0.9206 - val_loss: 1.2817 - val_accuracy: 0.7087\n","Epoch 29/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2049 - accuracy: 0.9268 - val_loss: 1.2635 - val_accuracy: 0.7236\n","Epoch 30/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2037 - accuracy: 0.9260 - val_loss: 1.4508 - val_accuracy: 0.6976\n","Epoch 31/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1815 - accuracy: 0.9351 - val_loss: 1.5418 - val_accuracy: 0.6894\n","Epoch 32/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1805 - accuracy: 0.9343 - val_loss: 1.5709 - val_accuracy: 0.6877\n","Epoch 33/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1704 - accuracy: 0.9386 - val_loss: 1.6432 - val_accuracy: 0.6879\n","Epoch 34/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1572 - accuracy: 0.9435 - val_loss: 1.5200 - val_accuracy: 0.6986\n","Epoch 35/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1624 - accuracy: 0.9416 - val_loss: 1.5739 - val_accuracy: 0.6923\n","Epoch 36/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1488 - accuracy: 0.9459 - val_loss: 1.5817 - val_accuracy: 0.6991\n","Epoch 37/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1493 - accuracy: 0.9461 - val_loss: 1.6640 - val_accuracy: 0.6863\n","Epoch 38/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1382 - accuracy: 0.9513 - val_loss: 1.7662 - val_accuracy: 0.6820\n","Epoch 39/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1318 - accuracy: 0.9520 - val_loss: 1.7031 - val_accuracy: 0.6953\n","Epoch 40/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1367 - accuracy: 0.9498 - val_loss: 1.6293 - val_accuracy: 0.7132\n","Epoch 41/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1276 - accuracy: 0.9544 - val_loss: 1.7422 - val_accuracy: 0.7080\n","Epoch 42/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1095 - accuracy: 0.9617 - val_loss: 1.7934 - val_accuracy: 0.6967\n","Epoch 43/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1336 - accuracy: 0.9502 - val_loss: 1.9213 - val_accuracy: 0.6808\n","Epoch 44/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1201 - accuracy: 0.9557 - val_loss: 1.7017 - val_accuracy: 0.7029\n","Epoch 45/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1080 - accuracy: 0.9608 - val_loss: 1.9906 - val_accuracy: 0.6977\n","Epoch 46/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1162 - accuracy: 0.9570 - val_loss: 1.9394 - val_accuracy: 0.6876\n","Epoch 47/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1017 - accuracy: 0.9631 - val_loss: 1.9358 - val_accuracy: 0.6962\n","Epoch 48/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0938 - accuracy: 0.9666 - val_loss: 1.8619 - val_accuracy: 0.6971\n","Epoch 49/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0989 - accuracy: 0.9651 - val_loss: 1.9739 - val_accuracy: 0.7004\n","Epoch 50/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0912 - accuracy: 0.9681 - val_loss: 2.0805 - val_accuracy: 0.6901\n","Epoch 51/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0894 - accuracy: 0.9680 - val_loss: 2.0862 - val_accuracy: 0.7014\n","Epoch 52/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0984 - accuracy: 0.9641 - val_loss: 2.0918 - val_accuracy: 0.6945\n","Epoch 53/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1029 - accuracy: 0.9635 - val_loss: 2.0809 - val_accuracy: 0.6830\n","Epoch 54/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0836 - accuracy: 0.9704 - val_loss: 2.1270 - val_accuracy: 0.7037\n","Epoch 55/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0750 - accuracy: 0.9733 - val_loss: 2.1374 - val_accuracy: 0.6941\n","Epoch 56/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0870 - accuracy: 0.9688 - val_loss: 2.1354 - val_accuracy: 0.7018\n","Epoch 57/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1007 - accuracy: 0.9641 - val_loss: 2.1273 - val_accuracy: 0.6951\n","Epoch 58/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.9692 - val_loss: 2.1556 - val_accuracy: 0.6981\n","Epoch 59/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0845 - accuracy: 0.9697 - val_loss: 2.1434 - val_accuracy: 0.7052\n","Epoch 60/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0625 - accuracy: 0.9783 - val_loss: 2.1588 - val_accuracy: 0.7092\n","Epoch 61/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0823 - accuracy: 0.9702 - val_loss: 2.3312 - val_accuracy: 0.6888\n","Epoch 62/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0952 - accuracy: 0.9661 - val_loss: 2.2829 - val_accuracy: 0.7044\n","Epoch 63/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0766 - accuracy: 0.9729 - val_loss: 2.6759 - val_accuracy: 0.6655\n","Epoch 64/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9747 - val_loss: 2.2882 - val_accuracy: 0.7147\n","Epoch 65/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.9762 - val_loss: 2.3047 - val_accuracy: 0.6947\n","Epoch 66/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0800 - accuracy: 0.9716 - val_loss: 2.3132 - val_accuracy: 0.6995\n","Epoch 67/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 2.6783 - val_accuracy: 0.6757\n","Epoch 68/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0882 - accuracy: 0.9685 - val_loss: 2.4027 - val_accuracy: 0.7008\n","Epoch 69/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0682 - accuracy: 0.9761 - val_loss: 2.3030 - val_accuracy: 0.7067\n","Epoch 70/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 2.3750 - val_accuracy: 0.7096\n","Epoch 71/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0734 - accuracy: 0.9745 - val_loss: 2.6067 - val_accuracy: 0.6914\n","Epoch 72/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0799 - accuracy: 0.9725 - val_loss: 2.4884 - val_accuracy: 0.6997\n","Epoch 73/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0745 - accuracy: 0.9749 - val_loss: 2.4718 - val_accuracy: 0.6966\n","Epoch 74/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0662 - accuracy: 0.9765 - val_loss: 2.6415 - val_accuracy: 0.6820\n","Epoch 75/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0604 - accuracy: 0.9788 - val_loss: 2.6109 - val_accuracy: 0.7025\n","Epoch 76/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0744 - accuracy: 0.9737 - val_loss: 2.5285 - val_accuracy: 0.6949\n","Epoch 77/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0650 - accuracy: 0.9775 - val_loss: 2.3869 - val_accuracy: 0.7002\n","Epoch 78/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 2.3597 - val_accuracy: 0.7015\n","Epoch 79/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0522 - accuracy: 0.9813 - val_loss: 2.5572 - val_accuracy: 0.7093\n","Epoch 80/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0594 - accuracy: 0.9789 - val_loss: 2.7185 - val_accuracy: 0.6850\n","Epoch 81/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0744 - accuracy: 0.9738 - val_loss: 2.5849 - val_accuracy: 0.6988\n","Epoch 82/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0625 - accuracy: 0.9785 - val_loss: 2.5665 - val_accuracy: 0.6904\n","Epoch 83/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0411 - accuracy: 0.9856 - val_loss: 2.5836 - val_accuracy: 0.7053\n","Epoch 84/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0654 - accuracy: 0.9788 - val_loss: 2.7080 - val_accuracy: 0.6902\n","Epoch 85/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0571 - accuracy: 0.9798 - val_loss: 2.7027 - val_accuracy: 0.6903\n","Epoch 86/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0636 - accuracy: 0.9778 - val_loss: 2.5697 - val_accuracy: 0.7063\n","Epoch 87/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0586 - accuracy: 0.9799 - val_loss: 2.6521 - val_accuracy: 0.6989\n","Epoch 88/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0598 - accuracy: 0.9798 - val_loss: 2.6954 - val_accuracy: 0.6898\n","Epoch 89/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0733 - accuracy: 0.9748 - val_loss: 2.6496 - val_accuracy: 0.7077\n","Epoch 90/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0462 - accuracy: 0.9835 - val_loss: 2.6480 - val_accuracy: 0.7024\n","Epoch 91/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0414 - accuracy: 0.9856 - val_loss: 2.7020 - val_accuracy: 0.6941\n","Epoch 92/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0473 - accuracy: 0.9843 - val_loss: 2.9394 - val_accuracy: 0.6945\n","Epoch 93/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0776 - accuracy: 0.9735 - val_loss: 3.2247 - val_accuracy: 0.6737\n","Epoch 94/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 2.9685 - val_accuracy: 0.6913\n","Epoch 95/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0478 - accuracy: 0.9841 - val_loss: 2.7994 - val_accuracy: 0.6979\n","Epoch 96/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0551 - accuracy: 0.9805 - val_loss: 3.3954 - val_accuracy: 0.6702\n","Epoch 97/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9729 - val_loss: 2.6741 - val_accuracy: 0.7051\n","Epoch 98/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 2.8542 - val_accuracy: 0.7028\n","Epoch 99/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 2.6994 - val_accuracy: 0.7094\n","Epoch 100/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0516 - accuracy: 0.9833 - val_loss: 3.1755 - val_accuracy: 0.6836\n","Accuracy of model 1:  0.6836000084877014\n","Epoch 1/100\n","391/391 [==============================] - 7s 14ms/step - loss: 1.3139 - accuracy: 0.5910 - val_loss: 0.9924 - val_accuracy: 0.6561\n","Epoch 2/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.7402 - accuracy: 0.7429 - val_loss: 1.6400 - val_accuracy: 0.4907\n","Epoch 3/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.6099 - accuracy: 0.7876 - val_loss: 0.8562 - val_accuracy: 0.7125\n","Epoch 4/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.5206 - accuracy: 0.8177 - val_loss: 0.8487 - val_accuracy: 0.7231\n","Epoch 5/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.4408 - accuracy: 0.8464 - val_loss: 0.9379 - val_accuracy: 0.7089\n","Epoch 6/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.3805 - accuracy: 0.8660 - val_loss: 1.1042 - val_accuracy: 0.6734\n","Epoch 7/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.3242 - accuracy: 0.8867 - val_loss: 0.8959 - val_accuracy: 0.7180\n","Epoch 8/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.2861 - accuracy: 0.8987 - val_loss: 0.9482 - val_accuracy: 0.7255\n","Epoch 9/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.2473 - accuracy: 0.9122 - val_loss: 1.0648 - val_accuracy: 0.7131\n","Epoch 10/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.2089 - accuracy: 0.9268 - val_loss: 0.9904 - val_accuracy: 0.7414\n","Epoch 11/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.1859 - accuracy: 0.9341 - val_loss: 0.9154 - val_accuracy: 0.7616\n","Epoch 12/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.1550 - accuracy: 0.9450 - val_loss: 1.0222 - val_accuracy: 0.7384\n","Epoch 13/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1473 - accuracy: 0.9479 - val_loss: 1.1613 - val_accuracy: 0.7283\n","Epoch 14/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1318 - accuracy: 0.9529 - val_loss: 1.0738 - val_accuracy: 0.7498\n","Epoch 15/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.1176 - accuracy: 0.9581 - val_loss: 1.4819 - val_accuracy: 0.6858\n","Epoch 16/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.1161 - accuracy: 0.9581 - val_loss: 1.0264 - val_accuracy: 0.7677\n","Epoch 17/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.1015 - accuracy: 0.9632 - val_loss: 1.1732 - val_accuracy: 0.7484\n","Epoch 18/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.1068 - accuracy: 0.9628 - val_loss: 1.1460 - val_accuracy: 0.7399\n","Epoch 19/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0921 - accuracy: 0.9672 - val_loss: 1.2735 - val_accuracy: 0.7520\n","Epoch 20/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0899 - accuracy: 0.9688 - val_loss: 1.1145 - val_accuracy: 0.7652\n","Epoch 21/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0900 - accuracy: 0.9682 - val_loss: 1.4622 - val_accuracy: 0.7328\n","Epoch 22/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0830 - accuracy: 0.9704 - val_loss: 1.1810 - val_accuracy: 0.7573\n","Epoch 23/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0779 - accuracy: 0.9723 - val_loss: 1.3013 - val_accuracy: 0.7582\n","Epoch 24/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0773 - accuracy: 0.9722 - val_loss: 1.4484 - val_accuracy: 0.7260\n","Epoch 25/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0752 - accuracy: 0.9738 - val_loss: 1.3922 - val_accuracy: 0.7409\n","Epoch 26/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0714 - accuracy: 0.9753 - val_loss: 1.5057 - val_accuracy: 0.7345\n","Epoch 27/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0669 - accuracy: 0.9768 - val_loss: 1.5434 - val_accuracy: 0.7368\n","Epoch 28/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0679 - accuracy: 0.9771 - val_loss: 1.2470 - val_accuracy: 0.7635\n","Epoch 29/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0664 - accuracy: 0.9766 - val_loss: 1.2800 - val_accuracy: 0.7708\n","Epoch 30/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0662 - accuracy: 0.9766 - val_loss: 1.2974 - val_accuracy: 0.7651\n","Epoch 31/100\n","391/391 [==============================] - 5s 14ms/step - loss: 0.0635 - accuracy: 0.9773 - val_loss: 1.5647 - val_accuracy: 0.7281\n","Epoch 32/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 1.6472 - val_accuracy: 0.7313\n","Epoch 33/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0615 - accuracy: 0.9791 - val_loss: 1.3516 - val_accuracy: 0.7611\n","Epoch 34/100\n","391/391 [==============================] - 5s 14ms/step - loss: 0.0502 - accuracy: 0.9829 - val_loss: 1.4104 - val_accuracy: 0.7468\n","Epoch 35/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0561 - accuracy: 0.9806 - val_loss: 1.3521 - val_accuracy: 0.7601\n","Epoch 36/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 1.9436 - val_accuracy: 0.6771\n","Epoch 37/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0543 - accuracy: 0.9813 - val_loss: 1.7391 - val_accuracy: 0.7231\n","Epoch 38/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0554 - accuracy: 0.9807 - val_loss: 1.4175 - val_accuracy: 0.7478\n","Epoch 39/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0484 - accuracy: 0.9831 - val_loss: 1.4660 - val_accuracy: 0.7635\n","Epoch 40/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 1.4886 - val_accuracy: 0.7509\n","Epoch 41/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0483 - accuracy: 0.9836 - val_loss: 1.6513 - val_accuracy: 0.7277\n","Epoch 42/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 1.4600 - val_accuracy: 0.7496\n","Epoch 43/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 1.5253 - val_accuracy: 0.7578\n","Epoch 44/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0479 - accuracy: 0.9840 - val_loss: 1.4993 - val_accuracy: 0.7571\n","Epoch 45/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0434 - accuracy: 0.9856 - val_loss: 1.3569 - val_accuracy: 0.7691\n","Epoch 46/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0512 - accuracy: 0.9828 - val_loss: 1.4586 - val_accuracy: 0.7540\n","Epoch 47/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0458 - accuracy: 0.9847 - val_loss: 1.3950 - val_accuracy: 0.7684\n","Epoch 48/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 1.4010 - val_accuracy: 0.7593\n","Epoch 49/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 1.7880 - val_accuracy: 0.7227\n","Epoch 50/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0406 - accuracy: 0.9861 - val_loss: 1.5677 - val_accuracy: 0.7435\n","Epoch 51/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 1.4786 - val_accuracy: 0.7604\n","Epoch 52/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 1.5612 - val_accuracy: 0.7536\n","Epoch 53/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 1.3502 - val_accuracy: 0.7712\n","Epoch 54/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0453 - accuracy: 0.9843 - val_loss: 1.4150 - val_accuracy: 0.7573\n","Epoch 55/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 1.9601 - val_accuracy: 0.7076\n","Epoch 56/100\n","391/391 [==============================] - 5s 14ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 1.4092 - val_accuracy: 0.7682\n","Epoch 57/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 2.0428 - val_accuracy: 0.6919\n","Epoch 58/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0367 - accuracy: 0.9871 - val_loss: 1.5846 - val_accuracy: 0.7639\n","Epoch 59/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 1.3942 - val_accuracy: 0.7659\n","Epoch 60/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 1.4644 - val_accuracy: 0.7709\n","Epoch 61/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0299 - accuracy: 0.9896 - val_loss: 1.4647 - val_accuracy: 0.7580\n","Epoch 62/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 1.6316 - val_accuracy: 0.7504\n","Epoch 63/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 1.6597 - val_accuracy: 0.7258\n","Epoch 64/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0340 - accuracy: 0.9885 - val_loss: 1.5544 - val_accuracy: 0.7589\n","Epoch 65/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 1.7211 - val_accuracy: 0.7633\n","Epoch 66/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 1.4935 - val_accuracy: 0.7576\n","Epoch 67/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0326 - accuracy: 0.9888 - val_loss: 1.4864 - val_accuracy: 0.7669\n","Epoch 68/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0294 - accuracy: 0.9901 - val_loss: 1.5417 - val_accuracy: 0.7310\n","Epoch 69/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0335 - accuracy: 0.9893 - val_loss: 1.5498 - val_accuracy: 0.7692\n","Epoch 70/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 1.5042 - val_accuracy: 0.7619\n","Epoch 71/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 1.6111 - val_accuracy: 0.7586\n","Epoch 72/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 1.6099 - val_accuracy: 0.7435\n","Epoch 73/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 1.4151 - val_accuracy: 0.7767\n","Epoch 74/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 1.5917 - val_accuracy: 0.7740\n","Epoch 75/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0374 - accuracy: 0.9875 - val_loss: 1.5238 - val_accuracy: 0.7554\n","Epoch 76/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 1.8053 - val_accuracy: 0.7419\n","Epoch 77/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 1.6039 - val_accuracy: 0.7540\n","Epoch 78/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 1.7850 - val_accuracy: 0.7510\n","Epoch 79/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0248 - accuracy: 0.9919 - val_loss: 1.7088 - val_accuracy: 0.7513\n","Epoch 80/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 1.5112 - val_accuracy: 0.7767\n","Epoch 81/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 1.6898 - val_accuracy: 0.7599\n","Epoch 82/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0237 - accuracy: 0.9912 - val_loss: 1.6228 - val_accuracy: 0.7553\n","Epoch 83/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0285 - accuracy: 0.9901 - val_loss: 1.5660 - val_accuracy: 0.7645\n","Epoch 84/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 1.4310 - val_accuracy: 0.7640\n","Epoch 85/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 1.6014 - val_accuracy: 0.7546\n","Epoch 86/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 1.6081 - val_accuracy: 0.7695\n","Epoch 87/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 1.6190 - val_accuracy: 0.7388\n","Epoch 88/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 1.7519 - val_accuracy: 0.7531\n","Epoch 89/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 1.6061 - val_accuracy: 0.7694\n","Epoch 90/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 1.6174 - val_accuracy: 0.7701\n","Epoch 91/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 1.7016 - val_accuracy: 0.7459\n","Epoch 92/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 1.5283 - val_accuracy: 0.7667\n","Epoch 93/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 2.4879 - val_accuracy: 0.6796\n","Epoch 94/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 1.6389 - val_accuracy: 0.7589\n","Epoch 95/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 1.6910 - val_accuracy: 0.7637\n","Epoch 96/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 1.6182 - val_accuracy: 0.7518\n","Epoch 97/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 1.6688 - val_accuracy: 0.7646\n","Epoch 98/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 1.5625 - val_accuracy: 0.7700\n","Epoch 99/100\n","391/391 [==============================] - 5s 14ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 1.8415 - val_accuracy: 0.7402\n","Epoch 100/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 1.5981 - val_accuracy: 0.7762\n","Accuracy of model 2:  0.776199996471405\n","Epoch 1/100\n","391/391 [==============================] - 12s 24ms/step - loss: 1.0494 - accuracy: 0.6943 - val_loss: 1.2294 - val_accuracy: 0.6367\n","Epoch 2/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.4139 - accuracy: 0.8551 - val_loss: 1.0123 - val_accuracy: 0.6947\n","Epoch 3/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.2814 - accuracy: 0.9027 - val_loss: 1.1083 - val_accuracy: 0.7164\n","Epoch 4/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.2265 - accuracy: 0.9211 - val_loss: 1.2854 - val_accuracy: 0.6454\n","Epoch 5/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.1725 - accuracy: 0.9403 - val_loss: 1.0127 - val_accuracy: 0.7424\n","Epoch 6/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.1505 - accuracy: 0.9486 - val_loss: 1.2159 - val_accuracy: 0.7292\n","Epoch 7/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.1389 - accuracy: 0.9526 - val_loss: 1.3634 - val_accuracy: 0.6873\n","Epoch 8/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1214 - accuracy: 0.9578 - val_loss: 1.8006 - val_accuracy: 0.6463\n","Epoch 9/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1181 - accuracy: 0.9589 - val_loss: 1.2295 - val_accuracy: 0.7444\n","Epoch 10/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0960 - accuracy: 0.9677 - val_loss: 1.4246 - val_accuracy: 0.7155\n","Epoch 11/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1041 - accuracy: 0.9649 - val_loss: 1.3655 - val_accuracy: 0.7093\n","Epoch 12/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0880 - accuracy: 0.9711 - val_loss: 1.2352 - val_accuracy: 0.7459\n","Epoch 13/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0883 - accuracy: 0.9713 - val_loss: 1.2660 - val_accuracy: 0.7375\n","Epoch 14/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0800 - accuracy: 0.9741 - val_loss: 1.3405 - val_accuracy: 0.7143\n","Epoch 15/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0775 - accuracy: 0.9746 - val_loss: 1.5096 - val_accuracy: 0.7097\n","Epoch 16/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0742 - accuracy: 0.9751 - val_loss: 1.5539 - val_accuracy: 0.6990\n","Epoch 17/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0772 - accuracy: 0.9745 - val_loss: 1.2790 - val_accuracy: 0.7436\n","Epoch 18/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0655 - accuracy: 0.9780 - val_loss: 1.2917 - val_accuracy: 0.7407\n","Epoch 19/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0671 - accuracy: 0.9782 - val_loss: 1.2166 - val_accuracy: 0.7555\n","Epoch 20/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0650 - accuracy: 0.9791 - val_loss: 1.1802 - val_accuracy: 0.7571\n","Epoch 21/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0620 - accuracy: 0.9798 - val_loss: 1.7783 - val_accuracy: 0.6789\n","Epoch 22/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0595 - accuracy: 0.9801 - val_loss: 1.3366 - val_accuracy: 0.7353\n","Epoch 23/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0570 - accuracy: 0.9813 - val_loss: 1.4161 - val_accuracy: 0.7367\n","Epoch 24/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0528 - accuracy: 0.9822 - val_loss: 1.4226 - val_accuracy: 0.7453\n","Epoch 25/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 1.4616 - val_accuracy: 0.7317\n","Epoch 26/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0547 - accuracy: 0.9822 - val_loss: 1.4360 - val_accuracy: 0.7587\n","Epoch 27/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 1.4623 - val_accuracy: 0.7362\n","Epoch 28/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 1.2805 - val_accuracy: 0.7565\n","Epoch 29/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0456 - accuracy: 0.9852 - val_loss: 1.5631 - val_accuracy: 0.7266\n","Epoch 30/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0548 - accuracy: 0.9818 - val_loss: 1.5674 - val_accuracy: 0.7325\n","Epoch 31/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0447 - accuracy: 0.9855 - val_loss: 1.4717 - val_accuracy: 0.7491\n","Epoch 32/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 1.4704 - val_accuracy: 0.7296\n","Epoch 33/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 1.4396 - val_accuracy: 0.7502\n","Epoch 34/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 1.4204 - val_accuracy: 0.7370\n","Epoch 35/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 1.6747 - val_accuracy: 0.7341\n","Epoch 36/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0421 - accuracy: 0.9859 - val_loss: 1.5265 - val_accuracy: 0.7236\n","Epoch 37/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0408 - accuracy: 0.9867 - val_loss: 1.4434 - val_accuracy: 0.7504\n","Epoch 38/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0396 - accuracy: 0.9871 - val_loss: 1.7840 - val_accuracy: 0.7017\n","Epoch 39/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 1.6004 - val_accuracy: 0.7551\n","Epoch 40/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 1.4813 - val_accuracy: 0.7421\n","Epoch 41/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 1.7423 - val_accuracy: 0.7184\n","Epoch 42/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 1.6942 - val_accuracy: 0.7355\n","Epoch 43/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0415 - accuracy: 0.9860 - val_loss: 1.5675 - val_accuracy: 0.7548\n","Epoch 44/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 1.5320 - val_accuracy: 0.7410\n","Epoch 45/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 1.6558 - val_accuracy: 0.7514\n","Epoch 46/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 1.5478 - val_accuracy: 0.7538\n","Epoch 47/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 1.6137 - val_accuracy: 0.7367\n","Epoch 48/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 1.6891 - val_accuracy: 0.7335\n","Epoch 49/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0414 - accuracy: 0.9867 - val_loss: 1.4047 - val_accuracy: 0.7475\n","Epoch 50/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 1.5946 - val_accuracy: 0.7387\n","Epoch 51/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 1.5710 - val_accuracy: 0.7532\n","Epoch 52/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0358 - accuracy: 0.9888 - val_loss: 1.5114 - val_accuracy: 0.7405\n","Epoch 53/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 1.4784 - val_accuracy: 0.7611\n","Epoch 54/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0350 - accuracy: 0.9895 - val_loss: 1.6094 - val_accuracy: 0.7489\n","Epoch 55/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 1.7687 - val_accuracy: 0.7507\n","Epoch 56/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0379 - accuracy: 0.9880 - val_loss: 1.7940 - val_accuracy: 0.7165\n","Epoch 57/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 1.4371 - val_accuracy: 0.7485\n","Epoch 58/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 1.8522 - val_accuracy: 0.7266\n","Epoch 59/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 1.7571 - val_accuracy: 0.7226\n","Epoch 60/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 1.9088 - val_accuracy: 0.7173\n","Epoch 61/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 1.8598 - val_accuracy: 0.7256\n","Epoch 62/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 1.7157 - val_accuracy: 0.7504\n","Epoch 63/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 2.0164 - val_accuracy: 0.7203\n","Epoch 64/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0327 - accuracy: 0.9898 - val_loss: 1.6793 - val_accuracy: 0.7303\n","Epoch 65/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 1.6177 - val_accuracy: 0.7514\n","Epoch 66/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 1.4970 - val_accuracy: 0.7478\n","Epoch 67/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 1.8218 - val_accuracy: 0.7296\n","Epoch 68/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 1.7236 - val_accuracy: 0.7303\n","Epoch 69/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 1.8197 - val_accuracy: 0.7531\n","Epoch 70/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 1.6731 - val_accuracy: 0.7432\n","Epoch 71/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 1.7306 - val_accuracy: 0.7591\n","Epoch 72/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 2.5244 - val_accuracy: 0.6913\n","Epoch 73/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 2.0877 - val_accuracy: 0.7146\n","Epoch 74/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 1.8336 - val_accuracy: 0.7646\n","Epoch 75/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 2.7542 - val_accuracy: 0.7119\n","Epoch 76/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 1.9331 - val_accuracy: 0.7191\n","Epoch 77/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 1.9622 - val_accuracy: 0.7420\n","Epoch 78/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 1.7049 - val_accuracy: 0.7346\n","Epoch 79/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 1.6756 - val_accuracy: 0.7521\n","Epoch 80/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 1.7409 - val_accuracy: 0.7328\n","Epoch 81/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 1.7162 - val_accuracy: 0.7496\n","Epoch 82/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 1.8261 - val_accuracy: 0.7318\n","Epoch 83/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 1.6229 - val_accuracy: 0.7575\n","Epoch 84/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 1.6473 - val_accuracy: 0.7451\n","Epoch 85/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 1.6981 - val_accuracy: 0.7456\n","Epoch 86/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 1.7423 - val_accuracy: 0.7491\n","Epoch 87/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 1.7333 - val_accuracy: 0.7601\n","Epoch 88/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 1.8736 - val_accuracy: 0.7464\n","Epoch 89/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 1.6951 - val_accuracy: 0.7440\n","Epoch 90/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 1.6968 - val_accuracy: 0.7427\n","Epoch 91/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 1.6643 - val_accuracy: 0.7505\n","Epoch 92/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 1.6546 - val_accuracy: 0.7470\n","Epoch 93/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 1.4633 - val_accuracy: 0.7517\n","Epoch 94/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 1.7413 - val_accuracy: 0.7432\n","Epoch 95/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 1.7307 - val_accuracy: 0.7507\n","Epoch 96/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 1.7723 - val_accuracy: 0.7515\n","Epoch 97/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 1.7449 - val_accuracy: 0.7676\n","Epoch 98/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 1.9932 - val_accuracy: 0.7475\n","Epoch 99/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 1.9195 - val_accuracy: 0.7561\n","Epoch 100/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 1.8836 - val_accuracy: 0.7495\n","Accuracy of model 3:  0.7494999766349792\n","Epoch 1/100\n","391/391 [==============================] - 13s 29ms/step - loss: 1.1499 - accuracy: 0.6972 - val_loss: 1.0349 - val_accuracy: 0.6881\n","Epoch 2/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.3115 - accuracy: 0.8951 - val_loss: 0.9404 - val_accuracy: 0.7286\n","Epoch 3/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.2053 - accuracy: 0.9295 - val_loss: 1.2482 - val_accuracy: 0.6732\n","Epoch 4/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.1738 - accuracy: 0.9415 - val_loss: 1.1458 - val_accuracy: 0.7128\n","Epoch 5/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.1443 - accuracy: 0.9514 - val_loss: 1.2675 - val_accuracy: 0.7156\n","Epoch 6/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.1303 - accuracy: 0.9573 - val_loss: 1.4056 - val_accuracy: 0.6929\n","Epoch 7/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.1108 - accuracy: 0.9640 - val_loss: 1.4603 - val_accuracy: 0.6920\n","Epoch 8/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.1094 - accuracy: 0.9636 - val_loss: 1.1870 - val_accuracy: 0.7302\n","Epoch 9/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.1029 - accuracy: 0.9657 - val_loss: 1.2702 - val_accuracy: 0.7436\n","Epoch 10/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0970 - accuracy: 0.9683 - val_loss: 1.2256 - val_accuracy: 0.7316\n","Epoch 11/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0895 - accuracy: 0.9702 - val_loss: 1.2867 - val_accuracy: 0.7184\n","Epoch 12/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0903 - accuracy: 0.9708 - val_loss: 1.3453 - val_accuracy: 0.7255\n","Epoch 13/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0722 - accuracy: 0.9763 - val_loss: 1.5925 - val_accuracy: 0.7071\n","Epoch 14/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0802 - accuracy: 0.9740 - val_loss: 1.3184 - val_accuracy: 0.7450\n","Epoch 15/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0783 - accuracy: 0.9747 - val_loss: 1.2889 - val_accuracy: 0.7237\n","Epoch 16/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0734 - accuracy: 0.9757 - val_loss: 1.2816 - val_accuracy: 0.7424\n","Epoch 17/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0691 - accuracy: 0.9769 - val_loss: 1.3791 - val_accuracy: 0.7392\n","Epoch 18/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0639 - accuracy: 0.9788 - val_loss: 1.6801 - val_accuracy: 0.6942\n","Epoch 19/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0715 - accuracy: 0.9771 - val_loss: 1.7594 - val_accuracy: 0.6645\n","Epoch 20/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0684 - accuracy: 0.9780 - val_loss: 1.2176 - val_accuracy: 0.7536\n","Epoch 21/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 1.4045 - val_accuracy: 0.7038\n","Epoch 22/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0574 - accuracy: 0.9816 - val_loss: 1.4078 - val_accuracy: 0.7368\n","Epoch 23/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0542 - accuracy: 0.9829 - val_loss: 1.5476 - val_accuracy: 0.7218\n","Epoch 24/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0543 - accuracy: 0.9824 - val_loss: 1.5101 - val_accuracy: 0.7132\n","Epoch 25/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0585 - accuracy: 0.9812 - val_loss: 1.4461 - val_accuracy: 0.7324\n","Epoch 26/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 1.3597 - val_accuracy: 0.7394\n","Epoch 27/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0530 - accuracy: 0.9829 - val_loss: 1.2505 - val_accuracy: 0.7574\n","Epoch 28/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0470 - accuracy: 0.9851 - val_loss: 1.5045 - val_accuracy: 0.7335\n","Epoch 29/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0481 - accuracy: 0.9840 - val_loss: 1.3863 - val_accuracy: 0.7391\n","Epoch 30/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 1.4673 - val_accuracy: 0.7434\n","Epoch 31/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 1.3197 - val_accuracy: 0.7558\n","Epoch 32/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0433 - accuracy: 0.9859 - val_loss: 1.4198 - val_accuracy: 0.7317\n","Epoch 33/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0451 - accuracy: 0.9854 - val_loss: 1.5024 - val_accuracy: 0.7070\n","Epoch 34/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0448 - accuracy: 0.9858 - val_loss: 1.5122 - val_accuracy: 0.7465\n","Epoch 35/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 1.6433 - val_accuracy: 0.7252\n","Epoch 36/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0413 - accuracy: 0.9871 - val_loss: 1.5363 - val_accuracy: 0.7317\n","Epoch 37/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 1.5590 - val_accuracy: 0.7177\n","Epoch 38/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 1.4346 - val_accuracy: 0.7535\n","Epoch 39/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 1.5499 - val_accuracy: 0.7305\n","Epoch 40/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0391 - accuracy: 0.9882 - val_loss: 1.6767 - val_accuracy: 0.7323\n","Epoch 41/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 1.7318 - val_accuracy: 0.7395\n","Epoch 42/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 1.4371 - val_accuracy: 0.7425\n","Epoch 43/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0371 - accuracy: 0.9883 - val_loss: 1.7147 - val_accuracy: 0.7205\n","Epoch 44/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 1.6515 - val_accuracy: 0.7447\n","Epoch 45/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 1.3998 - val_accuracy: 0.7494\n","Epoch 46/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 1.6087 - val_accuracy: 0.7502\n","Epoch 47/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 1.4678 - val_accuracy: 0.7495\n","Epoch 48/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 1.6184 - val_accuracy: 0.7263\n","Epoch 49/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0391 - accuracy: 0.9875 - val_loss: 1.5229 - val_accuracy: 0.7614\n","Epoch 50/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 1.8668 - val_accuracy: 0.7079\n","Epoch 51/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 1.6163 - val_accuracy: 0.7364\n","Epoch 52/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 1.5728 - val_accuracy: 0.7484\n","Epoch 53/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 1.5028 - val_accuracy: 0.7245\n","Epoch 54/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0275 - accuracy: 0.9910 - val_loss: 1.6857 - val_accuracy: 0.7532\n","Epoch 55/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 1.6741 - val_accuracy: 0.7138\n","Epoch 56/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 1.6272 - val_accuracy: 0.7464\n","Epoch 57/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 1.6972 - val_accuracy: 0.7552\n","Epoch 58/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 1.5575 - val_accuracy: 0.7280\n","Epoch 59/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 1.6301 - val_accuracy: 0.7428\n","Epoch 60/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 1.6870 - val_accuracy: 0.7353\n","Epoch 61/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 1.5256 - val_accuracy: 0.7437\n","Epoch 62/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 1.6508 - val_accuracy: 0.7460\n","Epoch 63/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 1.4461 - val_accuracy: 0.7509\n","Epoch 64/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 1.4168 - val_accuracy: 0.7384\n","Epoch 65/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 2.0105 - val_accuracy: 0.7293\n","Epoch 66/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 1.5730 - val_accuracy: 0.7628\n","Epoch 67/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 1.8654 - val_accuracy: 0.6856\n","Epoch 68/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 1.6369 - val_accuracy: 0.7373\n","Epoch 69/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 1.7872 - val_accuracy: 0.7350\n","Epoch 70/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 1.6933 - val_accuracy: 0.7238\n","Epoch 71/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 1.5641 - val_accuracy: 0.7565\n","Epoch 72/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 1.5294 - val_accuracy: 0.7408\n","Epoch 73/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 1.6306 - val_accuracy: 0.7602\n","Epoch 74/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 2.0853 - val_accuracy: 0.7050\n","Epoch 75/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 2.1383 - val_accuracy: 0.7301\n","Epoch 76/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 1.8854 - val_accuracy: 0.7456\n","Epoch 77/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 1.6339 - val_accuracy: 0.7537\n","Epoch 78/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 1.8133 - val_accuracy: 0.7542\n","Epoch 79/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 1.6684 - val_accuracy: 0.7661\n","Epoch 80/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 1.7846 - val_accuracy: 0.7554\n","Epoch 81/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 1.6464 - val_accuracy: 0.7465\n","Epoch 82/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 1.7259 - val_accuracy: 0.7537\n","Epoch 83/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 1.6964 - val_accuracy: 0.7307\n","Epoch 84/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 1.6104 - val_accuracy: 0.7483\n","Epoch 85/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 1.7196 - val_accuracy: 0.7488\n","Epoch 86/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 1.5776 - val_accuracy: 0.7604\n","Epoch 87/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 2.1103 - val_accuracy: 0.7549\n","Epoch 88/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 1.6249 - val_accuracy: 0.7573\n","Epoch 89/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 1.4952 - val_accuracy: 0.7578\n","Epoch 90/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 1.6661 - val_accuracy: 0.7644\n","Epoch 91/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 1.7627 - val_accuracy: 0.7526\n","Epoch 92/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 1.6252 - val_accuracy: 0.7482\n","Epoch 93/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 1.6503 - val_accuracy: 0.7608\n","Epoch 94/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 2.0252 - val_accuracy: 0.7256\n","Epoch 95/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 1.8405 - val_accuracy: 0.7214\n","Epoch 96/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 1.7528 - val_accuracy: 0.7516\n","Epoch 97/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 1.5914 - val_accuracy: 0.7571\n","Epoch 98/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 1.6648 - val_accuracy: 0.7565\n","Epoch 99/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 1.9248 - val_accuracy: 0.7460\n","Epoch 100/100\n","391/391 [==============================] - 11s 28ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 1.6614 - val_accuracy: 0.7429\n","Accuracy of model 4:  0.742900013923645\n","Epoch 1/100\n","391/391 [==============================] - 16s 33ms/step - loss: 0.3740 - accuracy: 0.9062 - val_loss: 1.1117 - val_accuracy: 0.7085\n","Epoch 2/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.1643 - accuracy: 0.9448 - val_loss: 1.3300 - val_accuracy: 0.6985\n","Epoch 3/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.1466 - accuracy: 0.9523 - val_loss: 1.1108 - val_accuracy: 0.7325\n","Epoch 4/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.1444 - accuracy: 0.9531 - val_loss: 1.1950 - val_accuracy: 0.7040\n","Epoch 5/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.1219 - accuracy: 0.9607 - val_loss: 1.2613 - val_accuracy: 0.7254\n","Epoch 6/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.1136 - accuracy: 0.9618 - val_loss: 1.3323 - val_accuracy: 0.7101\n","Epoch 7/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.1083 - accuracy: 0.9637 - val_loss: 1.5479 - val_accuracy: 0.6823\n","Epoch 8/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0990 - accuracy: 0.9674 - val_loss: 1.4444 - val_accuracy: 0.6973\n","Epoch 9/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0930 - accuracy: 0.9690 - val_loss: 1.2476 - val_accuracy: 0.7405\n","Epoch 10/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0902 - accuracy: 0.9701 - val_loss: 1.2476 - val_accuracy: 0.7246\n","Epoch 11/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0827 - accuracy: 0.9721 - val_loss: 1.2321 - val_accuracy: 0.7305\n","Epoch 12/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0792 - accuracy: 0.9744 - val_loss: 1.2835 - val_accuracy: 0.7233\n","Epoch 13/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0822 - accuracy: 0.9724 - val_loss: 1.4564 - val_accuracy: 0.7171\n","Epoch 14/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0738 - accuracy: 0.9757 - val_loss: 1.2916 - val_accuracy: 0.7327\n","Epoch 15/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0709 - accuracy: 0.9766 - val_loss: 1.4594 - val_accuracy: 0.7150\n","Epoch 16/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0746 - accuracy: 0.9760 - val_loss: 1.3411 - val_accuracy: 0.7245\n","Epoch 17/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0697 - accuracy: 0.9765 - val_loss: 1.3258 - val_accuracy: 0.7236\n","Epoch 18/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 1.2995 - val_accuracy: 0.7276\n","Epoch 19/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 1.4807 - val_accuracy: 0.7134\n","Epoch 20/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0635 - accuracy: 0.9791 - val_loss: 1.3116 - val_accuracy: 0.7227\n","Epoch 21/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0579 - accuracy: 0.9813 - val_loss: 1.3777 - val_accuracy: 0.7182\n","Epoch 22/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 1.5166 - val_accuracy: 0.7307\n","Epoch 23/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 1.3711 - val_accuracy: 0.7295\n","Epoch 24/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0543 - accuracy: 0.9824 - val_loss: 1.2615 - val_accuracy: 0.7429\n","Epoch 25/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 1.2411 - val_accuracy: 0.7438\n","Epoch 26/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0525 - accuracy: 0.9827 - val_loss: 1.5016 - val_accuracy: 0.7177\n","Epoch 27/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 1.3908 - val_accuracy: 0.7469\n","Epoch 28/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 1.5816 - val_accuracy: 0.7283\n","Epoch 29/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0464 - accuracy: 0.9849 - val_loss: 1.5317 - val_accuracy: 0.7347\n","Epoch 30/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0461 - accuracy: 0.9853 - val_loss: 1.4863 - val_accuracy: 0.7417\n","Epoch 31/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0489 - accuracy: 0.9840 - val_loss: 1.7959 - val_accuracy: 0.7008\n","Epoch 32/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0400 - accuracy: 0.9871 - val_loss: 1.3505 - val_accuracy: 0.7471\n","Epoch 33/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 1.8309 - val_accuracy: 0.7241\n","Epoch 34/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 1.4507 - val_accuracy: 0.7435\n","Epoch 35/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 1.6357 - val_accuracy: 0.7276\n","Epoch 36/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0427 - accuracy: 0.9862 - val_loss: 1.4746 - val_accuracy: 0.7426\n","Epoch 37/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 1.5439 - val_accuracy: 0.7304\n","Epoch 38/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0365 - accuracy: 0.9883 - val_loss: 1.4037 - val_accuracy: 0.7539\n","Epoch 39/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0405 - accuracy: 0.9868 - val_loss: 1.4616 - val_accuracy: 0.7291\n","Epoch 40/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 1.4287 - val_accuracy: 0.7540\n","Epoch 41/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 1.3793 - val_accuracy: 0.7489\n","Epoch 42/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0358 - accuracy: 0.9881 - val_loss: 1.4587 - val_accuracy: 0.7440\n","Epoch 43/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 1.5587 - val_accuracy: 0.7408\n","Epoch 44/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 1.5700 - val_accuracy: 0.7383\n","Epoch 45/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 1.6161 - val_accuracy: 0.7249\n","Epoch 46/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 1.6228 - val_accuracy: 0.7350\n","Epoch 47/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 1.5775 - val_accuracy: 0.7488\n","Epoch 48/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 2.0783 - val_accuracy: 0.7074\n","Epoch 49/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 1.5379 - val_accuracy: 0.7384\n","Epoch 50/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 1.5277 - val_accuracy: 0.7480\n","Epoch 51/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 1.5040 - val_accuracy: 0.7237\n","Epoch 52/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 1.5513 - val_accuracy: 0.7354\n","Epoch 53/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 1.8021 - val_accuracy: 0.7215\n","Epoch 54/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 1.4389 - val_accuracy: 0.7556\n","Epoch 55/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 1.6931 - val_accuracy: 0.7474\n","Epoch 56/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 1.4517 - val_accuracy: 0.7505\n","Epoch 57/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0551 - accuracy: 0.9833 - val_loss: 1.5466 - val_accuracy: 0.7429\n","Epoch 58/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0275 - accuracy: 0.9910 - val_loss: 1.7863 - val_accuracy: 0.7442\n","Epoch 59/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 1.6404 - val_accuracy: 0.7444\n","Epoch 60/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 1.7727 - val_accuracy: 0.7353\n","Epoch 61/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 1.4872 - val_accuracy: 0.7220\n","Epoch 62/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 1.8073 - val_accuracy: 0.7347\n","Epoch 63/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 1.9856 - val_accuracy: 0.7068\n","Epoch 64/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 1.5836 - val_accuracy: 0.7448\n","Epoch 65/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 1.6854 - val_accuracy: 0.7177\n","Epoch 66/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 1.4704 - val_accuracy: 0.7565\n","Epoch 67/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 1.4796 - val_accuracy: 0.7457\n","Epoch 68/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 2.2012 - val_accuracy: 0.7376\n","Epoch 69/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 1.9359 - val_accuracy: 0.7372\n","Epoch 70/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 1.6594 - val_accuracy: 0.7499\n","Epoch 71/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 1.6812 - val_accuracy: 0.7453\n","Epoch 72/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 1.6686 - val_accuracy: 0.7460\n","Epoch 73/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 1.5960 - val_accuracy: 0.7460\n","Epoch 74/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 1.4872 - val_accuracy: 0.7448\n","Epoch 75/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 1.7034 - val_accuracy: 0.7364\n","Epoch 76/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 1.7336 - val_accuracy: 0.7548\n","Epoch 77/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 1.7667 - val_accuracy: 0.7483\n","Epoch 78/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 1.7026 - val_accuracy: 0.7506\n","Epoch 79/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 1.7597 - val_accuracy: 0.7559\n","Epoch 80/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 1.6825 - val_accuracy: 0.7513\n","Epoch 81/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 1.4665 - val_accuracy: 0.7522\n","Epoch 82/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 1.8279 - val_accuracy: 0.7475\n","Epoch 83/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 1.5980 - val_accuracy: 0.7586\n","Epoch 84/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 1.6399 - val_accuracy: 0.7537\n","Epoch 85/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 2.4336 - val_accuracy: 0.7071\n","Epoch 86/100\n","391/391 [==============================] - 13s 32ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 1.6945 - val_accuracy: 0.7527\n","Epoch 87/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 1.6441 - val_accuracy: 0.7479\n","Epoch 88/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 1.5820 - val_accuracy: 0.7575\n","Epoch 89/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 2.0430 - val_accuracy: 0.7415\n","Epoch 90/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 1.7490 - val_accuracy: 0.7331\n","Epoch 91/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 1.7145 - val_accuracy: 0.7449\n","Epoch 92/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 1.9056 - val_accuracy: 0.7664\n","Epoch 93/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 1.6299 - val_accuracy: 0.7571\n","Epoch 94/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 1.6952 - val_accuracy: 0.7316\n","Epoch 95/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 1.7341 - val_accuracy: 0.7576\n","Epoch 96/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 1.8201 - val_accuracy: 0.7532\n","Epoch 97/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 1.9584 - val_accuracy: 0.7174\n","Epoch 98/100\n","391/391 [==============================] - 13s 33ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 1.7175 - val_accuracy: 0.7472\n","Epoch 99/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 2.0868 - val_accuracy: 0.7232\n","Epoch 100/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 1.8782 - val_accuracy: 0.7523\n","Accuracy of model 5:  0.7523000240325928\n","Epoch 1/100\n","391/391 [==============================] - 20s 41ms/step - loss: 0.3186 - accuracy: 0.9115 - val_loss: 1.0981 - val_accuracy: 0.7175\n","Epoch 2/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.1629 - accuracy: 0.9466 - val_loss: 1.2168 - val_accuracy: 0.7254\n","Epoch 3/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1456 - accuracy: 0.9508 - val_loss: 1.3416 - val_accuracy: 0.6962\n","Epoch 4/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1316 - accuracy: 0.9559 - val_loss: 1.4943 - val_accuracy: 0.6922\n","Epoch 5/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.1267 - accuracy: 0.9575 - val_loss: 1.1194 - val_accuracy: 0.7388\n","Epoch 6/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1102 - accuracy: 0.9634 - val_loss: 1.2476 - val_accuracy: 0.7228\n","Epoch 7/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1028 - accuracy: 0.9668 - val_loss: 1.5057 - val_accuracy: 0.6899\n","Epoch 8/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1073 - accuracy: 0.9637 - val_loss: 1.3946 - val_accuracy: 0.7010\n","Epoch 9/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0928 - accuracy: 0.9686 - val_loss: 1.3513 - val_accuracy: 0.7210\n","Epoch 10/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0872 - accuracy: 0.9710 - val_loss: 1.3540 - val_accuracy: 0.7134\n","Epoch 11/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0863 - accuracy: 0.9720 - val_loss: 1.5812 - val_accuracy: 0.6771\n","Epoch 12/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0811 - accuracy: 0.9736 - val_loss: 1.3420 - val_accuracy: 0.7158\n","Epoch 13/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0732 - accuracy: 0.9761 - val_loss: 1.4031 - val_accuracy: 0.7092\n","Epoch 14/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0771 - accuracy: 0.9742 - val_loss: 1.5456 - val_accuracy: 0.6945\n","Epoch 15/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0741 - accuracy: 0.9754 - val_loss: 1.5997 - val_accuracy: 0.7071\n","Epoch 16/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.2749 - accuracy: 0.9176 - val_loss: 1.3402 - val_accuracy: 0.6905\n","Epoch 17/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0711 - accuracy: 0.9759 - val_loss: 1.4531 - val_accuracy: 0.7069\n","Epoch 18/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 1.8441 - val_accuracy: 0.6851\n","Epoch 19/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0534 - accuracy: 0.9823 - val_loss: 1.3998 - val_accuracy: 0.7413\n","Epoch 20/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0488 - accuracy: 0.9840 - val_loss: 1.5152 - val_accuracy: 0.7258\n","Epoch 21/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 1.2375 - val_accuracy: 0.7485\n","Epoch 22/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0521 - accuracy: 0.9828 - val_loss: 1.4348 - val_accuracy: 0.7063\n","Epoch 23/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0551 - accuracy: 0.9815 - val_loss: 1.3133 - val_accuracy: 0.7346\n","Epoch 24/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0532 - accuracy: 0.9829 - val_loss: 1.4856 - val_accuracy: 0.7214\n","Epoch 25/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0572 - accuracy: 0.9814 - val_loss: 1.2432 - val_accuracy: 0.7424\n","Epoch 26/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0483 - accuracy: 0.9846 - val_loss: 1.3014 - val_accuracy: 0.7460\n","Epoch 27/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 1.3037 - val_accuracy: 0.7403\n","Epoch 28/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0458 - accuracy: 0.9842 - val_loss: 1.4258 - val_accuracy: 0.7443\n","Epoch 29/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 1.4491 - val_accuracy: 0.7131\n","Epoch 30/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0493 - accuracy: 0.9838 - val_loss: 1.3327 - val_accuracy: 0.7487\n","Epoch 31/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0463 - accuracy: 0.9857 - val_loss: 1.4039 - val_accuracy: 0.7414\n","Epoch 32/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 1.7514 - val_accuracy: 0.7125\n","Epoch 33/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0418 - accuracy: 0.9857 - val_loss: 1.6333 - val_accuracy: 0.7268\n","Epoch 34/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 1.5797 - val_accuracy: 0.7102\n","Epoch 35/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0414 - accuracy: 0.9869 - val_loss: 1.4919 - val_accuracy: 0.7450\n","Epoch 36/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 1.6370 - val_accuracy: 0.7121\n","Epoch 37/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 1.7779 - val_accuracy: 0.7141\n","Epoch 38/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 1.4697 - val_accuracy: 0.7406\n","Epoch 39/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 1.5411 - val_accuracy: 0.7340\n","Epoch 40/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 1.8135 - val_accuracy: 0.7001\n","Epoch 41/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0313 - accuracy: 0.9893 - val_loss: 1.6644 - val_accuracy: 0.7132\n","Epoch 42/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0394 - accuracy: 0.9869 - val_loss: 1.6033 - val_accuracy: 0.7284\n","Epoch 43/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 1.6103 - val_accuracy: 0.7357\n","Epoch 44/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 1.4379 - val_accuracy: 0.7420\n","Epoch 45/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 1.5044 - val_accuracy: 0.7385\n","Epoch 46/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0359 - accuracy: 0.9881 - val_loss: 1.6181 - val_accuracy: 0.7397\n","Epoch 47/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 1.6045 - val_accuracy: 0.7369\n","Epoch 48/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0426 - accuracy: 0.9873 - val_loss: 1.5769 - val_accuracy: 0.6945\n","Epoch 49/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0931 - accuracy: 0.9738 - val_loss: 1.2634 - val_accuracy: 0.7531\n","Epoch 50/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 1.4738 - val_accuracy: 0.7585\n","Epoch 51/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 1.6575 - val_accuracy: 0.7450\n","Epoch 52/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 1.7560 - val_accuracy: 0.7231\n","Epoch 53/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 1.4689 - val_accuracy: 0.7529\n","Epoch 54/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 1.7009 - val_accuracy: 0.7234\n","Epoch 55/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 1.9030 - val_accuracy: 0.7225\n","Epoch 56/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0297 - accuracy: 0.9902 - val_loss: 1.5087 - val_accuracy: 0.7327\n","Epoch 57/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 1.6799 - val_accuracy: 0.7342\n","Epoch 58/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 1.4593 - val_accuracy: 0.7558\n","Epoch 59/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 1.6840 - val_accuracy: 0.7557\n","Epoch 60/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 1.7765 - val_accuracy: 0.7074\n","Epoch 61/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 1.8540 - val_accuracy: 0.7295\n","Epoch 62/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 1.6837 - val_accuracy: 0.7270\n","Epoch 63/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 1.6956 - val_accuracy: 0.7242\n","Epoch 64/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 1.8599 - val_accuracy: 0.7293\n","Epoch 65/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 1.7199 - val_accuracy: 0.7395\n","Epoch 66/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 1.7609 - val_accuracy: 0.7388\n","Epoch 67/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 1.7363 - val_accuracy: 0.7560\n","Epoch 68/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 1.4881 - val_accuracy: 0.7597\n","Epoch 69/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 1.5045 - val_accuracy: 0.7588\n","Epoch 70/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.3759 - accuracy: 0.9088 - val_loss: 1.6791 - val_accuracy: 0.5771\n","Epoch 71/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.2376 - accuracy: 0.9216 - val_loss: 1.1418 - val_accuracy: 0.7420\n","Epoch 72/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 1.5546 - val_accuracy: 0.7557\n","Epoch 73/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 1.9869 - val_accuracy: 0.7543\n","Epoch 74/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.8760 - val_accuracy: 0.7592\n","Epoch 75/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.9365 - val_accuracy: 0.7505\n","Epoch 76/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 1.8650 - val_accuracy: 0.7504\n","Epoch 77/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 1.6381 - val_accuracy: 0.7617\n","Epoch 78/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 1.6249 - val_accuracy: 0.7562\n","Epoch 79/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 1.7358 - val_accuracy: 0.7376\n","Epoch 80/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 1.6670 - val_accuracy: 0.7462\n","Epoch 81/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 1.6638 - val_accuracy: 0.7328\n","Epoch 82/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 1.5661 - val_accuracy: 0.7438\n","Epoch 83/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 1.4915 - val_accuracy: 0.7548\n","Epoch 84/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 1.6045 - val_accuracy: 0.7552\n","Epoch 85/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 1.5773 - val_accuracy: 0.7571\n","Epoch 86/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 1.8443 - val_accuracy: 0.7313\n","Epoch 87/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 1.9435 - val_accuracy: 0.7210\n","Epoch 88/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0909 - accuracy: 0.9743 - val_loss: 1.3463 - val_accuracy: 0.7590\n","Epoch 89/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 1.5074 - val_accuracy: 0.7629\n","Epoch 90/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.7404 - val_accuracy: 0.7546\n","Epoch 91/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 1.6413 - val_accuracy: 0.7627\n","Epoch 92/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.1037 - accuracy: 0.9726 - val_loss: 1.2921 - val_accuracy: 0.7466\n","Epoch 93/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 1.4646 - val_accuracy: 0.7432\n","Epoch 94/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 1.6608 - val_accuracy: 0.7591\n","Epoch 95/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 1.8510 - val_accuracy: 0.7622\n","Epoch 96/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 1.8581 - val_accuracy: 0.7455\n","Epoch 97/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 1.6593 - val_accuracy: 0.7672\n","Epoch 98/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 1.7617 - val_accuracy: 0.7583\n","Epoch 99/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 1.9521 - val_accuracy: 0.7554\n","Epoch 100/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 1.8265 - val_accuracy: 0.7594\n","Accuracy of model 6:  0.7594000101089478\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pM1cIwzUTGyt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626700086828,"user_tz":-330,"elapsed":42,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"d8fd80ff-e884-4bff-d46d-dc25c47e320a"},"source":["accuracies_time"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['-----------------------------------------',\n"," (0.7071999907493591, 40.46028923988342),\n"," (0.6976000070571899, 60.690433859825134),\n"," (0.7131999731063843, 80.92057847976685),\n"," (0.6901000142097473, 101.15072309970856),\n"," (0.7092000246047974, 121.38086771965027),\n"," (0.7095999717712402, 141.61101233959198),\n"," (0.6850000023841858, 161.8411569595337),\n"," (0.7024000287055969, 182.0713015794754),\n"," (0.6836000084877014, 202.30144619941711),\n"," '-----------------------------------------',\n"," (0.7652000188827515, 100.72567691802979),\n"," (0.7651000022888184, 151.08851537704467),\n"," (0.7508999705314636, 201.45135383605958),\n"," (0.7434999942779541, 251.81419229507446),\n"," (0.7709000110626221, 302.17703075408934),\n"," (0.761900007724762, 352.5398692131042),\n"," (0.7767000198364258, 402.90270767211916),\n"," (0.7700999975204468, 453.26554613113404),\n"," (0.776199996471405, 503.6283845901489),\n"," '-----------------------------------------',\n"," (0.757099986076355, 184.79266786575317),\n"," (0.7325000166893005, 277.18900179862976),\n"," (0.7421000003814697, 369.58533573150635),\n"," (0.7386999726295471, 461.98166966438293),\n"," (0.7172999978065491, 554.3780035972595),\n"," (0.7432000041007996, 646.7743375301361),\n"," (0.7328000068664551, 739.1706714630127),\n"," (0.7426999807357788, 831.5670053958893),\n"," (0.7494999766349792, 923.9633393287659),\n"," '-----------------------------------------',\n"," (0.753600001335144, 220.86491398811341),\n"," (0.743399977684021, 331.2973709821701),\n"," (0.7322999835014343, 441.72982797622683),\n"," (0.7078999876976013, 552.1622849702835),\n"," (0.7353000044822693, 662.5947419643402),\n"," (0.723800003528595, 773.0271989583969),\n"," (0.7554000020027161, 883.4596559524537),\n"," (0.7644000053405762, 993.8921129465103),\n"," (0.742900013923645, 1104.324569940567),\n"," '-----------------------------------------',\n"," (0.7226999998092651, 257.01399912834165),\n"," (0.7416999936103821, 385.52099869251253),\n"," (0.7540000081062317, 514.0279982566833),\n"," (0.7480000257492065, 642.5349978208542),\n"," (0.7353000044822693, 771.0419973850251),\n"," (0.7498999834060669, 899.5489969491958),\n"," (0.7512999773025513, 1028.0559965133666),\n"," (0.7330999970436096, 1156.5629960775375),\n"," (0.7523000240325928, 1285.0699956417084),\n"," '-----------------------------------------',\n"," (0.7257999777793884, 317.2587631225586),\n"," (0.7487000226974487, 475.8881446838379),\n"," (0.7001000046730042, 634.5175262451172),\n"," (0.7584999799728394, 793.1469078063965),\n"," (0.7074000239372253, 951.7762893676758),\n"," (0.5770999789237976, 1110.405670928955),\n"," (0.7462000250816345, 1269.0350524902344),\n"," (0.7545999884605408, 1427.6644340515136),\n"," (0.7594000101089478, 1586.293815612793)]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Tejc-61PxwIW"},"source":[""],"execution_count":null,"outputs":[]}]}