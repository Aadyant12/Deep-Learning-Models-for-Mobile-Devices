{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment 3.ipynb","provenance":[{"file_id":"16BW6xzLdZiy4fu7b2BJ83z7Litp9w7YG","timestamp":1623066655292},{"file_id":"1qQ_0RaSDUXo_uEbw1vvx3nPGsLtg7iBu","timestamp":1623050277321},{"file_id":"1cGXeoDEMw72Qwq_JddSrkccvR6jR01V_","timestamp":1622991507291}],"mount_file_id":"1k5NEVmfZ3o85e48r8Pax9mivCvm4QPAi","authorship_tag":"ABX9TyNSmEmQ144SvlUQ1+woPXk6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EhRVl-j9XISJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626683720293,"user_tz":-330,"elapsed":6768,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"6f29c295-469c-4c9c-d2f8-4a755c630e2b"},"source":["from tensorflow.keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 3s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SSpWlE_jfAFQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626683724973,"user_tz":-330,"elapsed":4682,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"036c075b-0014-4388-b730-6ab55f30b5b2"},"source":["# example of loading the MobileNet model\n","from keras.applications.resnet50 import ResNet50\n","model = ResNet50(include_top=False, weights= None, input_shape=(32, 32, 3))\n","# summarize the model\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"resnet50\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n","==================================================================================================\n","Total params: 23,587,712\n","Trainable params: 23,534,592\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjtWcfj4WV0l","executionInfo":{"status":"ok","timestamp":1626683724974,"user_tz":-330,"elapsed":15,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"72f7aa46-4838-425b-8996-be36731f9b4f"},"source":["# add new classifier layers for cifar10 classification\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","\n","flat = Flatten()(model.layers[-1].output)\n","class1 = Dense(1024, activation='relu')(flat)\n","class2 = Dense(512, activation='relu')(class1)\n","\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","model = Model(inputs=model.inputs, outputs=prediction)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 2048)         0           conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1024)         2098176     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 10)           5130        dense_1[0][0]                    \n","==================================================================================================\n","Total params: 26,215,818\n","Trainable params: 26,162,698\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dTmxCpIW5eV0"},"source":["import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZK0ePslkBPF","executionInfo":{"status":"ok","timestamp":1626694314864,"user_tz":-330,"elapsed":10589402,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"5ed0804a-e4b6-44b6-c479-97e98e00e824"},"source":["exits = [6, 38, 60, 80, 112, 142]\n","accuracies_time = []\n","for i in range(len(exits)):\n","  model.load_weights(f\"/ResNet50/EarlyExit_till_exit{i+1}_weights.h5\", by_name=True)\n","  for layer in range(exits[i] + 1):\n","    model.layers[layer].trainable = False\n","  model.compile(\n","        optimizer='adam',\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy']\n","  )\n","  start = time.time()\n","  history = model.fit(\n","    x=x_train,\n","    y=y_train,\n","    epochs=100,\n","    verbose=1,\n","    validation_data=(x_test, y_test),\n","    batch_size=128\n","  )\n","  end = time.time()\n","  accuracies_time.append(((history.history.get('val_accuracy')[19]), (end-start)*2/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[29]), (end-start)*3/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[39]), (end-start)*4/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[49]), (end-start)*5/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[59]), (end-start)*6/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[69]), (end-start)*7/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[79]), (end-start)*8/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[89]), (end-start)*9/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[99]), (end-start)*10/10))\n","  print(f\"Accuracy of model {i+1}: \", history.history.get('val_accuracy')[len(history.history.get('val_accuracy')) - 1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","391/391 [==============================] - 42s 56ms/step - loss: 1.6743 - accuracy: 0.3972 - val_loss: 1.5240 - val_accuracy: 0.4740\n","Epoch 2/100\n","391/391 [==============================] - 21s 52ms/step - loss: 1.0685 - accuracy: 0.6229 - val_loss: 1.2577 - val_accuracy: 0.6017\n","Epoch 3/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.8646 - accuracy: 0.7014 - val_loss: 1.0328 - val_accuracy: 0.6576\n","Epoch 4/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.7868 - accuracy: 0.7309 - val_loss: 1.2406 - val_accuracy: 0.6675\n","Epoch 5/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.6629 - accuracy: 0.7736 - val_loss: 1.0399 - val_accuracy: 0.6812\n","Epoch 6/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.5622 - accuracy: 0.8085 - val_loss: 1.1616 - val_accuracy: 0.6588\n","Epoch 7/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.5165 - accuracy: 0.8238 - val_loss: 1.0057 - val_accuracy: 0.6936\n","Epoch 8/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.4436 - accuracy: 0.8505 - val_loss: 1.0799 - val_accuracy: 0.6871\n","Epoch 9/100\n","391/391 [==============================] - 22s 56ms/step - loss: 0.3989 - accuracy: 0.8649 - val_loss: 0.9114 - val_accuracy: 0.7356\n","Epoch 10/100\n","391/391 [==============================] - 22s 56ms/step - loss: 0.3648 - accuracy: 0.8769 - val_loss: 1.0086 - val_accuracy: 0.6994\n","Epoch 11/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3138 - accuracy: 0.8938 - val_loss: 1.0396 - val_accuracy: 0.7155\n","Epoch 12/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.2777 - accuracy: 0.9070 - val_loss: 0.9395 - val_accuracy: 0.7293\n","Epoch 13/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.2444 - accuracy: 0.9179 - val_loss: 1.1555 - val_accuracy: 0.7034\n","Epoch 14/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.2231 - accuracy: 0.9255 - val_loss: 1.2559 - val_accuracy: 0.6864\n","Epoch 15/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.2055 - accuracy: 0.9299 - val_loss: 0.9761 - val_accuracy: 0.7319\n","Epoch 16/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.1953 - accuracy: 0.9344 - val_loss: 8.4407 - val_accuracy: 0.4219\n","Epoch 17/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.2128 - accuracy: 0.9279 - val_loss: 1.0486 - val_accuracy: 0.7314\n","Epoch 18/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.1436 - accuracy: 0.9528 - val_loss: 1.1122 - val_accuracy: 0.7431\n","Epoch 19/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.1414 - accuracy: 0.9524 - val_loss: 1.3194 - val_accuracy: 0.7219\n","Epoch 20/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.1251 - accuracy: 0.9586 - val_loss: 1.1357 - val_accuracy: 0.7402\n","Epoch 21/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.1202 - accuracy: 0.9597 - val_loss: 1.0519 - val_accuracy: 0.7623\n","Epoch 22/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.1154 - accuracy: 0.9612 - val_loss: 1.0977 - val_accuracy: 0.7399\n","Epoch 23/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.1063 - accuracy: 0.9641 - val_loss: 1.1802 - val_accuracy: 0.7450\n","Epoch 24/100\n","391/391 [==============================] - 21s 52ms/step - loss: 0.1037 - accuracy: 0.9650 - val_loss: 1.1323 - val_accuracy: 0.7486\n","Epoch 25/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0918 - accuracy: 0.9698 - val_loss: 1.1689 - val_accuracy: 0.7439\n","Epoch 26/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.1031 - accuracy: 0.9654 - val_loss: 1.3868 - val_accuracy: 0.7371\n","Epoch 27/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0902 - accuracy: 0.9701 - val_loss: 1.1640 - val_accuracy: 0.7470\n","Epoch 28/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0813 - accuracy: 0.9728 - val_loss: 1.3244 - val_accuracy: 0.7501\n","Epoch 29/100\n","391/391 [==============================] - 21s 52ms/step - loss: 0.0797 - accuracy: 0.9738 - val_loss: 1.3045 - val_accuracy: 0.7499\n","Epoch 30/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0814 - accuracy: 0.9730 - val_loss: 1.1953 - val_accuracy: 0.7326\n","Epoch 31/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0794 - accuracy: 0.9738 - val_loss: 1.2129 - val_accuracy: 0.7470\n","Epoch 32/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0788 - accuracy: 0.9744 - val_loss: 1.2246 - val_accuracy: 0.7435\n","Epoch 33/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0667 - accuracy: 0.9784 - val_loss: 1.2154 - val_accuracy: 0.7647\n","Epoch 34/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0684 - accuracy: 0.9772 - val_loss: 1.3013 - val_accuracy: 0.7524\n","Epoch 35/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 1.2271 - val_accuracy: 0.7543\n","Epoch 36/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 1.4060 - val_accuracy: 0.7504\n","Epoch 37/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0550 - accuracy: 0.9812 - val_loss: 1.2287 - val_accuracy: 0.7567\n","Epoch 38/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.1068 - accuracy: 0.9666 - val_loss: 1.8054 - val_accuracy: 0.7026\n","Epoch 39/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.1459 - accuracy: 0.9527 - val_loss: 1.2317 - val_accuracy: 0.7612\n","Epoch 40/100\n","391/391 [==============================] - 22s 55ms/step - loss: 0.0590 - accuracy: 0.9807 - val_loss: 1.2334 - val_accuracy: 0.7599\n","Epoch 41/100\n","391/391 [==============================] - 22s 56ms/step - loss: 0.0378 - accuracy: 0.9873 - val_loss: 1.3526 - val_accuracy: 0.7599\n","Epoch 42/100\n","391/391 [==============================] - 22s 56ms/step - loss: 0.0378 - accuracy: 0.9882 - val_loss: 1.3643 - val_accuracy: 0.7571\n","Epoch 43/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 1.2655 - val_accuracy: 0.7674\n","Epoch 44/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 1.3653 - val_accuracy: 0.7639\n","Epoch 45/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0437 - accuracy: 0.9853 - val_loss: 1.3707 - val_accuracy: 0.7609\n","Epoch 46/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0489 - accuracy: 0.9839 - val_loss: 1.2249 - val_accuracy: 0.7601\n","Epoch 47/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0477 - accuracy: 0.9843 - val_loss: 1.3815 - val_accuracy: 0.7555\n","Epoch 48/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0443 - accuracy: 0.9854 - val_loss: 1.2822 - val_accuracy: 0.7519\n","Epoch 49/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0467 - accuracy: 0.9845 - val_loss: 1.3399 - val_accuracy: 0.7573\n","Epoch 50/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0402 - accuracy: 0.9869 - val_loss: 1.3651 - val_accuracy: 0.7582\n","Epoch 51/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 1.2137 - val_accuracy: 0.7654\n","Epoch 52/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0409 - accuracy: 0.9860 - val_loss: 1.3158 - val_accuracy: 0.7668\n","Epoch 53/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0394 - accuracy: 0.9869 - val_loss: 1.3742 - val_accuracy: 0.7669\n","Epoch 54/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0367 - accuracy: 0.9881 - val_loss: 1.3385 - val_accuracy: 0.7635\n","Epoch 55/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0385 - accuracy: 0.9868 - val_loss: 1.3427 - val_accuracy: 0.7638\n","Epoch 56/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 1.4457 - val_accuracy: 0.7542\n","Epoch 57/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 1.3841 - val_accuracy: 0.7609\n","Epoch 58/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0345 - accuracy: 0.9892 - val_loss: 1.2932 - val_accuracy: 0.7631\n","Epoch 59/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0908 - accuracy: 0.9728 - val_loss: 1.2059 - val_accuracy: 0.7691\n","Epoch 60/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 1.2935 - val_accuracy: 0.7703\n","Epoch 61/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 1.4070 - val_accuracy: 0.7723\n","Epoch 62/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 1.3601 - val_accuracy: 0.7648\n","Epoch 63/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 1.3080 - val_accuracy: 0.7668\n","Epoch 64/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 1.3298 - val_accuracy: 0.7639\n","Epoch 65/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 1.4662 - val_accuracy: 0.7659\n","Epoch 66/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 1.3471 - val_accuracy: 0.7656\n","Epoch 67/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 1.3286 - val_accuracy: 0.7682\n","Epoch 68/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0324 - accuracy: 0.9898 - val_loss: 1.4072 - val_accuracy: 0.7597\n","Epoch 69/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 1.3124 - val_accuracy: 0.7654\n","Epoch 70/100\n","391/391 [==============================] - 21s 54ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 1.3295 - val_accuracy: 0.7686\n","Epoch 71/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 1.3925 - val_accuracy: 0.7665\n","Epoch 72/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 1.3366 - val_accuracy: 0.7673\n","Epoch 73/100\n","391/391 [==============================] - 21s 54ms/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 1.4589 - val_accuracy: 0.7624\n","Epoch 74/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 1.3685 - val_accuracy: 0.7624\n","Epoch 75/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 1.4402 - val_accuracy: 0.7625\n","Epoch 76/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 1.5310 - val_accuracy: 0.7627\n","Epoch 77/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 1.3712 - val_accuracy: 0.7682\n","Epoch 78/100\n","391/391 [==============================] - 21s 54ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 1.3645 - val_accuracy: 0.7642\n","Epoch 79/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 1.4075 - val_accuracy: 0.7603\n","Epoch 80/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 1.3988 - val_accuracy: 0.7663\n","Epoch 81/100\n","391/391 [==============================] - 21s 54ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 1.3938 - val_accuracy: 0.7634\n","Epoch 82/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 1.4186 - val_accuracy: 0.7674\n","Epoch 83/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0993 - accuracy: 0.9703 - val_loss: 1.2303 - val_accuracy: 0.7655\n","Epoch 84/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0572 - accuracy: 0.9838 - val_loss: 1.3588 - val_accuracy: 0.7693\n","Epoch 85/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 1.4397 - val_accuracy: 0.7733\n","Epoch 86/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 1.7005 - val_accuracy: 0.7741\n","Epoch 87/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 1.6654 - val_accuracy: 0.7694\n","Epoch 88/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 1.4582 - val_accuracy: 0.7620\n","Epoch 89/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 1.4588 - val_accuracy: 0.7715\n","Epoch 90/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 1.4215 - val_accuracy: 0.7709\n","Epoch 91/100\n","391/391 [==============================] - 21s 54ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 1.4701 - val_accuracy: 0.7598\n","Epoch 92/100\n","391/391 [==============================] - 21s 54ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 1.4147 - val_accuracy: 0.7656\n","Epoch 93/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 1.4887 - val_accuracy: 0.7657\n","Epoch 94/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 1.6467 - val_accuracy: 0.7700\n","Epoch 95/100\n","391/391 [==============================] - 21s 54ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 1.4201 - val_accuracy: 0.7655\n","Epoch 96/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 1.5340 - val_accuracy: 0.7636\n","Epoch 97/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 1.4179 - val_accuracy: 0.7727\n","Epoch 98/100\n","391/391 [==============================] - 22s 57ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 1.6654 - val_accuracy: 0.7580\n","Epoch 99/100\n","391/391 [==============================] - 21s 54ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 1.4523 - val_accuracy: 0.7748\n","Epoch 100/100\n","391/391 [==============================] - 21s 53ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 1.3985 - val_accuracy: 0.7701\n","Accuracy of model 1:  0.7700999975204468\n","Epoch 1/100\n","391/391 [==============================] - 24s 50ms/step - loss: 1.8054 - accuracy: 0.3952 - val_loss: 1.4204 - val_accuracy: 0.4897\n","Epoch 2/100\n","391/391 [==============================] - 19s 48ms/step - loss: 1.0400 - accuracy: 0.6258 - val_loss: 1.2417 - val_accuracy: 0.5740\n","Epoch 3/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.8024 - accuracy: 0.7151 - val_loss: 1.0552 - val_accuracy: 0.6464\n","Epoch 4/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.6749 - accuracy: 0.7637 - val_loss: 0.9604 - val_accuracy: 0.6813\n","Epoch 5/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.5687 - accuracy: 0.8022 - val_loss: 0.9692 - val_accuracy: 0.6850\n","Epoch 6/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.5121 - accuracy: 0.8237 - val_loss: 0.9910 - val_accuracy: 0.6919\n","Epoch 7/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.4314 - accuracy: 0.8507 - val_loss: 1.0322 - val_accuracy: 0.6887\n","Epoch 8/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.3539 - accuracy: 0.8772 - val_loss: 1.2608 - val_accuracy: 0.6641\n","Epoch 9/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.2886 - accuracy: 0.9012 - val_loss: 1.3340 - val_accuracy: 0.6735\n","Epoch 10/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.2365 - accuracy: 0.9188 - val_loss: 1.2619 - val_accuracy: 0.6994\n","Epoch 11/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.2264 - accuracy: 0.9229 - val_loss: 1.2908 - val_accuracy: 0.7058\n","Epoch 12/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1709 - accuracy: 0.9414 - val_loss: 1.3460 - val_accuracy: 0.7012\n","Epoch 13/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1512 - accuracy: 0.9479 - val_loss: 1.3166 - val_accuracy: 0.7095\n","Epoch 14/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1851 - accuracy: 0.9377 - val_loss: 1.4392 - val_accuracy: 0.7011\n","Epoch 15/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.1141 - accuracy: 0.9612 - val_loss: 1.4389 - val_accuracy: 0.7035\n","Epoch 16/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1311 - accuracy: 0.9569 - val_loss: 1.4444 - val_accuracy: 0.6845\n","Epoch 17/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1028 - accuracy: 0.9654 - val_loss: 1.6071 - val_accuracy: 0.6964\n","Epoch 18/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0924 - accuracy: 0.9686 - val_loss: 1.5723 - val_accuracy: 0.7140\n","Epoch 19/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1518 - accuracy: 0.9495 - val_loss: 1.2878 - val_accuracy: 0.6225\n","Epoch 20/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.3592 - accuracy: 0.8764 - val_loss: 1.2633 - val_accuracy: 0.6958\n","Epoch 21/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1900 - accuracy: 0.9338 - val_loss: 1.2041 - val_accuracy: 0.7112\n","Epoch 22/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1488 - accuracy: 0.9507 - val_loss: 1.3280 - val_accuracy: 0.7142\n","Epoch 23/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0987 - accuracy: 0.9666 - val_loss: 1.4031 - val_accuracy: 0.7190\n","Epoch 24/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0647 - accuracy: 0.9777 - val_loss: 1.6792 - val_accuracy: 0.7202\n","Epoch 25/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0518 - accuracy: 0.9822 - val_loss: 1.6775 - val_accuracy: 0.7161\n","Epoch 26/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 1.7826 - val_accuracy: 0.7095\n","Epoch 27/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.1103 - accuracy: 0.9651 - val_loss: 1.8993 - val_accuracy: 0.6605\n","Epoch 28/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.1073 - accuracy: 0.9635 - val_loss: 1.5322 - val_accuracy: 0.6461\n","Epoch 29/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0953 - accuracy: 0.9679 - val_loss: 1.6830 - val_accuracy: 0.7245\n","Epoch 30/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0426 - accuracy: 0.9852 - val_loss: 1.7716 - val_accuracy: 0.7232\n","Epoch 31/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0465 - accuracy: 0.9843 - val_loss: 1.8888 - val_accuracy: 0.7040\n","Epoch 32/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 1.7192 - val_accuracy: 0.7137\n","Epoch 33/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0546 - accuracy: 0.9807 - val_loss: 1.6169 - val_accuracy: 0.7176\n","Epoch 34/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 1.7184 - val_accuracy: 0.7251\n","Epoch 35/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 1.9296 - val_accuracy: 0.7008\n","Epoch 36/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0568 - accuracy: 0.9812 - val_loss: 1.6710 - val_accuracy: 0.7263\n","Epoch 37/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 1.7614 - val_accuracy: 0.7135\n","Epoch 38/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 1.8041 - val_accuracy: 0.7116\n","Epoch 39/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0439 - accuracy: 0.9850 - val_loss: 1.8085 - val_accuracy: 0.7164\n","Epoch 40/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0447 - accuracy: 0.9851 - val_loss: 1.6716 - val_accuracy: 0.7231\n","Epoch 41/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0431 - accuracy: 0.9853 - val_loss: 1.7367 - val_accuracy: 0.7197\n","Epoch 42/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 1.7856 - val_accuracy: 0.7138\n","Epoch 43/100\n","391/391 [==============================] - 20s 52ms/step - loss: 0.0462 - accuracy: 0.9842 - val_loss: 1.7118 - val_accuracy: 0.7122\n","Epoch 44/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0381 - accuracy: 0.9871 - val_loss: 1.6622 - val_accuracy: 0.7151\n","Epoch 45/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0327 - accuracy: 0.9888 - val_loss: 1.8037 - val_accuracy: 0.7260\n","Epoch 46/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 1.7825 - val_accuracy: 0.7216\n","Epoch 47/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 1.8911 - val_accuracy: 0.7109\n","Epoch 48/100\n","391/391 [==============================] - 20s 51ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 1.9199 - val_accuracy: 0.7059\n","Epoch 49/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0365 - accuracy: 0.9877 - val_loss: 1.8679 - val_accuracy: 0.7035\n","Epoch 50/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 1.7483 - val_accuracy: 0.7183\n","Epoch 51/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 1.9580 - val_accuracy: 0.7145\n","Epoch 52/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 2.0704 - val_accuracy: 0.7070\n","Epoch 53/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 1.9643 - val_accuracy: 0.7185\n","Epoch 54/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0307 - accuracy: 0.9897 - val_loss: 1.8643 - val_accuracy: 0.7137\n","Epoch 55/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 1.9030 - val_accuracy: 0.7097\n","Epoch 56/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0317 - accuracy: 0.9893 - val_loss: 1.8389 - val_accuracy: 0.7239\n","Epoch 57/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 2.0723 - val_accuracy: 0.7170\n","Epoch 58/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 1.8375 - val_accuracy: 0.7214\n","Epoch 59/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0275 - accuracy: 0.9905 - val_loss: 1.9166 - val_accuracy: 0.7182\n","Epoch 60/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 1.6712 - val_accuracy: 0.7210\n","Epoch 61/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 1.8121 - val_accuracy: 0.7221\n","Epoch 62/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 1.9201 - val_accuracy: 0.7138\n","Epoch 63/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0294 - accuracy: 0.9898 - val_loss: 1.9401 - val_accuracy: 0.7100\n","Epoch 64/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 1.8786 - val_accuracy: 0.7240\n","Epoch 65/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 1.8043 - val_accuracy: 0.7260\n","Epoch 66/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 1.8931 - val_accuracy: 0.7242\n","Epoch 67/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 1.9241 - val_accuracy: 0.7288\n","Epoch 68/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 1.8132 - val_accuracy: 0.7244\n","Epoch 69/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 2.0022 - val_accuracy: 0.7254\n","Epoch 70/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 1.8497 - val_accuracy: 0.7232\n","Epoch 71/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 1.8475 - val_accuracy: 0.7280\n","Epoch 72/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 1.7856 - val_accuracy: 0.7296\n","Epoch 73/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 1.8124 - val_accuracy: 0.7225\n","Epoch 74/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 1.8188 - val_accuracy: 0.7303\n","Epoch 75/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 1.9191 - val_accuracy: 0.7317\n","Epoch 76/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 1.8814 - val_accuracy: 0.7262\n","Epoch 77/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 2.1106 - val_accuracy: 0.7190\n","Epoch 78/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 1.8165 - val_accuracy: 0.7268\n","Epoch 79/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 1.8513 - val_accuracy: 0.7214\n","Epoch 80/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 1.9428 - val_accuracy: 0.7279\n","Epoch 81/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 1.9348 - val_accuracy: 0.7341\n","Epoch 82/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 1.9117 - val_accuracy: 0.7261\n","Epoch 83/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 1.8306 - val_accuracy: 0.7262\n","Epoch 84/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 1.9038 - val_accuracy: 0.7241\n","Epoch 85/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 1.9936 - val_accuracy: 0.7305\n","Epoch 86/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 1.9915 - val_accuracy: 0.7275\n","Epoch 87/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 1.7861 - val_accuracy: 0.7324\n","Epoch 88/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 2.0598 - val_accuracy: 0.7270\n","Epoch 89/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 1.7890 - val_accuracy: 0.7253\n","Epoch 90/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 1.9267 - val_accuracy: 0.7199\n","Epoch 91/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 1.8762 - val_accuracy: 0.7302\n","Epoch 92/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 1.9746 - val_accuracy: 0.7307\n","Epoch 93/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 1.9062 - val_accuracy: 0.7326\n","Epoch 94/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 1.9675 - val_accuracy: 0.7256\n","Epoch 95/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 2.0260 - val_accuracy: 0.7257\n","Epoch 96/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 1.8972 - val_accuracy: 0.7273\n","Epoch 97/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 2.0310 - val_accuracy: 0.7282\n","Epoch 98/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 2.0396 - val_accuracy: 0.7285\n","Epoch 99/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 2.1260 - val_accuracy: 0.7265\n","Epoch 100/100\n","391/391 [==============================] - 19s 49ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 1.7997 - val_accuracy: 0.7319\n","Accuracy of model 2:  0.7318999767303467\n","Epoch 1/100\n","391/391 [==============================] - 23s 49ms/step - loss: 1.3543 - accuracy: 0.6168 - val_loss: 1.0477 - val_accuracy: 0.6901\n","Epoch 2/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.3732 - accuracy: 0.8794 - val_loss: 0.9700 - val_accuracy: 0.7420\n","Epoch 3/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.2128 - accuracy: 0.9316 - val_loss: 1.0493 - val_accuracy: 0.7491\n","Epoch 4/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.1356 - accuracy: 0.9572 - val_loss: 1.1038 - val_accuracy: 0.7612\n","Epoch 5/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0862 - accuracy: 0.9725 - val_loss: 1.2343 - val_accuracy: 0.7675\n","Epoch 6/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 1.3545 - val_accuracy: 0.7667\n","Epoch 7/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 1.5849 - val_accuracy: 0.7676\n","Epoch 8/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 1.7207 - val_accuracy: 0.7652\n","Epoch 9/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.8734 - val_accuracy: 0.7669\n","Epoch 10/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 1.8287 - val_accuracy: 0.7692\n","Epoch 11/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 1.9138 - val_accuracy: 0.7683\n","Epoch 12/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 1.9476 - val_accuracy: 0.7711\n","Epoch 13/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 2.0604 - val_accuracy: 0.7672\n","Epoch 14/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 2.1222 - val_accuracy: 0.7683\n","Epoch 15/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 1.9421 - val_accuracy: 0.7684\n","Epoch 16/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 2.0708 - val_accuracy: 0.7717\n","Epoch 17/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 2.1307 - val_accuracy: 0.7718\n","Epoch 18/100\n","391/391 [==============================] - 19s 50ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 2.1269 - val_accuracy: 0.7681\n","Epoch 19/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 2.1363 - val_accuracy: 0.7686\n","Epoch 20/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 2.1292 - val_accuracy: 0.7745\n","Epoch 21/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 2.1374 - val_accuracy: 0.7663\n","Epoch 22/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 2.1348 - val_accuracy: 0.7681\n","Epoch 23/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 2.1179 - val_accuracy: 0.7750\n","Epoch 24/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 2.2677 - val_accuracy: 0.7751\n","Epoch 25/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 2.4177 - val_accuracy: 0.7736\n","Epoch 26/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 2.3676 - val_accuracy: 0.7752\n","Epoch 27/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 2.4200 - val_accuracy: 0.7740\n","Epoch 28/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 2.2429 - val_accuracy: 0.7730\n","Epoch 29/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 2.1689 - val_accuracy: 0.7766\n","Epoch 30/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 2.4287 - val_accuracy: 0.7739\n","Epoch 31/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 2.4582 - val_accuracy: 0.7792\n","Epoch 32/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 2.2800 - val_accuracy: 0.7780\n","Epoch 33/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 2.3491 - val_accuracy: 0.7742\n","Epoch 34/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 2.3156 - val_accuracy: 0.7774\n","Epoch 35/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 2.2908 - val_accuracy: 0.7768\n","Epoch 36/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 2.3649 - val_accuracy: 0.7719\n","Epoch 37/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 2.4236 - val_accuracy: 0.7802\n","Epoch 38/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 2.4868 - val_accuracy: 0.7794\n","Epoch 39/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 2.5920 - val_accuracy: 0.7765\n","Epoch 40/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 2.4401 - val_accuracy: 0.7786\n","Epoch 41/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 2.5482 - val_accuracy: 0.7742\n","Epoch 42/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 2.2658 - val_accuracy: 0.7762\n","Epoch 43/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 2.4663 - val_accuracy: 0.7798\n","Epoch 44/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 2.4466 - val_accuracy: 0.7778\n","Epoch 45/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 2.6988 - val_accuracy: 0.7814\n","Epoch 46/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 2.3461 - val_accuracy: 0.7720\n","Epoch 47/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 2.3305 - val_accuracy: 0.7757\n","Epoch 48/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 2.5631 - val_accuracy: 0.7743\n","Epoch 49/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 2.5530 - val_accuracy: 0.7773\n","Epoch 50/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 2.5242 - val_accuracy: 0.7725\n","Epoch 51/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 2.8441 - val_accuracy: 0.7777\n","Epoch 52/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 2.5580 - val_accuracy: 0.7747\n","Epoch 53/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 2.5388 - val_accuracy: 0.7789\n","Epoch 54/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 2.5571 - val_accuracy: 0.7775\n","Epoch 55/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 2.7906 - val_accuracy: 0.7786\n","Epoch 56/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0150 - accuracy: 0.9980 - val_loss: 2.3309 - val_accuracy: 0.7730\n","Epoch 57/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 2.3297 - val_accuracy: 0.7780\n","Epoch 58/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 2.6835 - val_accuracy: 0.7784\n","Epoch 59/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.9485 - val_accuracy: 0.7757\n","Epoch 60/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 2.5056 - val_accuracy: 0.7780\n","Epoch 61/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 2.4380 - val_accuracy: 0.7751\n","Epoch 62/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 2.6189 - val_accuracy: 0.7770\n","Epoch 63/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 2.6804 - val_accuracy: 0.7805\n","Epoch 64/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 2.5660 - val_accuracy: 0.7800\n","Epoch 65/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 2.3487 - val_accuracy: 0.7789\n","Epoch 66/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 2.8144 - val_accuracy: 0.7762\n","Epoch 67/100\n","391/391 [==============================] - 19s 47ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 2.4346 - val_accuracy: 0.7787\n","Epoch 68/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 3.2115 - val_accuracy: 0.7773\n","Epoch 69/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 2.8578 - val_accuracy: 0.7766\n","Epoch 70/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 2.8795 - val_accuracy: 0.7750\n","Epoch 71/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 2.9761 - val_accuracy: 0.7777\n","Epoch 72/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 2.4757 - val_accuracy: 0.7787\n","Epoch 73/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 2.8168 - val_accuracy: 0.7787\n","Epoch 74/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 2.9218 - val_accuracy: 0.7795\n","Epoch 75/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 3.1233 - val_accuracy: 0.7765\n","Epoch 76/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 2.7719 - val_accuracy: 0.7811\n","Epoch 77/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.6611 - val_accuracy: 0.7782\n","Epoch 78/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 3.0503 - val_accuracy: 0.7776\n","Epoch 79/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 2.6651 - val_accuracy: 0.7790\n","Epoch 80/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 2.8176 - val_accuracy: 0.7780\n","Epoch 81/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 2.4833 - val_accuracy: 0.7789\n","Epoch 82/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 2.6412 - val_accuracy: 0.7761\n","Epoch 83/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 2.8311 - val_accuracy: 0.7793\n","Epoch 84/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 2.7028 - val_accuracy: 0.7777\n","Epoch 85/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 2.5785 - val_accuracy: 0.7793\n","Epoch 86/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 2.4707 - val_accuracy: 0.7815\n","Epoch 87/100\n","391/391 [==============================] - 18s 47ms/step - loss: 9.5225e-04 - accuracy: 0.9997 - val_loss: 3.2558 - val_accuracy: 0.7785\n","Epoch 88/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 3.1101 - val_accuracy: 0.7814\n","Epoch 89/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 2.9903 - val_accuracy: 0.7797\n","Epoch 90/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 2.7775 - val_accuracy: 0.7801\n","Epoch 91/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 2.7334 - val_accuracy: 0.7792\n","Epoch 92/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 2.6901 - val_accuracy: 0.7796\n","Epoch 93/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 2.6375 - val_accuracy: 0.7796\n","Epoch 94/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 3.0198 - val_accuracy: 0.7805\n","Epoch 95/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 2.5941 - val_accuracy: 0.7801\n","Epoch 96/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 2.9803 - val_accuracy: 0.7798\n","Epoch 97/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 3.1752 - val_accuracy: 0.7811\n","Epoch 98/100\n","391/391 [==============================] - 18s 46ms/step - loss: 6.7813e-04 - accuracy: 0.9998 - val_loss: 3.5368 - val_accuracy: 0.7800\n","Epoch 99/100\n","391/391 [==============================] - 18s 46ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 3.2292 - val_accuracy: 0.7800\n","Epoch 100/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 2.8488 - val_accuracy: 0.7840\n","Accuracy of model 3:  0.7839999794960022\n","Epoch 1/100\n","391/391 [==============================] - 21s 45ms/step - loss: 0.3483 - accuracy: 0.8997 - val_loss: 0.9518 - val_accuracy: 0.7377\n","Epoch 2/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.2288 - accuracy: 0.9270 - val_loss: 0.9451 - val_accuracy: 0.7457\n","Epoch 3/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.1840 - accuracy: 0.9401 - val_loss: 1.0039 - val_accuracy: 0.7537\n","Epoch 4/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.1536 - accuracy: 0.9490 - val_loss: 1.0325 - val_accuracy: 0.7559\n","Epoch 5/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.1322 - accuracy: 0.9563 - val_loss: 1.0574 - val_accuracy: 0.7530\n","Epoch 6/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.1128 - accuracy: 0.9624 - val_loss: 1.2424 - val_accuracy: 0.7537\n","Epoch 7/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0944 - accuracy: 0.9687 - val_loss: 1.1856 - val_accuracy: 0.7598\n","Epoch 8/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0768 - accuracy: 0.9743 - val_loss: 1.3657 - val_accuracy: 0.7554\n","Epoch 9/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0623 - accuracy: 0.9796 - val_loss: 1.4775 - val_accuracy: 0.7557\n","Epoch 10/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 1.6495 - val_accuracy: 0.7472\n","Epoch 11/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0422 - accuracy: 0.9863 - val_loss: 1.7260 - val_accuracy: 0.7541\n","Epoch 12/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0347 - accuracy: 0.9889 - val_loss: 1.8520 - val_accuracy: 0.7556\n","Epoch 13/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0523 - accuracy: 0.9860 - val_loss: 1.6832 - val_accuracy: 0.7496\n","Epoch 14/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 1.8229 - val_accuracy: 0.7554\n","Epoch 15/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 1.9357 - val_accuracy: 0.7567\n","Epoch 16/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 2.1413 - val_accuracy: 0.7564\n","Epoch 17/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 2.3843 - val_accuracy: 0.7573\n","Epoch 18/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 2.2221 - val_accuracy: 0.7565\n","Epoch 19/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 2.5714 - val_accuracy: 0.7564\n","Epoch 20/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 2.2581 - val_accuracy: 0.7525\n","Epoch 21/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 2.4197 - val_accuracy: 0.7492\n","Epoch 22/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 2.2694 - val_accuracy: 0.7575\n","Epoch 23/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 2.3323 - val_accuracy: 0.7550\n","Epoch 24/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 2.3907 - val_accuracy: 0.7538\n","Epoch 25/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 2.2870 - val_accuracy: 0.7553\n","Epoch 26/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 2.2651 - val_accuracy: 0.7520\n","Epoch 27/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 2.5164 - val_accuracy: 0.7498\n","Epoch 28/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 2.3795 - val_accuracy: 0.7510\n","Epoch 29/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 2.2869 - val_accuracy: 0.7541\n","Epoch 30/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 2.2956 - val_accuracy: 0.7523\n","Epoch 31/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 2.6109 - val_accuracy: 0.7520\n","Epoch 32/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 2.4655 - val_accuracy: 0.7533\n","Epoch 33/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 2.5012 - val_accuracy: 0.7512\n","Epoch 34/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 2.7240 - val_accuracy: 0.7482\n","Epoch 35/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 2.3227 - val_accuracy: 0.7525\n","Epoch 36/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 2.4887 - val_accuracy: 0.7535\n","Epoch 37/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 2.5188 - val_accuracy: 0.7556\n","Epoch 38/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 2.5104 - val_accuracy: 0.7590\n","Epoch 39/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 2.3746 - val_accuracy: 0.7544\n","Epoch 40/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 2.6676 - val_accuracy: 0.7550\n","Epoch 41/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 2.7422 - val_accuracy: 0.7560\n","Epoch 42/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 2.7103 - val_accuracy: 0.7509\n","Epoch 43/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 2.6868 - val_accuracy: 0.7520\n","Epoch 44/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 2.7529 - val_accuracy: 0.7542\n","Epoch 45/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 2.8830 - val_accuracy: 0.7557\n","Epoch 46/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 2.8549 - val_accuracy: 0.7510\n","Epoch 47/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 2.5766 - val_accuracy: 0.7559\n","Epoch 48/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 2.6949 - val_accuracy: 0.7574\n","Epoch 49/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 2.9047 - val_accuracy: 0.7516\n","Epoch 50/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 2.8168 - val_accuracy: 0.7530\n","Epoch 51/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 2.9327 - val_accuracy: 0.7436\n","Epoch 52/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 2.7456 - val_accuracy: 0.7533\n","Epoch 53/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 2.5087 - val_accuracy: 0.7582\n","Epoch 54/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 2.9689 - val_accuracy: 0.7592\n","Epoch 55/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 3.1562 - val_accuracy: 0.7523\n","Epoch 56/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 2.8974 - val_accuracy: 0.7501\n","Epoch 57/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 2.8053 - val_accuracy: 0.7568\n","Epoch 58/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 2.7501 - val_accuracy: 0.7581\n","Epoch 59/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 2.8257 - val_accuracy: 0.7570\n","Epoch 60/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0277 - accuracy: 0.9960 - val_loss: 2.3740 - val_accuracy: 0.7577\n","Epoch 61/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 2.7187 - val_accuracy: 0.7558\n","Epoch 62/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 3.0005 - val_accuracy: 0.7564\n","Epoch 63/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 4.0300 - val_accuracy: 0.7530\n","Epoch 64/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 3.2003 - val_accuracy: 0.7594\n","Epoch 65/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 3.3915 - val_accuracy: 0.7582\n","Epoch 66/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 3.5027 - val_accuracy: 0.7590\n","Epoch 67/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 3.6052 - val_accuracy: 0.7576\n","Epoch 68/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 3.4899 - val_accuracy: 0.7585\n","Epoch 69/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 3.3501 - val_accuracy: 0.7576\n","Epoch 70/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 3.3540 - val_accuracy: 0.7527\n","Epoch 71/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 3.1963 - val_accuracy: 0.7538\n","Epoch 72/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 3.4933 - val_accuracy: 0.7587\n","Epoch 73/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 3.5105 - val_accuracy: 0.7552\n","Epoch 74/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 3.2174 - val_accuracy: 0.7538\n","Epoch 75/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 3.6058 - val_accuracy: 0.7583\n","Epoch 76/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 3.4749 - val_accuracy: 0.7434\n","Epoch 77/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 3.0235 - val_accuracy: 0.7528\n","Epoch 78/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 3.5561 - val_accuracy: 0.7555\n","Epoch 79/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 3.0689 - val_accuracy: 0.7570\n","Epoch 80/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 3.3833 - val_accuracy: 0.7565\n","Epoch 81/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 2.9814 - val_accuracy: 0.7580\n","Epoch 82/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 2.8962 - val_accuracy: 0.7608\n","Epoch 83/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 3.0365 - val_accuracy: 0.7574\n","Epoch 84/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 3.0390 - val_accuracy: 0.7591\n","Epoch 85/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 3.2221 - val_accuracy: 0.7598\n","Epoch 86/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 2.7369 - val_accuracy: 0.7544\n","Epoch 87/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 3.0217 - val_accuracy: 0.7556\n","Epoch 88/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 2.7357 - val_accuracy: 0.7536\n","Epoch 89/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 3.0630 - val_accuracy: 0.7566\n","Epoch 90/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0189 - accuracy: 0.9977 - val_loss: 2.6127 - val_accuracy: 0.7545\n","Epoch 91/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 2.9232 - val_accuracy: 0.7564\n","Epoch 92/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 3.0775 - val_accuracy: 0.7536\n","Epoch 93/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 3.1151 - val_accuracy: 0.7581\n","Epoch 94/100\n","391/391 [==============================] - 19s 48ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 2.8831 - val_accuracy: 0.7551\n","Epoch 95/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 2.9396 - val_accuracy: 0.7577\n","Epoch 96/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 3.0591 - val_accuracy: 0.7563\n","Epoch 97/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 2.9164 - val_accuracy: 0.7566\n","Epoch 98/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 3.1091 - val_accuracy: 0.7579\n","Epoch 99/100\n","391/391 [==============================] - 18s 47ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 2.8994 - val_accuracy: 0.7578\n","Epoch 100/100\n","391/391 [==============================] - 17s 44ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 3.2472 - val_accuracy: 0.7584\n","Accuracy of model 4:  0.758400022983551\n","Epoch 1/100\n","391/391 [==============================] - 19s 42ms/step - loss: 1.3318 - accuracy: 0.5972 - val_loss: 6.8880 - val_accuracy: 0.0992\n","Epoch 2/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.3464 - accuracy: 0.9019 - val_loss: 10.4772 - val_accuracy: 0.1267\n","Epoch 3/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.2361 - accuracy: 0.9340 - val_loss: 10.4596 - val_accuracy: 0.1021\n","Epoch 4/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.2021 - accuracy: 0.9447 - val_loss: 9.6740 - val_accuracy: 0.1024\n","Epoch 5/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1839 - accuracy: 0.9464 - val_loss: 6.3803 - val_accuracy: 0.1844\n","Epoch 6/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1666 - accuracy: 0.9528 - val_loss: 8.0409 - val_accuracy: 0.1210\n","Epoch 7/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.1608 - accuracy: 0.9547 - val_loss: 9.7398 - val_accuracy: 0.1028\n","Epoch 8/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1513 - accuracy: 0.9581 - val_loss: 6.5351 - val_accuracy: 0.1807\n","Epoch 9/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1475 - accuracy: 0.9566 - val_loss: 10.9882 - val_accuracy: 0.1023\n","Epoch 10/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1394 - accuracy: 0.9593 - val_loss: 11.4968 - val_accuracy: 0.1028\n","Epoch 11/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1344 - accuracy: 0.9608 - val_loss: 11.3588 - val_accuracy: 0.1029\n","Epoch 12/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1278 - accuracy: 0.9626 - val_loss: 12.5090 - val_accuracy: 0.1029\n","Epoch 13/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.1232 - accuracy: 0.9637 - val_loss: 13.8933 - val_accuracy: 0.1028\n","Epoch 14/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.1367 - accuracy: 0.9617 - val_loss: 11.2127 - val_accuracy: 0.1040\n","Epoch 15/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1271 - accuracy: 0.9636 - val_loss: 8.7043 - val_accuracy: 0.1729\n","Epoch 16/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1220 - accuracy: 0.9632 - val_loss: 8.6174 - val_accuracy: 0.1779\n","Epoch 17/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1201 - accuracy: 0.9639 - val_loss: 11.6740 - val_accuracy: 0.1670\n","Epoch 18/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.1183 - accuracy: 0.9636 - val_loss: 8.6665 - val_accuracy: 0.1547\n","Epoch 19/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1181 - accuracy: 0.9634 - val_loss: 10.9403 - val_accuracy: 0.1304\n","Epoch 20/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.1150 - accuracy: 0.9642 - val_loss: 8.6088 - val_accuracy: 0.1437\n","Epoch 21/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.1128 - accuracy: 0.9647 - val_loss: 8.6486 - val_accuracy: 0.1134\n","Epoch 22/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.1120 - accuracy: 0.9657 - val_loss: 9.1295 - val_accuracy: 0.1208\n","Epoch 23/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1117 - accuracy: 0.9647 - val_loss: 9.7082 - val_accuracy: 0.1233\n","Epoch 24/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1118 - accuracy: 0.9657 - val_loss: 9.0269 - val_accuracy: 0.1048\n","Epoch 25/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1069 - accuracy: 0.9664 - val_loss: 9.9615 - val_accuracy: 0.1094\n","Epoch 26/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.1079 - accuracy: 0.9666 - val_loss: 10.1270 - val_accuracy: 0.1297\n","Epoch 27/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1088 - accuracy: 0.9664 - val_loss: 9.1395 - val_accuracy: 0.1361\n","Epoch 28/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.1079 - accuracy: 0.9664 - val_loss: 11.5698 - val_accuracy: 0.1023\n","Epoch 29/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1036 - accuracy: 0.9673 - val_loss: 11.9320 - val_accuracy: 0.1038\n","Epoch 30/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1026 - accuracy: 0.9676 - val_loss: 11.9739 - val_accuracy: 0.1031\n","Epoch 31/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1186 - accuracy: 0.9654 - val_loss: 10.1911 - val_accuracy: 0.1050\n","Epoch 32/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.1052 - accuracy: 0.9666 - val_loss: 11.2271 - val_accuracy: 0.1277\n","Epoch 33/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0993 - accuracy: 0.9682 - val_loss: 11.5696 - val_accuracy: 0.1030\n","Epoch 34/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0986 - accuracy: 0.9683 - val_loss: 11.0502 - val_accuracy: 0.1045\n","Epoch 35/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0991 - accuracy: 0.9681 - val_loss: 11.8670 - val_accuracy: 0.1042\n","Epoch 36/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1041 - accuracy: 0.9681 - val_loss: 15.3690 - val_accuracy: 0.1029\n","Epoch 37/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0983 - accuracy: 0.9682 - val_loss: 13.3529 - val_accuracy: 0.1219\n","Epoch 38/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.1066 - accuracy: 0.9667 - val_loss: 13.9081 - val_accuracy: 0.1147\n","Epoch 39/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0967 - accuracy: 0.9683 - val_loss: 13.4239 - val_accuracy: 0.1450\n","Epoch 40/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0945 - accuracy: 0.9691 - val_loss: 13.4226 - val_accuracy: 0.1233\n","Epoch 41/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0946 - accuracy: 0.9696 - val_loss: 12.6147 - val_accuracy: 0.1311\n","Epoch 42/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0921 - accuracy: 0.9703 - val_loss: 15.2379 - val_accuracy: 0.1030\n","Epoch 43/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0936 - accuracy: 0.9695 - val_loss: 13.7872 - val_accuracy: 0.1246\n","Epoch 44/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0939 - accuracy: 0.9696 - val_loss: 11.8771 - val_accuracy: 0.1121\n","Epoch 45/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0975 - accuracy: 0.9685 - val_loss: 9.0383 - val_accuracy: 0.1367\n","Epoch 46/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0918 - accuracy: 0.9695 - val_loss: 12.6218 - val_accuracy: 0.1048\n","Epoch 47/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0926 - accuracy: 0.9696 - val_loss: 14.3247 - val_accuracy: 0.1035\n","Epoch 48/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0908 - accuracy: 0.9707 - val_loss: 16.8735 - val_accuracy: 0.1025\n","Epoch 49/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0906 - accuracy: 0.9705 - val_loss: 14.4748 - val_accuracy: 0.1026\n","Epoch 50/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0900 - accuracy: 0.9707 - val_loss: 13.6442 - val_accuracy: 0.1024\n","Epoch 51/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0914 - accuracy: 0.9701 - val_loss: 13.3548 - val_accuracy: 0.1025\n","Epoch 52/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0880 - accuracy: 0.9703 - val_loss: 12.6380 - val_accuracy: 0.1173\n","Epoch 53/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0882 - accuracy: 0.9704 - val_loss: 11.4995 - val_accuracy: 0.1027\n","Epoch 54/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0871 - accuracy: 0.9709 - val_loss: 13.0582 - val_accuracy: 0.1025\n","Epoch 55/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0900 - accuracy: 0.9688 - val_loss: 12.2684 - val_accuracy: 0.1031\n","Epoch 56/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0887 - accuracy: 0.9704 - val_loss: 13.6283 - val_accuracy: 0.1026\n","Epoch 57/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0855 - accuracy: 0.9714 - val_loss: 11.7675 - val_accuracy: 0.1028\n","Epoch 58/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0840 - accuracy: 0.9709 - val_loss: 10.3453 - val_accuracy: 0.1056\n","Epoch 59/100\n","391/391 [==============================] - 17s 42ms/step - loss: 0.0833 - accuracy: 0.9715 - val_loss: 13.3024 - val_accuracy: 0.1048\n","Epoch 60/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0818 - accuracy: 0.9714 - val_loss: 11.5699 - val_accuracy: 0.1094\n","Epoch 61/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0843 - accuracy: 0.9722 - val_loss: 10.3600 - val_accuracy: 0.1123\n","Epoch 62/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0816 - accuracy: 0.9726 - val_loss: 15.7330 - val_accuracy: 0.1046\n","Epoch 63/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 11.9566 - val_accuracy: 0.1102\n","Epoch 64/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0828 - accuracy: 0.9712 - val_loss: 12.5315 - val_accuracy: 0.1038\n","Epoch 65/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0830 - accuracy: 0.9713 - val_loss: 11.3918 - val_accuracy: 0.1042\n","Epoch 66/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0796 - accuracy: 0.9724 - val_loss: 13.3484 - val_accuracy: 0.1034\n","Epoch 67/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0909 - accuracy: 0.9709 - val_loss: 13.6644 - val_accuracy: 0.1030\n","Epoch 68/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0842 - accuracy: 0.9714 - val_loss: 12.2251 - val_accuracy: 0.1068\n","Epoch 69/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0803 - accuracy: 0.9733 - val_loss: 13.2090 - val_accuracy: 0.1035\n","Epoch 70/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 14.3540 - val_accuracy: 0.1036\n","Epoch 71/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0749 - accuracy: 0.9737 - val_loss: 12.3487 - val_accuracy: 0.1084\n","Epoch 72/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0769 - accuracy: 0.9732 - val_loss: 12.2241 - val_accuracy: 0.1036\n","Epoch 73/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0785 - accuracy: 0.9727 - val_loss: 12.1456 - val_accuracy: 0.1043\n","Epoch 74/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0773 - accuracy: 0.9729 - val_loss: 14.2887 - val_accuracy: 0.1029\n","Epoch 75/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0772 - accuracy: 0.9728 - val_loss: 13.4612 - val_accuracy: 0.1055\n","Epoch 76/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0752 - accuracy: 0.9740 - val_loss: 14.2769 - val_accuracy: 0.1069\n","Epoch 77/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0760 - accuracy: 0.9734 - val_loss: 13.8807 - val_accuracy: 0.1064\n","Epoch 78/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0800 - accuracy: 0.9723 - val_loss: 11.9733 - val_accuracy: 0.1088\n","Epoch 79/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0746 - accuracy: 0.9744 - val_loss: 12.5395 - val_accuracy: 0.1117\n","Epoch 80/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0754 - accuracy: 0.9736 - val_loss: 13.0593 - val_accuracy: 0.1087\n","Epoch 81/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0763 - accuracy: 0.9737 - val_loss: 13.5033 - val_accuracy: 0.1090\n","Epoch 82/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0751 - accuracy: 0.9735 - val_loss: 12.6569 - val_accuracy: 0.1061\n","Epoch 83/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0738 - accuracy: 0.9746 - val_loss: 13.6025 - val_accuracy: 0.1049\n","Epoch 84/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0751 - accuracy: 0.9740 - val_loss: 15.1547 - val_accuracy: 0.1135\n","Epoch 85/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0719 - accuracy: 0.9749 - val_loss: 14.4619 - val_accuracy: 0.1125\n","Epoch 86/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0706 - accuracy: 0.9755 - val_loss: 15.5033 - val_accuracy: 0.1098\n","Epoch 87/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0718 - accuracy: 0.9743 - val_loss: 12.6749 - val_accuracy: 0.1410\n","Epoch 88/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 13.1798 - val_accuracy: 0.1254\n","Epoch 89/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0715 - accuracy: 0.9751 - val_loss: 13.2183 - val_accuracy: 0.1039\n","Epoch 90/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0691 - accuracy: 0.9751 - val_loss: 13.4501 - val_accuracy: 0.1135\n","Epoch 91/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0711 - accuracy: 0.9745 - val_loss: 14.2746 - val_accuracy: 0.1090\n","Epoch 92/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0695 - accuracy: 0.9760 - val_loss: 13.3478 - val_accuracy: 0.1057\n","Epoch 93/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0694 - accuracy: 0.9754 - val_loss: 17.7834 - val_accuracy: 0.1034\n","Epoch 94/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0708 - accuracy: 0.9746 - val_loss: 15.8009 - val_accuracy: 0.1035\n","Epoch 95/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0679 - accuracy: 0.9757 - val_loss: 14.4219 - val_accuracy: 0.1362\n","Epoch 96/100\n","391/391 [==============================] - 15s 40ms/step - loss: 0.0696 - accuracy: 0.9758 - val_loss: 15.9805 - val_accuracy: 0.1058\n","Epoch 97/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0698 - accuracy: 0.9755 - val_loss: 19.5676 - val_accuracy: 0.1049\n","Epoch 98/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0678 - accuracy: 0.9760 - val_loss: 15.4916 - val_accuracy: 0.1100\n","Epoch 99/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0671 - accuracy: 0.9753 - val_loss: 23.1188 - val_accuracy: 0.1040\n","Epoch 100/100\n","391/391 [==============================] - 17s 43ms/step - loss: 0.0662 - accuracy: 0.9764 - val_loss: 17.2787 - val_accuracy: 0.1057\n","Accuracy of model 5:  0.10570000112056732\n","Epoch 1/100\n","391/391 [==============================] - 17s 36ms/step - loss: 2.5180 - accuracy: 0.1647 - val_loss: 2.7727 - val_accuracy: 0.1001\n","Epoch 2/100\n","391/391 [==============================] - 13s 33ms/step - loss: 2.0633 - accuracy: 0.2383 - val_loss: 2.3753 - val_accuracy: 0.1016\n","Epoch 3/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.9697 - accuracy: 0.2725 - val_loss: 2.2979 - val_accuracy: 0.1321\n","Epoch 4/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.9141 - accuracy: 0.2957 - val_loss: 2.3152 - val_accuracy: 0.1035\n","Epoch 5/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.8767 - accuracy: 0.3104 - val_loss: 3.2693 - val_accuracy: 0.1000\n","Epoch 6/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.8569 - accuracy: 0.3169 - val_loss: 2.3104 - val_accuracy: 0.1149\n","Epoch 7/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.8271 - accuracy: 0.3270 - val_loss: 2.4102 - val_accuracy: 0.1255\n","Epoch 8/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.7941 - accuracy: 0.3409 - val_loss: 2.5846 - val_accuracy: 0.1021\n","Epoch 9/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.7837 - accuracy: 0.3440 - val_loss: 3.3572 - val_accuracy: 0.1138\n","Epoch 10/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.7608 - accuracy: 0.3511 - val_loss: 2.6460 - val_accuracy: 0.1032\n","Epoch 11/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.7423 - accuracy: 0.3597 - val_loss: 2.6970 - val_accuracy: 0.1021\n","Epoch 12/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.7487 - accuracy: 0.3574 - val_loss: 4.0012 - val_accuracy: 0.1033\n","Epoch 13/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.7301 - accuracy: 0.3637 - val_loss: 2.7907 - val_accuracy: 0.1024\n","Epoch 14/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.7127 - accuracy: 0.3716 - val_loss: 3.2521 - val_accuracy: 0.1037\n","Epoch 15/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.7170 - accuracy: 0.3688 - val_loss: 3.7474 - val_accuracy: 0.1033\n","Epoch 16/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.7031 - accuracy: 0.3722 - val_loss: 4.5365 - val_accuracy: 0.0998\n","Epoch 17/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6907 - accuracy: 0.3792 - val_loss: 3.4106 - val_accuracy: 0.1068\n","Epoch 18/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6834 - accuracy: 0.3839 - val_loss: 3.5686 - val_accuracy: 0.0992\n","Epoch 19/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6875 - accuracy: 0.3804 - val_loss: 3.9651 - val_accuracy: 0.1022\n","Epoch 20/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.6834 - accuracy: 0.3825 - val_loss: 4.5926 - val_accuracy: 0.1035\n","Epoch 21/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6803 - accuracy: 0.3809 - val_loss: 4.1512 - val_accuracy: 0.0991\n","Epoch 22/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6686 - accuracy: 0.3870 - val_loss: 3.8946 - val_accuracy: 0.1047\n","Epoch 23/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6763 - accuracy: 0.3846 - val_loss: 4.5212 - val_accuracy: 0.1000\n","Epoch 24/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6514 - accuracy: 0.3949 - val_loss: 4.2762 - val_accuracy: 0.0989\n","Epoch 25/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.6543 - accuracy: 0.3929 - val_loss: 3.8382 - val_accuracy: 0.1118\n","Epoch 26/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.6462 - accuracy: 0.3984 - val_loss: 3.7496 - val_accuracy: 0.1000\n","Epoch 27/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6394 - accuracy: 0.3990 - val_loss: 3.9294 - val_accuracy: 0.1034\n","Epoch 28/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6329 - accuracy: 0.4018 - val_loss: 4.8877 - val_accuracy: 0.1025\n","Epoch 29/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.6392 - accuracy: 0.4003 - val_loss: 4.1925 - val_accuracy: 0.1103\n","Epoch 30/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.6373 - accuracy: 0.4011 - val_loss: 3.8452 - val_accuracy: 0.1037\n","Epoch 31/100\n","391/391 [==============================] - 14s 37ms/step - loss: 1.6346 - accuracy: 0.4039 - val_loss: 3.7932 - val_accuracy: 0.1050\n","Epoch 32/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6314 - accuracy: 0.4036 - val_loss: 4.1999 - val_accuracy: 0.1035\n","Epoch 33/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6353 - accuracy: 0.4005 - val_loss: 5.1046 - val_accuracy: 0.1000\n","Epoch 34/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.6188 - accuracy: 0.4116 - val_loss: 4.6738 - val_accuracy: 0.1021\n","Epoch 35/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6084 - accuracy: 0.4148 - val_loss: 4.1872 - val_accuracy: 0.1031\n","Epoch 36/100\n","391/391 [==============================] - 14s 36ms/step - loss: 1.6276 - accuracy: 0.4073 - val_loss: 4.2119 - val_accuracy: 0.1035\n","Epoch 37/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6240 - accuracy: 0.4088 - val_loss: 3.9915 - val_accuracy: 0.1000\n","Epoch 38/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.6166 - accuracy: 0.4097 - val_loss: 3.7958 - val_accuracy: 0.1000\n","Epoch 39/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.6027 - accuracy: 0.4141 - val_loss: 3.8954 - val_accuracy: 0.1007\n","Epoch 40/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5962 - accuracy: 0.4192 - val_loss: 3.5457 - val_accuracy: 0.1000\n","Epoch 41/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5866 - accuracy: 0.4225 - val_loss: 4.0107 - val_accuracy: 0.1000\n","Epoch 42/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.6120 - accuracy: 0.4114 - val_loss: 4.1186 - val_accuracy: 0.1030\n","Epoch 43/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5929 - accuracy: 0.4222 - val_loss: 4.0879 - val_accuracy: 0.0994\n","Epoch 44/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5810 - accuracy: 0.4242 - val_loss: 4.1926 - val_accuracy: 0.0996\n","Epoch 45/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5891 - accuracy: 0.4234 - val_loss: 4.2679 - val_accuracy: 0.1000\n","Epoch 46/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5849 - accuracy: 0.4219 - val_loss: 3.4551 - val_accuracy: 0.1000\n","Epoch 47/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5667 - accuracy: 0.4325 - val_loss: 3.5326 - val_accuracy: 0.1041\n","Epoch 48/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5852 - accuracy: 0.4239 - val_loss: 4.2389 - val_accuracy: 0.0989\n","Epoch 49/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5832 - accuracy: 0.4251 - val_loss: 4.8282 - val_accuracy: 0.0989\n","Epoch 50/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5792 - accuracy: 0.4259 - val_loss: 4.8388 - val_accuracy: 0.0995\n","Epoch 51/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5674 - accuracy: 0.4291 - val_loss: 5.5302 - val_accuracy: 0.1000\n","Epoch 52/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5787 - accuracy: 0.4271 - val_loss: 4.6825 - val_accuracy: 0.1000\n","Epoch 53/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5662 - accuracy: 0.4320 - val_loss: 3.7429 - val_accuracy: 0.1000\n","Epoch 54/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5600 - accuracy: 0.4352 - val_loss: 4.3531 - val_accuracy: 0.1000\n","Epoch 55/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5751 - accuracy: 0.4287 - val_loss: 3.3170 - val_accuracy: 0.1000\n","Epoch 56/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5514 - accuracy: 0.4361 - val_loss: 5.3059 - val_accuracy: 0.0989\n","Epoch 57/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5599 - accuracy: 0.4358 - val_loss: 6.4521 - val_accuracy: 0.0996\n","Epoch 58/100\n","391/391 [==============================] - 14s 37ms/step - loss: 1.5561 - accuracy: 0.4362 - val_loss: 4.3758 - val_accuracy: 0.0996\n","Epoch 59/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5637 - accuracy: 0.4323 - val_loss: 4.7716 - val_accuracy: 0.0992\n","Epoch 60/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5602 - accuracy: 0.4341 - val_loss: 5.9069 - val_accuracy: 0.0996\n","Epoch 61/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5376 - accuracy: 0.4439 - val_loss: 5.0239 - val_accuracy: 0.1143\n","Epoch 62/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5636 - accuracy: 0.4317 - val_loss: 5.6713 - val_accuracy: 0.0996\n","Epoch 63/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5400 - accuracy: 0.4428 - val_loss: 6.0593 - val_accuracy: 0.1000\n","Epoch 64/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5477 - accuracy: 0.4376 - val_loss: 3.8436 - val_accuracy: 0.1000\n","Epoch 65/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5459 - accuracy: 0.4395 - val_loss: 4.4746 - val_accuracy: 0.0987\n","Epoch 66/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5351 - accuracy: 0.4442 - val_loss: 4.4455 - val_accuracy: 0.1000\n","Epoch 67/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5377 - accuracy: 0.4448 - val_loss: 4.3976 - val_accuracy: 0.0996\n","Epoch 68/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5353 - accuracy: 0.4446 - val_loss: 5.2299 - val_accuracy: 0.1000\n","Epoch 69/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5384 - accuracy: 0.4440 - val_loss: 5.4022 - val_accuracy: 0.0995\n","Epoch 70/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5493 - accuracy: 0.4399 - val_loss: 4.6265 - val_accuracy: 0.1000\n","Epoch 71/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5423 - accuracy: 0.4417 - val_loss: 4.0456 - val_accuracy: 0.0999\n","Epoch 72/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5326 - accuracy: 0.4452 - val_loss: 4.4446 - val_accuracy: 0.1202\n","Epoch 73/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5151 - accuracy: 0.4528 - val_loss: 4.0272 - val_accuracy: 0.1000\n","Epoch 74/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5142 - accuracy: 0.4531 - val_loss: 5.3006 - val_accuracy: 0.0997\n","Epoch 75/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5082 - accuracy: 0.4546 - val_loss: 4.4555 - val_accuracy: 0.1019\n","Epoch 76/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5212 - accuracy: 0.4506 - val_loss: 4.2965 - val_accuracy: 0.1037\n","Epoch 77/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5038 - accuracy: 0.4551 - val_loss: 4.3321 - val_accuracy: 0.1037\n","Epoch 78/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4813 - accuracy: 0.4641 - val_loss: 3.9307 - val_accuracy: 0.1054\n","Epoch 79/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.5009 - accuracy: 0.4570 - val_loss: 3.9426 - val_accuracy: 0.1043\n","Epoch 80/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4839 - accuracy: 0.4646 - val_loss: 3.9588 - val_accuracy: 0.1042\n","Epoch 81/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.4760 - accuracy: 0.4666 - val_loss: 3.8996 - val_accuracy: 0.0990\n","Epoch 82/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4950 - accuracy: 0.4612 - val_loss: 3.8570 - val_accuracy: 0.1173\n","Epoch 83/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4794 - accuracy: 0.4653 - val_loss: 3.9767 - val_accuracy: 0.1020\n","Epoch 84/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4717 - accuracy: 0.4683 - val_loss: 4.4343 - val_accuracy: 0.1046\n","Epoch 85/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4682 - accuracy: 0.4710 - val_loss: 4.2839 - val_accuracy: 0.1034\n","Epoch 86/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4950 - accuracy: 0.4604 - val_loss: 4.5269 - val_accuracy: 0.1032\n","Epoch 87/100\n","391/391 [==============================] - 14s 36ms/step - loss: 1.4905 - accuracy: 0.4603 - val_loss: 4.2458 - val_accuracy: 0.1032\n","Epoch 88/100\n","391/391 [==============================] - 13s 33ms/step - loss: 1.5162 - accuracy: 0.4531 - val_loss: 3.9058 - val_accuracy: 0.1033\n","Epoch 89/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4838 - accuracy: 0.4635 - val_loss: 3.6246 - val_accuracy: 0.1033\n","Epoch 90/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4684 - accuracy: 0.4731 - val_loss: 3.4692 - val_accuracy: 0.1033\n","Epoch 91/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4619 - accuracy: 0.4718 - val_loss: 3.3558 - val_accuracy: 0.1025\n","Epoch 92/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4660 - accuracy: 0.4696 - val_loss: 3.1432 - val_accuracy: 0.1033\n","Epoch 93/100\n","391/391 [==============================] - 14s 37ms/step - loss: 1.4659 - accuracy: 0.4713 - val_loss: 3.0522 - val_accuracy: 0.1025\n","Epoch 94/100\n","391/391 [==============================] - 14s 37ms/step - loss: 1.4508 - accuracy: 0.4775 - val_loss: 2.9879 - val_accuracy: 0.1047\n","Epoch 95/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4644 - accuracy: 0.4723 - val_loss: 2.9909 - val_accuracy: 0.1034\n","Epoch 96/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4631 - accuracy: 0.4726 - val_loss: 3.2375 - val_accuracy: 0.1035\n","Epoch 97/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4631 - accuracy: 0.4755 - val_loss: 3.0680 - val_accuracy: 0.1035\n","Epoch 98/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4602 - accuracy: 0.4741 - val_loss: 3.5701 - val_accuracy: 0.1054\n","Epoch 99/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4586 - accuracy: 0.4745 - val_loss: 3.5353 - val_accuracy: 0.1032\n","Epoch 100/100\n","391/391 [==============================] - 13s 34ms/step - loss: 1.4597 - accuracy: 0.4742 - val_loss: 2.8333 - val_accuracy: 0.1032\n","Accuracy of model 6:  0.10320000350475311\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lohtumcD_XfB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626694314865,"user_tz":-330,"elapsed":34,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"2522b9d5-bda9-4705-aa76-4a08498ed7e7"},"source":["accuracies_time"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0.7401999831199646, 425.40002884864805),\n"," (0.7325999736785889, 638.1000432729721),\n"," (0.7598999738693237, 850.8000576972961),\n"," (0.7581999897956848, 1063.5000721216202),\n"," (0.7702999711036682, 1276.2000865459443),\n"," (0.7685999870300293, 1488.9001009702683),\n"," (0.7663000226020813, 1701.6001153945922),\n"," (0.7709000110626221, 1914.3001298189163),\n"," (0.7700999975204468, 2127.0001442432404),\n"," (0.6958000063896179, 389.2349425792694),\n"," (0.7232000231742859, 583.8524138689041),\n"," (0.7231000065803528, 778.4698851585388),\n"," (0.7182999849319458, 973.0873564481735),\n"," (0.7210000157356262, 1167.7048277378083),\n"," (0.7232000231742859, 1362.322299027443),\n"," (0.7279000282287598, 1556.9397703170775),\n"," (0.7199000120162964, 1751.5572416067123),\n"," (0.7318999767303467, 1946.174712896347),\n"," (0.7745000123977661, 363.29851880073545),\n"," (0.7738999724388123, 544.9477782011032),\n"," (0.7785999774932861, 726.5970376014709),\n"," (0.7724999785423279, 908.2462970018387),\n"," (0.777999997138977, 1089.8955564022065),\n"," (0.7749999761581421, 1271.5448158025742),\n"," (0.777999997138977, 1453.1940752029418),\n"," (0.7800999879837036, 1634.8433346033096),\n"," (0.7839999794960022, 1816.4925940036774),\n"," (0.7524999976158142, 353.1070746898651),\n"," (0.7523000240325928, 529.6606120347976),\n"," (0.7549999952316284, 706.2141493797302),\n"," (0.753000020980835, 882.7676867246628),\n"," (0.7577000260353088, 1059.3212240695952),\n"," (0.7526999711990356, 1235.874761414528),\n"," (0.7565000057220459, 1412.4282987594604),\n"," (0.7544999718666077, 1588.981836104393),\n"," (0.758400022983551, 1765.5353734493256),\n"," (0.1437000036239624, 317.0882082462311),\n"," (0.1031000018119812, 475.6323123693466),\n"," (0.12330000102519989, 634.1764164924622),\n"," (0.10239999741315842, 792.7205206155777),\n"," (0.10939999669790268, 951.2646247386932),\n"," (0.10360000282526016, 1109.8087288618087),\n"," (0.10869999974966049, 1268.3528329849244),\n"," (0.11349999904632568, 1426.8969371080398),\n"," (0.10570000112056732, 1585.4410412311554),\n"," (0.10350000113248825, 269.0303942680359),\n"," (0.10369999706745148, 403.54559140205384),\n"," (0.10000000149011612, 538.0607885360718),\n"," (0.09950000047683716, 672.5759856700897),\n"," (0.09960000216960907, 807.0911828041077),\n"," (0.10000000149011612, 941.6063799381257),\n"," (0.10419999808073044, 1076.1215770721435),\n"," (0.10329999774694443, 1210.6367742061616),\n"," (0.10320000350475311, 1345.1519713401794)]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Krvll-MEjS5v","executionInfo":{"status":"ok","timestamp":1624214868188,"user_tz":-330,"elapsed":386076,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"8d9b5cd8-a2b3-4427-b57b-2006483d6b73"},"source":["model.load_weights(\"/ResNet50/EarlyExit_till_exit6_weights.h5\", by_name=True)\n","for layer in range(exits[5] + 1):\n","    model.layers[layer].trainable = False\n","model.summary()\n","model.compile(\n","        optimizer='adam',\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy']\n",")\n","history = model.fit(\n","    x=x_train,\n","    y=y_train,\n","    epochs=20,\n","    verbose=1,\n","    validation_data=(x_test, y_test),\n","    batch_size=128\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 2048)         0           conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1024)         2098176     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 10)           5130        dense_1[0][0]                    \n","==================================================================================================\n","Total params: 26,215,818\n","Trainable params: 17,604,106\n","Non-trainable params: 8,611,712\n","__________________________________________________________________________________________________\n","Epoch 1/20\n","391/391 [==============================] - 20s 44ms/step - loss: 1.2839 - accuracy: 0.5459 - val_loss: 3.4225 - val_accuracy: 0.2047\n","Epoch 2/20\n","391/391 [==============================] - 16s 42ms/step - loss: 1.2585 - accuracy: 0.5549 - val_loss: 3.8895 - val_accuracy: 0.1474\n","Epoch 3/20\n","391/391 [==============================] - 16s 42ms/step - loss: 1.2485 - accuracy: 0.5556 - val_loss: 2.1729 - val_accuracy: 0.3014\n","Epoch 4/20\n","391/391 [==============================] - 16s 42ms/step - loss: 1.2355 - accuracy: 0.5624 - val_loss: 3.5774 - val_accuracy: 0.1617\n","Epoch 5/20\n","391/391 [==============================] - 17s 45ms/step - loss: 1.2050 - accuracy: 0.5741 - val_loss: 3.7118 - val_accuracy: 0.1735\n","Epoch 6/20\n","391/391 [==============================] - 17s 42ms/step - loss: 1.1970 - accuracy: 0.5794 - val_loss: 3.4278 - val_accuracy: 0.2226\n","Epoch 7/20\n","391/391 [==============================] - 17s 45ms/step - loss: 1.1591 - accuracy: 0.5883 - val_loss: 4.0701 - val_accuracy: 0.1960\n","Epoch 8/20\n","391/391 [==============================] - 17s 42ms/step - loss: 1.1326 - accuracy: 0.5998 - val_loss: 2.7970 - val_accuracy: 0.2460\n","Epoch 9/20\n","391/391 [==============================] - 17s 42ms/step - loss: 1.1023 - accuracy: 0.6121 - val_loss: 4.4391 - val_accuracy: 0.1797\n","Epoch 10/20\n","391/391 [==============================] - 17s 42ms/step - loss: 1.0571 - accuracy: 0.6260 - val_loss: 4.2634 - val_accuracy: 0.1897\n","Epoch 11/20\n","391/391 [==============================] - 18s 45ms/step - loss: 0.9725 - accuracy: 0.6588 - val_loss: 6.7468 - val_accuracy: 0.1498\n","Epoch 12/20\n","391/391 [==============================] - 17s 45ms/step - loss: 0.9113 - accuracy: 0.6813 - val_loss: 6.5149 - val_accuracy: 0.1641\n","Epoch 13/20\n","391/391 [==============================] - 18s 45ms/step - loss: 0.8538 - accuracy: 0.7006 - val_loss: 12.1985 - val_accuracy: 0.1461\n","Epoch 14/20\n","391/391 [==============================] - 17s 42ms/step - loss: 0.8288 - accuracy: 0.7094 - val_loss: 6.7368 - val_accuracy: 0.1840\n","Epoch 15/20\n","391/391 [==============================] - 17s 42ms/step - loss: 0.8424 - accuracy: 0.7053 - val_loss: 11.1565 - val_accuracy: 0.1492\n","Epoch 16/20\n","391/391 [==============================] - 17s 45ms/step - loss: 0.7941 - accuracy: 0.7224 - val_loss: 7.4428 - val_accuracy: 0.1557\n","Epoch 17/20\n","391/391 [==============================] - 17s 42ms/step - loss: 0.7549 - accuracy: 0.7363 - val_loss: 7.9603 - val_accuracy: 0.1542\n","Epoch 18/20\n","391/391 [==============================] - 17s 42ms/step - loss: 0.7538 - accuracy: 0.7379 - val_loss: 8.7070 - val_accuracy: 0.1481\n","Epoch 19/20\n","391/391 [==============================] - 18s 45ms/step - loss: 0.7309 - accuracy: 0.7452 - val_loss: 9.1165 - val_accuracy: 0.1513\n","Epoch 20/20\n","391/391 [==============================] - 16s 42ms/step - loss: 0.7129 - accuracy: 0.7534 - val_loss: 8.4258 - val_accuracy: 0.1462\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-_CsoEqouOu_"},"source":[""],"execution_count":null,"outputs":[]}]}