{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment 2.ipynb","provenance":[{"file_id":"1qQ_0RaSDUXo_uEbw1vvx3nPGsLtg7iBu","timestamp":1623870104154},{"file_id":"1cGXeoDEMw72Qwq_JddSrkccvR6jR01V_","timestamp":1622991507291}],"collapsed_sections":[],"mount_file_id":"1Tq_HhnSsXthmvK4OgbHCdJZSsDLhD9VT","authorship_tag":"ABX9TyOm10e1qVewpYJ+KplEmnIJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iA1lWtoCvBnP"},"source":["### **HERE EXIT NETWORKS HAVE BEEN ADDED IN ResNet50 NETWORK**"]},{"cell_type":"code","metadata":{"id":"EhRVl-j9XISJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626678809929,"user_tz":-330,"elapsed":7406,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"3b9253a1-47d9-4417-b3c7-65b92bd4c33b"},"source":["from tensorflow.keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSpWlE_jfAFQ","executionInfo":{"status":"ok","timestamp":1626678814806,"user_tz":-330,"elapsed":4882,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"add3d245-ef6e-47d3-b87d-381c00573e4e"},"source":["# example of loading the MobileNet model\n","from keras.applications.resnet50 import ResNet50\n","model = ResNet50(include_top=False, weights= None, input_shape=(32, 32, 3))\n","# summarize the model\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"resnet50\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n","==================================================================================================\n","Total params: 23,587,712\n","Trainable params: 23,534,592\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWPVP0KFNY_P","executionInfo":{"status":"ok","timestamp":1626678814807,"user_tz":-330,"elapsed":25,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"0aab9309-2d74-4f82-f1e3-95a8d8fcedc6"},"source":["len(model.layers)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["175"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"6enOD5B6OAiZ"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYrda208Nh56"},"source":["exits = [6, 38, 60, 80, 112, 142]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p9tH_ROcvkFj"},"source":["## **ADDITION OF EXIT NETWORK**"]},{"cell_type":"code","metadata":{"id":"5AzuwnTDSOSf"},"source":["exit_layer1 = model.layers[6]\n","exit_layer2 = model.layers[38]\n","exit_layer3 = model.layers[60]\n","exit_layer4 = model.layers[80]\n","exit_layer5 = model.layers[112]\n","exit_layer6 = model.layers[142]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vII6zf4pNIK"},"source":["exit_models = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DeJahSRq07MG","executionInfo":{"status":"ok","timestamp":1626678814809,"user_tz":-330,"elapsed":13,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"10ad8806-8aba-4a8a-ab47-0bf511357271"},"source":["exit_layer1.output_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 8, 8, 64)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gz-OYNBTdRO","executionInfo":{"status":"ok","timestamp":1626678814810,"user_tz":-330,"elapsed":12,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"b5031df9-f95c-44ed-dd03-81bed4dcf725"},"source":["conv1 = Conv2D(128, (3,3), padding='same', activation='relu')(exit_layer1.output)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((3,3), strides=(3,3))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model1 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model1)\n","exit_model1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1_pad (ZeroPadding2D)    (None, 38, 38, 3)         0         \n","_________________________________________________________________\n","conv1_conv (Conv2D)          (None, 16, 16, 64)        9472      \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv1_relu (Activation)      (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","pool1_pad (ZeroPadding2D)    (None, 18, 18, 64)        0         \n","_________________________________________________________________\n","pool1_pool (MaxPooling2D)    (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 8, 8, 128)         73856     \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               65664     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 150,538\n","Trainable params: 150,410\n","Non-trainable params: 128\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IM2PVMio17OU","executionInfo":{"status":"ok","timestamp":1626678814810,"user_tz":-330,"elapsed":9,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"985ca317-fca1-4d4a-f5f6-b202b0fc765d"},"source":["exit_layer2.output_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 8, 8, 256)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5OL3CceSEEL","executionInfo":{"status":"ok","timestamp":1626678815522,"user_tz":-330,"elapsed":719,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"5fc9a345-75a5-45ef-e3b4-19a111a9e401"},"source":["pool1 = MaxPooling2D((3,3), strides=(3,3))(exit_layer2.output)\n","conv1 = Conv2D(512, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model2 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model2)\n","exit_model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 2, 2, 256)    0           conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 2, 2, 512)    1180160     max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 512)          0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 128)          65664       flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 10)           1290        dense_2[0][0]                    \n","==================================================================================================\n","Total params: 1,476,874\n","Trainable params: 1,473,930\n","Non-trainable params: 2,944\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmLfm9KM8GO7","executionInfo":{"status":"ok","timestamp":1626678815523,"user_tz":-330,"elapsed":54,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"cefbd77c-da65-453e-a2de-d44d079fd393"},"source":["exit_layer3.output_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 4, 4, 512)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jW--RdXSSfj","executionInfo":{"status":"ok","timestamp":1626678815524,"user_tz":-330,"elapsed":51,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"be70752d-fcee-4b0d-89e2-66dc56944eef"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer3.output)\n","conv1 = Conv2D(1024, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(512, activation='relu')(flat1)\n","class2 = Dense(128, activation='relu')(class1)\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","exit_model3 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model3)\n","exit_model3.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 512)    0           conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 2, 2, 1024)   4719616     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 1024)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 1024)         0           max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 128)          65664       dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 10)           1290        dense_5[0][0]                    \n","==================================================================================================\n","Total params: 6,206,730\n","Trainable params: 6,199,690\n","Non-trainable params: 7,040\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EZh_IuU9j78","executionInfo":{"status":"ok","timestamp":1626678815524,"user_tz":-330,"elapsed":49,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"be113ef5-877e-4f08-8239-252eee01fb01"},"source":["exit_layer4.output_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 4, 4, 512)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XwmZ_Ntorkl","executionInfo":{"status":"ok","timestamp":1626678815525,"user_tz":-330,"elapsed":44,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"93aebdfb-f655-4ac2-df9e-30030d369dbe"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer4.output)\n","conv1 = Conv2D(1024, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(512, activation='relu')(flat1)\n","class2 = Dense(128, activation='relu')(class1)\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","exit_model4 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model4)\n","exit_model4.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 512)    0           conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 2, 2, 1024)   4719616     max_pooling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 1024)   0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 1024)         0           max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 512)          524800      flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 128)          65664       dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 10)           1290        dense_8[0][0]                    \n","==================================================================================================\n","Total params: 6,771,466\n","Trainable params: 6,761,354\n","Non-trainable params: 10,112\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcrG8b6b907O","executionInfo":{"status":"ok","timestamp":1626678815525,"user_tz":-330,"elapsed":42,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"b4f8bd67-4b45-465c-d70e-c693dcc86b3c"},"source":["exit_layer5.output_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 2, 2, 1024)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uii5hgYt901-","executionInfo":{"status":"ok","timestamp":1626678815526,"user_tz":-330,"elapsed":36,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"71099050-02f9-4896-875f-73eef0b38bb9"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer5.output)\n","#conv1 = Conv2D(1024, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","#pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool1)\n","class1 = Dense(512, activation='relu')(flat1)\n","class2 = Dense(128, activation='relu')(class1)\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","exit_model5 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model5)\n","exit_model5.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 1024)   0           conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 1024)         0           max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 512)          524800      flatten_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 128)          65664       dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 10)           1290        dense_11[0][0]                   \n","==================================================================================================\n","Total params: 5,815,562\n","Trainable params: 5,794,186\n","Non-trainable params: 21,376\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RL6_cBYn90tr","executionInfo":{"status":"ok","timestamp":1626678815527,"user_tz":-330,"elapsed":33,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"44640bbd-beda-48e5-9359-cc83ff3cb7dc"},"source":["exit_layer6.output_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 2, 2, 1024)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-lEmcDc90NI","executionInfo":{"status":"ok","timestamp":1626678815527,"user_tz":-330,"elapsed":25,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"f031c7eb-8ef7-49b6-e01a-6b7fcdea777d"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer6.output)\n","#conv1 = Conv2D(1024, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","#pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool1)\n","class1 = Dense(512, activation='relu')(flat1)\n","class2 = Dense(128, activation='relu')(class1)\n","prediction = Dense(10, activation='softmax')(class2)\n","\n","exit_model6 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model6)\n","exit_model6.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 1024)   0           conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","flatten_5 (Flatten)             (None, 1024)         0           max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","dense_13 (Dense)                (None, 512)          524800      flatten_5[0][0]                  \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 128)          65664       dense_13[0][0]                   \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 10)           1290        dense_14[0][0]                   \n","==================================================================================================\n","Total params: 9,180,938\n","Trainable params: 9,150,346\n","Non-trainable params: 30,592\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDdgNEwKpf_8","executionInfo":{"status":"ok","timestamp":1626678815528,"user_tz":-330,"elapsed":23,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"d50a0c0b-8a68-4a61-a013-3d53eb8f5d5b"},"source":["exit_models"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tensorflow.python.keras.engine.functional.Functional at 0x7f58a05f1790>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f58a031ef10>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f58a0374bd0>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f58a02efc90>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f58a0301e50>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f58a0295190>]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"qs5OkuHGkCcX"},"source":["for model in exit_models:\n","  model.compile(\n","          optimizer='adam',\n","          loss='sparse_categorical_crossentropy',\n","          metrics=['accuracy']\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5F2Ip_4HnObI"},"source":["import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5GvpA1ElIqe","executionInfo":{"status":"ok","timestamp":1626684222123,"user_tz":-330,"elapsed":5306231,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"4ee1747b-4a45-41d1-e83a-fb1dbd037c2c"},"source":["i = 1\n","accuracies_time = []\n","for model in exit_models:\n","  start = time.time()\n","  history = model.fit(\n","      x=x_train,\n","      y=y_train,\n","      epochs=100,\n","      verbose=1,\n","      validation_data=(x_test, y_test),\n","      batch_size=128\n","  )\n","  end = time.time()\n","  Model(inputs = model.inputs, outputs = model.layers[exits[i-1]].output).save_weights(f\"/ResNet50/EarlyExit_till_exit{i}_weights.h5\")\n","  print(\"Saved!\")\n","  accuracies_time.append(((history.history.get('val_accuracy')[19]), (end-start)*2/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[29]), (end-start)*3/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[39]), (end-start)*4/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[49]), (end-start)*5/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[59]), (end-start)*6/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[69]), (end-start)*7/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[79]), (end-start)*8/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[89]), (end-start)*9/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[99]), (end-start)*10/10))\n","  print(f\"Accuracy of model {i}: \", history.history.get('val_accuracy')[len(history.history.get('val_accuracy')) - 1])\n","  i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","391/391 [==============================] - 17s 5ms/step - loss: 1.5289 - accuracy: 0.4468 - val_loss: 1.2938 - val_accuracy: 0.5327\n","Epoch 2/100\n","391/391 [==============================] - 2s 4ms/step - loss: 1.1855 - accuracy: 0.5814 - val_loss: 1.1940 - val_accuracy: 0.5692\n","Epoch 3/100\n","391/391 [==============================] - 2s 4ms/step - loss: 1.0384 - accuracy: 0.6358 - val_loss: 1.1041 - val_accuracy: 0.6075\n","Epoch 4/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.9436 - accuracy: 0.6701 - val_loss: 1.1313 - val_accuracy: 0.6165\n","Epoch 5/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.8741 - accuracy: 0.6961 - val_loss: 0.9876 - val_accuracy: 0.6580\n","Epoch 6/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.8215 - accuracy: 0.7144 - val_loss: 1.0982 - val_accuracy: 0.6289\n","Epoch 7/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.7738 - accuracy: 0.7308 - val_loss: 0.9742 - val_accuracy: 0.6628\n","Epoch 8/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.7254 - accuracy: 0.7469 - val_loss: 0.9843 - val_accuracy: 0.6573\n","Epoch 9/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.6948 - accuracy: 0.7580 - val_loss: 1.1941 - val_accuracy: 0.6309\n","Epoch 10/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.6562 - accuracy: 0.7699 - val_loss: 1.0277 - val_accuracy: 0.6761\n","Epoch 11/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.6210 - accuracy: 0.7801 - val_loss: 1.1853 - val_accuracy: 0.6316\n","Epoch 12/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.5940 - accuracy: 0.7918 - val_loss: 0.9417 - val_accuracy: 0.6874\n","Epoch 13/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.7998 - val_loss: 1.0111 - val_accuracy: 0.6781\n","Epoch 14/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.5347 - accuracy: 0.8115 - val_loss: 0.9123 - val_accuracy: 0.7067\n","Epoch 15/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.5122 - accuracy: 0.8190 - val_loss: 0.9460 - val_accuracy: 0.7025\n","Epoch 16/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4844 - accuracy: 0.8287 - val_loss: 0.9031 - val_accuracy: 0.7144\n","Epoch 17/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4606 - accuracy: 0.8378 - val_loss: 0.9145 - val_accuracy: 0.7152\n","Epoch 18/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4351 - accuracy: 0.8458 - val_loss: 1.0154 - val_accuracy: 0.7001\n","Epoch 19/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4198 - accuracy: 0.8515 - val_loss: 0.9455 - val_accuracy: 0.7136\n","Epoch 20/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3992 - accuracy: 0.8573 - val_loss: 1.0359 - val_accuracy: 0.6980\n","Epoch 21/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3778 - accuracy: 0.8665 - val_loss: 1.0117 - val_accuracy: 0.7068\n","Epoch 22/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.8720 - val_loss: 1.1330 - val_accuracy: 0.6809\n","Epoch 23/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3308 - accuracy: 0.8820 - val_loss: 1.1130 - val_accuracy: 0.6921\n","Epoch 24/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3236 - accuracy: 0.8843 - val_loss: 1.2171 - val_accuracy: 0.6856\n","Epoch 25/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.3008 - accuracy: 0.8928 - val_loss: 1.0894 - val_accuracy: 0.7148\n","Epoch 26/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2896 - accuracy: 0.8957 - val_loss: 1.1479 - val_accuracy: 0.7005\n","Epoch 27/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2726 - accuracy: 0.9013 - val_loss: 1.1523 - val_accuracy: 0.7091\n","Epoch 28/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2657 - accuracy: 0.9039 - val_loss: 1.2033 - val_accuracy: 0.7007\n","Epoch 29/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2454 - accuracy: 0.9114 - val_loss: 1.2228 - val_accuracy: 0.7047\n","Epoch 30/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2228 - accuracy: 0.9195 - val_loss: 1.3161 - val_accuracy: 0.6923\n","Epoch 31/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2143 - accuracy: 0.9232 - val_loss: 1.3938 - val_accuracy: 0.6840\n","Epoch 32/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2042 - accuracy: 0.9274 - val_loss: 1.4734 - val_accuracy: 0.6762\n","Epoch 33/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1980 - accuracy: 0.9281 - val_loss: 1.4167 - val_accuracy: 0.6894\n","Epoch 34/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1868 - accuracy: 0.9321 - val_loss: 1.4408 - val_accuracy: 0.7048\n","Epoch 35/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1731 - accuracy: 0.9377 - val_loss: 1.4737 - val_accuracy: 0.7031\n","Epoch 36/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1562 - accuracy: 0.9439 - val_loss: 1.5269 - val_accuracy: 0.6931\n","Epoch 37/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1608 - accuracy: 0.9414 - val_loss: 1.6450 - val_accuracy: 0.6899\n","Epoch 38/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1549 - accuracy: 0.9439 - val_loss: 1.5526 - val_accuracy: 0.6985\n","Epoch 39/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1468 - accuracy: 0.9474 - val_loss: 1.7047 - val_accuracy: 0.6871\n","Epoch 40/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1400 - accuracy: 0.9505 - val_loss: 1.8078 - val_accuracy: 0.6756\n","Epoch 41/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1308 - accuracy: 0.9523 - val_loss: 1.5988 - val_accuracy: 0.7046\n","Epoch 42/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1195 - accuracy: 0.9564 - val_loss: 1.7250 - val_accuracy: 0.6970\n","Epoch 43/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1273 - accuracy: 0.9529 - val_loss: 1.9250 - val_accuracy: 0.6769\n","Epoch 44/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1258 - accuracy: 0.9533 - val_loss: 1.8118 - val_accuracy: 0.6864\n","Epoch 45/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1108 - accuracy: 0.9599 - val_loss: 1.8744 - val_accuracy: 0.6886\n","Epoch 46/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1167 - accuracy: 0.9571 - val_loss: 1.8394 - val_accuracy: 0.6912\n","Epoch 47/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1028 - accuracy: 0.9638 - val_loss: 2.0833 - val_accuracy: 0.6680\n","Epoch 48/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0994 - accuracy: 0.9641 - val_loss: 1.8301 - val_accuracy: 0.7044\n","Epoch 49/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1108 - accuracy: 0.9601 - val_loss: 1.9116 - val_accuracy: 0.6994\n","Epoch 50/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1075 - accuracy: 0.9615 - val_loss: 1.9073 - val_accuracy: 0.6973\n","Epoch 51/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0955 - accuracy: 0.9658 - val_loss: 2.0703 - val_accuracy: 0.6791\n","Epoch 52/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0896 - accuracy: 0.9674 - val_loss: 1.9437 - val_accuracy: 0.7064\n","Epoch 53/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0830 - accuracy: 0.9705 - val_loss: 2.0726 - val_accuracy: 0.7016\n","Epoch 54/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0897 - accuracy: 0.9685 - val_loss: 2.3080 - val_accuracy: 0.6703\n","Epoch 55/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1019 - accuracy: 0.9640 - val_loss: 2.0259 - val_accuracy: 0.6950\n","Epoch 56/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0888 - accuracy: 0.9692 - val_loss: 2.1154 - val_accuracy: 0.6923\n","Epoch 57/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0718 - accuracy: 0.9744 - val_loss: 2.1178 - val_accuracy: 0.7023\n","Epoch 58/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0722 - accuracy: 0.9741 - val_loss: 2.1724 - val_accuracy: 0.6855\n","Epoch 59/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0956 - accuracy: 0.9656 - val_loss: 2.2919 - val_accuracy: 0.6898\n","Epoch 60/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0714 - accuracy: 0.9747 - val_loss: 2.2738 - val_accuracy: 0.6949\n","Epoch 61/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0863 - accuracy: 0.9689 - val_loss: 2.3301 - val_accuracy: 0.6905\n","Epoch 62/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0786 - accuracy: 0.9729 - val_loss: 2.1497 - val_accuracy: 0.6989\n","Epoch 63/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9737 - val_loss: 2.5444 - val_accuracy: 0.6813\n","Epoch 64/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0778 - accuracy: 0.9725 - val_loss: 2.2764 - val_accuracy: 0.6987\n","Epoch 65/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0777 - accuracy: 0.9723 - val_loss: 2.3973 - val_accuracy: 0.6874\n","Epoch 66/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0765 - accuracy: 0.9727 - val_loss: 2.4513 - val_accuracy: 0.6942\n","Epoch 67/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9744 - val_loss: 2.3871 - val_accuracy: 0.6854\n","Epoch 68/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0675 - accuracy: 0.9768 - val_loss: 2.5207 - val_accuracy: 0.6764\n","Epoch 69/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 2.5321 - val_accuracy: 0.7012\n","Epoch 70/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0671 - accuracy: 0.9761 - val_loss: 2.5030 - val_accuracy: 0.6911\n","Epoch 71/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0826 - accuracy: 0.9720 - val_loss: 2.7025 - val_accuracy: 0.6770\n","Epoch 72/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0679 - accuracy: 0.9760 - val_loss: 2.5942 - val_accuracy: 0.6907\n","Epoch 73/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0649 - accuracy: 0.9768 - val_loss: 2.3937 - val_accuracy: 0.6979\n","Epoch 74/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0646 - accuracy: 0.9779 - val_loss: 2.5235 - val_accuracy: 0.6953\n","Epoch 75/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0565 - accuracy: 0.9798 - val_loss: 2.4234 - val_accuracy: 0.6970\n","Epoch 76/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9743 - val_loss: 2.4727 - val_accuracy: 0.7087\n","Epoch 77/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9792 - val_loss: 2.6736 - val_accuracy: 0.6956\n","Epoch 78/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0476 - accuracy: 0.9825 - val_loss: 2.6181 - val_accuracy: 0.6965\n","Epoch 79/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0773 - accuracy: 0.9733 - val_loss: 2.6333 - val_accuracy: 0.7007\n","Epoch 80/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0666 - accuracy: 0.9773 - val_loss: 2.5618 - val_accuracy: 0.6947\n","Epoch 81/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9829 - val_loss: 2.6147 - val_accuracy: 0.6973\n","Epoch 82/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0785 - accuracy: 0.9730 - val_loss: 2.7533 - val_accuracy: 0.6870\n","Epoch 83/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0558 - accuracy: 0.9808 - val_loss: 2.6554 - val_accuracy: 0.6950\n","Epoch 84/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9851 - val_loss: 2.7638 - val_accuracy: 0.6933\n","Epoch 85/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0588 - accuracy: 0.9792 - val_loss: 2.7673 - val_accuracy: 0.6940\n","Epoch 86/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0841 - accuracy: 0.9714 - val_loss: 2.8127 - val_accuracy: 0.6853\n","Epoch 87/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0426 - accuracy: 0.9852 - val_loss: 2.6479 - val_accuracy: 0.7058\n","Epoch 88/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0537 - accuracy: 0.9821 - val_loss: 2.7591 - val_accuracy: 0.6908\n","Epoch 89/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9790 - val_loss: 2.6828 - val_accuracy: 0.7076\n","Epoch 90/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 3.1713 - val_accuracy: 0.6566\n","Epoch 91/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0604 - accuracy: 0.9792 - val_loss: 2.8758 - val_accuracy: 0.6897\n","Epoch 92/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0361 - accuracy: 0.9879 - val_loss: 2.9819 - val_accuracy: 0.6808\n","Epoch 93/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0570 - accuracy: 0.9814 - val_loss: 2.9905 - val_accuracy: 0.6764\n","Epoch 94/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9747 - val_loss: 2.8854 - val_accuracy: 0.6918\n","Epoch 95/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 2.8372 - val_accuracy: 0.6925\n","Epoch 96/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0433 - accuracy: 0.9852 - val_loss: 2.7801 - val_accuracy: 0.6966\n","Epoch 97/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9757 - val_loss: 2.8218 - val_accuracy: 0.6958\n","Epoch 98/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0491 - accuracy: 0.9830 - val_loss: 2.8168 - val_accuracy: 0.6970\n","Epoch 99/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.9846 - val_loss: 2.9495 - val_accuracy: 0.6892\n","Epoch 100/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0458 - accuracy: 0.9839 - val_loss: 3.1345 - val_accuracy: 0.6821\n","Saved!\n","Accuracy of model 1:  0.6820999979972839\n","Epoch 1/100\n","391/391 [==============================] - 6s 13ms/step - loss: 1.3921 - accuracy: 0.5203 - val_loss: 1.3874 - val_accuracy: 0.5206\n","Epoch 2/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.8246 - accuracy: 0.7100 - val_loss: 0.9229 - val_accuracy: 0.6846\n","Epoch 3/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.6716 - accuracy: 0.7658 - val_loss: 0.8217 - val_accuracy: 0.7189\n","Epoch 4/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.5592 - accuracy: 0.8031 - val_loss: 0.8378 - val_accuracy: 0.7096\n","Epoch 5/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.4701 - accuracy: 0.8359 - val_loss: 0.8529 - val_accuracy: 0.7163\n","Epoch 6/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.4044 - accuracy: 0.8584 - val_loss: 0.8445 - val_accuracy: 0.7304\n","Epoch 7/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.3372 - accuracy: 0.8812 - val_loss: 0.8736 - val_accuracy: 0.7394\n","Epoch 8/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.2863 - accuracy: 0.8991 - val_loss: 0.8588 - val_accuracy: 0.7486\n","Epoch 9/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.2387 - accuracy: 0.9148 - val_loss: 0.8841 - val_accuracy: 0.7560\n","Epoch 10/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1958 - accuracy: 0.9310 - val_loss: 0.9376 - val_accuracy: 0.7494\n","Epoch 11/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1732 - accuracy: 0.9379 - val_loss: 0.9342 - val_accuracy: 0.7541\n","Epoch 12/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1468 - accuracy: 0.9476 - val_loss: 0.9656 - val_accuracy: 0.7598\n","Epoch 13/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.1286 - accuracy: 0.9546 - val_loss: 1.0974 - val_accuracy: 0.7427\n","Epoch 14/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1168 - accuracy: 0.9581 - val_loss: 1.2702 - val_accuracy: 0.7390\n","Epoch 15/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1126 - accuracy: 0.9606 - val_loss: 1.1871 - val_accuracy: 0.7347\n","Epoch 16/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0966 - accuracy: 0.9662 - val_loss: 1.1722 - val_accuracy: 0.7467\n","Epoch 17/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0916 - accuracy: 0.9681 - val_loss: 1.1507 - val_accuracy: 0.7552\n","Epoch 18/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0775 - accuracy: 0.9731 - val_loss: 1.2410 - val_accuracy: 0.7544\n","Epoch 19/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0781 - accuracy: 0.9721 - val_loss: 1.1554 - val_accuracy: 0.7578\n","Epoch 20/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0803 - accuracy: 0.9713 - val_loss: 1.4895 - val_accuracy: 0.7282\n","Epoch 21/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0723 - accuracy: 0.9745 - val_loss: 1.3000 - val_accuracy: 0.7517\n","Epoch 22/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0652 - accuracy: 0.9770 - val_loss: 1.3715 - val_accuracy: 0.7610\n","Epoch 23/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 1.2652 - val_accuracy: 0.7536\n","Epoch 24/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0649 - accuracy: 0.9777 - val_loss: 1.5496 - val_accuracy: 0.7482\n","Epoch 25/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0625 - accuracy: 0.9784 - val_loss: 1.3331 - val_accuracy: 0.7423\n","Epoch 26/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0527 - accuracy: 0.9825 - val_loss: 1.3528 - val_accuracy: 0.7517\n","Epoch 27/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0612 - accuracy: 0.9787 - val_loss: 1.4109 - val_accuracy: 0.7549\n","Epoch 28/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0639 - accuracy: 0.9782 - val_loss: 1.3253 - val_accuracy: 0.7609\n","Epoch 29/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0550 - accuracy: 0.9800 - val_loss: 1.5216 - val_accuracy: 0.7465\n","Epoch 30/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 1.3061 - val_accuracy: 0.7703\n","Epoch 31/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0451 - accuracy: 0.9836 - val_loss: 1.4633 - val_accuracy: 0.7529\n","Epoch 32/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0578 - accuracy: 0.9801 - val_loss: 1.5939 - val_accuracy: 0.7492\n","Epoch 33/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0539 - accuracy: 0.9806 - val_loss: 1.2927 - val_accuracy: 0.7720\n","Epoch 34/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0429 - accuracy: 0.9853 - val_loss: 1.4042 - val_accuracy: 0.7615\n","Epoch 35/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 1.3317 - val_accuracy: 0.7667\n","Epoch 36/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0414 - accuracy: 0.9854 - val_loss: 1.3767 - val_accuracy: 0.7725\n","Epoch 37/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0490 - accuracy: 0.9831 - val_loss: 1.3110 - val_accuracy: 0.7721\n","Epoch 38/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 1.5203 - val_accuracy: 0.7545\n","Epoch 39/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 1.5448 - val_accuracy: 0.7553\n","Epoch 40/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0482 - accuracy: 0.9832 - val_loss: 1.4027 - val_accuracy: 0.7720\n","Epoch 41/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0385 - accuracy: 0.9864 - val_loss: 1.4456 - val_accuracy: 0.7565\n","Epoch 42/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 1.5207 - val_accuracy: 0.7624\n","Epoch 43/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0406 - accuracy: 0.9862 - val_loss: 1.4118 - val_accuracy: 0.7661\n","Epoch 44/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 1.4952 - val_accuracy: 0.7563\n","Epoch 45/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 1.4006 - val_accuracy: 0.7638\n","Epoch 46/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 1.9666 - val_accuracy: 0.7249\n","Epoch 47/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 1.4407 - val_accuracy: 0.7554\n","Epoch 48/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 1.6740 - val_accuracy: 0.7356\n","Epoch 49/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 1.5289 - val_accuracy: 0.7715\n","Epoch 50/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 1.4750 - val_accuracy: 0.7681\n","Epoch 51/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 1.4665 - val_accuracy: 0.7720\n","Epoch 52/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 1.6166 - val_accuracy: 0.7571\n","Epoch 53/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0371 - accuracy: 0.9879 - val_loss: 1.5993 - val_accuracy: 0.7565\n","Epoch 54/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0354 - accuracy: 0.9875 - val_loss: 1.4877 - val_accuracy: 0.7702\n","Epoch 55/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 1.4697 - val_accuracy: 0.7623\n","Epoch 56/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 1.4789 - val_accuracy: 0.7707\n","Epoch 57/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0271 - accuracy: 0.9910 - val_loss: 1.6919 - val_accuracy: 0.7428\n","Epoch 58/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 1.5168 - val_accuracy: 0.7628\n","Epoch 59/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 1.5611 - val_accuracy: 0.7676\n","Epoch 60/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0317 - accuracy: 0.9893 - val_loss: 1.6545 - val_accuracy: 0.7685\n","Epoch 61/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 1.5681 - val_accuracy: 0.7609\n","Epoch 62/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 2.3080 - val_accuracy: 0.6888\n","Epoch 63/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 1.5640 - val_accuracy: 0.7762\n","Epoch 64/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 1.4289 - val_accuracy: 0.7727\n","Epoch 65/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 1.6808 - val_accuracy: 0.7553\n","Epoch 66/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 1.6212 - val_accuracy: 0.7511\n","Epoch 67/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 1.5983 - val_accuracy: 0.7684\n","Epoch 68/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 1.5774 - val_accuracy: 0.7612\n","Epoch 69/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 1.7440 - val_accuracy: 0.7517\n","Epoch 70/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 1.6705 - val_accuracy: 0.7516\n","Epoch 71/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 1.6315 - val_accuracy: 0.7635\n","Epoch 72/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 1.7754 - val_accuracy: 0.7645\n","Epoch 73/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 1.7390 - val_accuracy: 0.7511\n","Epoch 74/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 1.6952 - val_accuracy: 0.7478\n","Epoch 75/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 1.7084 - val_accuracy: 0.7573\n","Epoch 76/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 1.6011 - val_accuracy: 0.7706\n","Epoch 77/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 1.7240 - val_accuracy: 0.7613\n","Epoch 78/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 1.6348 - val_accuracy: 0.7742\n","Epoch 79/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 1.6970 - val_accuracy: 0.7656\n","Epoch 80/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 1.6108 - val_accuracy: 0.7729\n","Epoch 81/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 1.7173 - val_accuracy: 0.7594\n","Epoch 82/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 1.6838 - val_accuracy: 0.7730\n","Epoch 83/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 1.7813 - val_accuracy: 0.7603\n","Epoch 84/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0280 - accuracy: 0.9902 - val_loss: 1.6120 - val_accuracy: 0.7676\n","Epoch 85/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0263 - accuracy: 0.9907 - val_loss: 1.8518 - val_accuracy: 0.7542\n","Epoch 86/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 1.6989 - val_accuracy: 0.7660\n","Epoch 87/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 1.5621 - val_accuracy: 0.7664\n","Epoch 88/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 1.6236 - val_accuracy: 0.7698\n","Epoch 89/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 1.7074 - val_accuracy: 0.7636\n","Epoch 90/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 1.5987 - val_accuracy: 0.7678\n","Epoch 91/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 2.0375 - val_accuracy: 0.7435\n","Epoch 92/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 1.6262 - val_accuracy: 0.7670\n","Epoch 93/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 1.5039 - val_accuracy: 0.7734\n","Epoch 94/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 1.6915 - val_accuracy: 0.7737\n","Epoch 95/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.9384 - val_accuracy: 0.7591\n","Epoch 96/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 1.7475 - val_accuracy: 0.7691\n","Epoch 97/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.6174 - val_accuracy: 0.7733\n","Epoch 98/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 1.8498 - val_accuracy: 0.7621\n","Epoch 99/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 1.7046 - val_accuracy: 0.7552\n","Epoch 100/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 1.7312 - val_accuracy: 0.7619\n","Saved!\n","Accuracy of model 2:  0.761900007724762\n","Epoch 1/100\n","391/391 [==============================] - 11s 23ms/step - loss: 1.5134 - accuracy: 0.5196 - val_loss: 1.0593 - val_accuracy: 0.6316\n","Epoch 2/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.5544 - accuracy: 0.8086 - val_loss: 0.6835 - val_accuracy: 0.7713\n","Epoch 3/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.3952 - accuracy: 0.8614 - val_loss: 0.9795 - val_accuracy: 0.7193\n","Epoch 4/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.2931 - accuracy: 0.8995 - val_loss: 0.8215 - val_accuracy: 0.7610\n","Epoch 5/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.2216 - accuracy: 0.9242 - val_loss: 0.9211 - val_accuracy: 0.7574\n","Epoch 6/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.1707 - accuracy: 0.9426 - val_loss: 1.0435 - val_accuracy: 0.7476\n","Epoch 7/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.1396 - accuracy: 0.9520 - val_loss: 1.0321 - val_accuracy: 0.7736\n","Epoch 8/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.1196 - accuracy: 0.9593 - val_loss: 1.1170 - val_accuracy: 0.7671\n","Epoch 9/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.1042 - accuracy: 0.9651 - val_loss: 1.1553 - val_accuracy: 0.7560\n","Epoch 10/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0935 - accuracy: 0.9694 - val_loss: 1.2642 - val_accuracy: 0.7547\n","Epoch 11/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0780 - accuracy: 0.9743 - val_loss: 1.1056 - val_accuracy: 0.7676\n","Epoch 12/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0782 - accuracy: 0.9741 - val_loss: 1.1465 - val_accuracy: 0.7571\n","Epoch 13/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0722 - accuracy: 0.9757 - val_loss: 1.2377 - val_accuracy: 0.7484\n","Epoch 14/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0639 - accuracy: 0.9788 - val_loss: 1.3053 - val_accuracy: 0.7720\n","Epoch 15/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0662 - accuracy: 0.9780 - val_loss: 1.2296 - val_accuracy: 0.7646\n","Epoch 16/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 1.4115 - val_accuracy: 0.7654\n","Epoch 17/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0585 - accuracy: 0.9812 - val_loss: 1.1601 - val_accuracy: 0.7749\n","Epoch 18/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0487 - accuracy: 0.9840 - val_loss: 1.3303 - val_accuracy: 0.7715\n","Epoch 19/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 1.3094 - val_accuracy: 0.7615\n","Epoch 20/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0528 - accuracy: 0.9825 - val_loss: 1.3007 - val_accuracy: 0.7693\n","Epoch 21/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 1.2718 - val_accuracy: 0.7726\n","Epoch 22/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0502 - accuracy: 0.9836 - val_loss: 1.2866 - val_accuracy: 0.7738\n","Epoch 23/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 1.2404 - val_accuracy: 0.7672\n","Epoch 24/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 1.2809 - val_accuracy: 0.7704\n","Epoch 25/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 1.3368 - val_accuracy: 0.7696\n","Epoch 26/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 1.4136 - val_accuracy: 0.7565\n","Epoch 27/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 1.5753 - val_accuracy: 0.7495\n","Epoch 28/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 1.4249 - val_accuracy: 0.7626\n","Epoch 29/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 1.3515 - val_accuracy: 0.7719\n","Epoch 30/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0414 - accuracy: 0.9873 - val_loss: 1.2735 - val_accuracy: 0.7601\n","Epoch 31/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 1.2807 - val_accuracy: 0.7755\n","Epoch 32/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 1.4538 - val_accuracy: 0.7754\n","Epoch 33/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 1.4545 - val_accuracy: 0.7628\n","Epoch 34/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 1.4642 - val_accuracy: 0.7679\n","Epoch 35/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 1.2932 - val_accuracy: 0.7819\n","Epoch 36/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 1.4074 - val_accuracy: 0.7805\n","Epoch 37/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 1.2084 - val_accuracy: 0.7824\n","Epoch 38/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 1.4570 - val_accuracy: 0.7673\n","Epoch 39/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 1.3864 - val_accuracy: 0.7767\n","Epoch 40/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 1.7187 - val_accuracy: 0.7623\n","Epoch 41/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 1.3644 - val_accuracy: 0.7705\n","Epoch 42/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0284 - accuracy: 0.9913 - val_loss: 1.4758 - val_accuracy: 0.7666\n","Epoch 43/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0302 - accuracy: 0.9902 - val_loss: 1.5581 - val_accuracy: 0.7633\n","Epoch 44/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 1.3309 - val_accuracy: 0.7697\n","Epoch 45/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 1.3419 - val_accuracy: 0.7890\n","Epoch 46/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 1.5697 - val_accuracy: 0.7734\n","Epoch 47/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 1.2226 - val_accuracy: 0.7712\n","Epoch 48/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 1.5059 - val_accuracy: 0.7643\n","Epoch 49/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 1.3068 - val_accuracy: 0.7764\n","Epoch 50/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 1.3896 - val_accuracy: 0.7729\n","Epoch 51/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 1.5597 - val_accuracy: 0.7815\n","Epoch 52/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 1.3535 - val_accuracy: 0.7842\n","Epoch 53/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 1.3712 - val_accuracy: 0.7799\n","Epoch 54/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 1.3457 - val_accuracy: 0.7826\n","Epoch 55/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 1.4824 - val_accuracy: 0.7735\n","Epoch 56/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 1.6167 - val_accuracy: 0.7724\n","Epoch 57/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 1.4994 - val_accuracy: 0.7653\n","Epoch 58/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 1.4957 - val_accuracy: 0.7756\n","Epoch 59/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 1.7562 - val_accuracy: 0.7389\n","Epoch 60/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 1.4154 - val_accuracy: 0.7796\n","Epoch 61/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0276 - accuracy: 0.9919 - val_loss: 1.4445 - val_accuracy: 0.7659\n","Epoch 62/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 1.4202 - val_accuracy: 0.7854\n","Epoch 63/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 1.4900 - val_accuracy: 0.7793\n","Epoch 64/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 1.5420 - val_accuracy: 0.7705\n","Epoch 65/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 1.5506 - val_accuracy: 0.7824\n","Epoch 66/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 1.6199 - val_accuracy: 0.7691\n","Epoch 67/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 1.6213 - val_accuracy: 0.7744\n","Epoch 68/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 1.6422 - val_accuracy: 0.7668\n","Epoch 69/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 1.5658 - val_accuracy: 0.7683\n","Epoch 70/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 1.5374 - val_accuracy: 0.7631\n","Epoch 71/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 1.3039 - val_accuracy: 0.7878\n","Epoch 72/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 1.6582 - val_accuracy: 0.7831\n","Epoch 73/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 1.4014 - val_accuracy: 0.7782\n","Epoch 74/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 1.7498 - val_accuracy: 0.7571\n","Epoch 75/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 1.5414 - val_accuracy: 0.7544\n","Epoch 76/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 1.9496 - val_accuracy: 0.7357\n","Epoch 77/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.4044 - val_accuracy: 0.7804\n","Epoch 78/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 1.4428 - val_accuracy: 0.7885\n","Epoch 79/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 1.9003 - val_accuracy: 0.7638\n","Epoch 80/100\n","391/391 [==============================] - 8s 21ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 1.4969 - val_accuracy: 0.7705\n","Epoch 81/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 1.5269 - val_accuracy: 0.7674\n","Epoch 82/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 1.8925 - val_accuracy: 0.7730\n","Epoch 83/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 1.4330 - val_accuracy: 0.7735\n","Epoch 84/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 1.4182 - val_accuracy: 0.7825\n","Epoch 85/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 1.6726 - val_accuracy: 0.7654\n","Epoch 86/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 1.3008 - val_accuracy: 0.7833\n","Epoch 87/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 1.6482 - val_accuracy: 0.7812\n","Epoch 88/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 1.7025 - val_accuracy: 0.7506\n","Epoch 89/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 1.6815 - val_accuracy: 0.7727\n","Epoch 90/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 1.4308 - val_accuracy: 0.7831\n","Epoch 91/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 1.3778 - val_accuracy: 0.7879\n","Epoch 92/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 1.6173 - val_accuracy: 0.7667\n","Epoch 93/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 1.9645 - val_accuracy: 0.7445\n","Epoch 94/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.7646 - val_accuracy: 0.7743\n","Epoch 95/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 1.5356 - val_accuracy: 0.7768\n","Epoch 96/100\n","391/391 [==============================] - 8s 22ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 1.5553 - val_accuracy: 0.7888\n","Epoch 97/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 1.6425 - val_accuracy: 0.7803\n","Epoch 98/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 1.6209 - val_accuracy: 0.7702\n","Epoch 99/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 1.5786 - val_accuracy: 0.7817\n","Epoch 100/100\n","391/391 [==============================] - 9s 22ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 1.7920 - val_accuracy: 0.7650\n","Saved!\n","Accuracy of model 3:  0.7649999856948853\n","Epoch 1/100\n","391/391 [==============================] - 13s 27ms/step - loss: 0.3393 - accuracy: 0.9201 - val_loss: 1.0857 - val_accuracy: 0.7962\n","Epoch 2/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0376 - accuracy: 0.9892 - val_loss: 1.4322 - val_accuracy: 0.7790\n","Epoch 3/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.4922 - val_accuracy: 0.7866\n","Epoch 4/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 1.6777 - val_accuracy: 0.7637\n","Epoch 5/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 1.4852 - val_accuracy: 0.7806\n","Epoch 6/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.2165 - accuracy: 0.9461 - val_loss: 1.1020 - val_accuracy: 0.7619\n","Epoch 7/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0313 - accuracy: 0.9901 - val_loss: 1.3941 - val_accuracy: 0.7903\n","Epoch 8/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 1.6753 - val_accuracy: 0.7952\n","Epoch 9/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 1.7006 - val_accuracy: 0.7689\n","Epoch 10/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 1.4418 - val_accuracy: 0.7870\n","Epoch 11/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 1.5996 - val_accuracy: 0.7786\n","Epoch 12/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.4344 - val_accuracy: 0.7903\n","Epoch 13/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 1.5078 - val_accuracy: 0.7777\n","Epoch 14/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 1.4516 - val_accuracy: 0.7780\n","Epoch 15/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0236 - accuracy: 0.9930 - val_loss: 1.4203 - val_accuracy: 0.7824\n","Epoch 16/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 1.3190 - val_accuracy: 0.7678\n","Epoch 17/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 1.4507 - val_accuracy: 0.7779\n","Epoch 18/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 1.6531 - val_accuracy: 0.7677\n","Epoch 19/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 1.6527 - val_accuracy: 0.7556\n","Epoch 20/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 1.7514 - val_accuracy: 0.7544\n","Epoch 21/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 1.4785 - val_accuracy: 0.7697\n","Epoch 22/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 1.5938 - val_accuracy: 0.7614\n","Epoch 23/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0305 - accuracy: 0.9913 - val_loss: 1.5228 - val_accuracy: 0.7708\n","Epoch 24/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 1.5119 - val_accuracy: 0.7698\n","Epoch 25/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 1.7184 - val_accuracy: 0.7764\n","Epoch 26/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 1.4954 - val_accuracy: 0.7780\n","Epoch 27/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 1.8455 - val_accuracy: 0.7410\n","Epoch 28/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 1.5584 - val_accuracy: 0.7803\n","Epoch 29/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 1.4883 - val_accuracy: 0.7839\n","Epoch 30/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 1.5604 - val_accuracy: 0.7786\n","Epoch 31/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 1.6362 - val_accuracy: 0.7760\n","Epoch 32/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 1.5502 - val_accuracy: 0.7823\n","Epoch 33/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0464 - accuracy: 0.9877 - val_loss: 1.2481 - val_accuracy: 0.7606\n","Epoch 34/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0283 - accuracy: 0.9920 - val_loss: 1.4137 - val_accuracy: 0.7835\n","Epoch 35/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 1.6933 - val_accuracy: 0.7782\n","Epoch 36/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 1.9302 - val_accuracy: 0.7885\n","Epoch 37/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 1.5671 - val_accuracy: 0.7801\n","Epoch 38/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 1.4378 - val_accuracy: 0.7824\n","Epoch 39/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 1.8528 - val_accuracy: 0.7711\n","Epoch 40/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 1.7478 - val_accuracy: 0.7855\n","Epoch 41/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 1.8323 - val_accuracy: 0.7714\n","Epoch 42/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 1.8079 - val_accuracy: 0.7686\n","Epoch 43/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 2.1036 - val_accuracy: 0.7779\n","Epoch 44/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 1.6226 - val_accuracy: 0.7627\n","Epoch 45/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 1.7494 - val_accuracy: 0.7850\n","Epoch 46/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 1.8860 - val_accuracy: 0.7928\n","Epoch 47/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 1.5782 - val_accuracy: 0.7775\n","Epoch 48/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 1.9838 - val_accuracy: 0.7601\n","Epoch 49/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 2.2300 - val_accuracy: 0.7659\n","Epoch 50/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 1.7702 - val_accuracy: 0.7775\n","Epoch 51/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 1.5788 - val_accuracy: 0.7854\n","Epoch 52/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 2.0453 - val_accuracy: 0.7729\n","Epoch 53/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 1.5784 - val_accuracy: 0.7879\n","Epoch 54/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 1.5437 - val_accuracy: 0.7751\n","Epoch 55/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 1.6273 - val_accuracy: 0.7740\n","Epoch 56/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 2.2640 - val_accuracy: 0.7537\n","Epoch 57/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 1.5015 - val_accuracy: 0.7823\n","Epoch 58/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 1.7463 - val_accuracy: 0.7745\n","Epoch 59/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0608 - accuracy: 0.9866 - val_loss: 1.4596 - val_accuracy: 0.7806\n","Epoch 60/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 1.8658 - val_accuracy: 0.7897\n","Epoch 61/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.9871 - val_accuracy: 0.7837\n","Epoch 62/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 1.7537 - val_accuracy: 0.7857\n","Epoch 63/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 1.9218 - val_accuracy: 0.7483\n","Epoch 64/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.8132 - val_accuracy: 0.7757\n","Epoch 65/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 1.8538 - val_accuracy: 0.7776\n","Epoch 66/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 1.8555 - val_accuracy: 0.7856\n","Epoch 67/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 1.8813 - val_accuracy: 0.7811\n","Epoch 68/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 1.8170 - val_accuracy: 0.7927\n","Epoch 69/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 1.6258 - val_accuracy: 0.7818\n","Epoch 70/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 1.6993 - val_accuracy: 0.7640\n","Epoch 71/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.8496 - val_accuracy: 0.7672\n","Epoch 72/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 1.7947 - val_accuracy: 0.7796\n","Epoch 73/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 1.8672 - val_accuracy: 0.7880\n","Epoch 74/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 1.6983 - val_accuracy: 0.7761\n","Epoch 75/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 1.5541 - val_accuracy: 0.7834\n","Epoch 76/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 1.8390 - val_accuracy: 0.7947\n","Epoch 77/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 1.7943 - val_accuracy: 0.7773\n","Epoch 78/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 2.0436 - val_accuracy: 0.7679\n","Epoch 79/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 1.9913 - val_accuracy: 0.7910\n","Epoch 80/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 1.7727 - val_accuracy: 0.7803\n","Epoch 81/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 1.5647 - val_accuracy: 0.7858\n","Epoch 82/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 1.8183 - val_accuracy: 0.7817\n","Epoch 83/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 1.8593 - val_accuracy: 0.7793\n","Epoch 84/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0558 - accuracy: 0.9855 - val_loss: 1.2743 - val_accuracy: 0.7781\n","Epoch 85/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 1.4718 - val_accuracy: 0.7962\n","Epoch 86/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 1.8626 - val_accuracy: 0.7871\n","Epoch 87/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 1.9251 - val_accuracy: 0.7822\n","Epoch 88/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0256 - accuracy: 0.9943 - val_loss: 1.8566 - val_accuracy: 0.7860\n","Epoch 89/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 1.7566 - val_accuracy: 0.7932\n","Epoch 90/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 1.8970 - val_accuracy: 0.7950\n","Epoch 91/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.4590 - val_accuracy: 0.7885\n","Epoch 92/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 1.9441 - val_accuracy: 0.7830\n","Epoch 93/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 2.0035 - val_accuracy: 0.7813\n","Epoch 94/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 2.0742 - val_accuracy: 0.7712\n","Epoch 95/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 2.0188 - val_accuracy: 0.7693\n","Epoch 96/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 1.7486 - val_accuracy: 0.7893\n","Epoch 97/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 2.0529 - val_accuracy: 0.7787\n","Epoch 98/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.7919 - val_accuracy: 0.7707\n","Epoch 99/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 1.6583 - val_accuracy: 0.7874\n","Epoch 100/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 1.6990 - val_accuracy: 0.7851\n","Saved!\n","Accuracy of model 4:  0.785099983215332\n","Epoch 1/100\n","391/391 [==============================] - 15s 31ms/step - loss: 0.1747 - accuracy: 0.9492 - val_loss: 1.3310 - val_accuracy: 0.7718\n","Epoch 2/100\n","391/391 [==============================] - 11s 29ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 1.3646 - val_accuracy: 0.7847\n","Epoch 3/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 1.3596 - val_accuracy: 0.7857\n","Epoch 4/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 1.7049 - val_accuracy: 0.7773\n","Epoch 5/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 1.3530 - val_accuracy: 0.7916\n","Epoch 6/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 1.4889 - val_accuracy: 0.7794\n","Epoch 7/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 1.7628 - val_accuracy: 0.7669\n","Epoch 8/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 1.4849 - val_accuracy: 0.7785\n","Epoch 9/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 1.4080 - val_accuracy: 0.7877\n","Epoch 10/100\n","391/391 [==============================] - 12s 29ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 1.5942 - val_accuracy: 0.7652\n","Epoch 11/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 1.3778 - val_accuracy: 0.7879\n","Epoch 12/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 1.3628 - val_accuracy: 0.7889\n","Epoch 13/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 1.4917 - val_accuracy: 0.7777\n","Epoch 14/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 1.6855 - val_accuracy: 0.7742\n","Epoch 15/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 1.7452 - val_accuracy: 0.7586\n","Epoch 16/100\n","391/391 [==============================] - 12s 29ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 1.3476 - val_accuracy: 0.7879\n","Epoch 17/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.1880 - accuracy: 0.9572 - val_loss: 1.1100 - val_accuracy: 0.7818\n","Epoch 18/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 1.3233 - val_accuracy: 0.7924\n","Epoch 19/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 1.5577 - val_accuracy: 0.7978\n","Epoch 20/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 1.7182 - val_accuracy: 0.7855\n","Epoch 21/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 1.7181 - val_accuracy: 0.7929\n","Epoch 22/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 1.5298 - val_accuracy: 0.7944\n","Epoch 23/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 1.5422 - val_accuracy: 0.7730\n","Epoch 24/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 1.6608 - val_accuracy: 0.7922\n","Epoch 25/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 1.5168 - val_accuracy: 0.7888\n","Epoch 26/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 1.5550 - val_accuracy: 0.7757\n","Epoch 27/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 1.5431 - val_accuracy: 0.7788\n","Epoch 28/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 1.4402 - val_accuracy: 0.7856\n","Epoch 29/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 1.5108 - val_accuracy: 0.7872\n","Epoch 30/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 1.7233 - val_accuracy: 0.7871\n","Epoch 31/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 1.7367 - val_accuracy: 0.7546\n","Epoch 32/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 1.5927 - val_accuracy: 0.7807\n","Epoch 33/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 1.5138 - val_accuracy: 0.7682\n","Epoch 34/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 1.4703 - val_accuracy: 0.7881\n","Epoch 35/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 1.4968 - val_accuracy: 0.7753\n","Epoch 36/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 1.4970 - val_accuracy: 0.7907\n","Epoch 37/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 1.6242 - val_accuracy: 0.7894\n","Epoch 38/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 1.7677 - val_accuracy: 0.7763\n","Epoch 39/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 1.4247 - val_accuracy: 0.7808\n","Epoch 40/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 1.4414 - val_accuracy: 0.7810\n","Epoch 41/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 1.7350 - val_accuracy: 0.7766\n","Epoch 42/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 1.5492 - val_accuracy: 0.7894\n","Epoch 43/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 1.4887 - val_accuracy: 0.7907\n","Epoch 44/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 1.4781 - val_accuracy: 0.7745\n","Epoch 45/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 1.4270 - val_accuracy: 0.7898\n","Epoch 46/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.5052 - val_accuracy: 0.7858\n","Epoch 47/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 1.6650 - val_accuracy: 0.7737\n","Epoch 48/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 1.6436 - val_accuracy: 0.7722\n","Epoch 49/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 1.6496 - val_accuracy: 0.7900\n","Epoch 50/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 1.4255 - val_accuracy: 0.7888\n","Epoch 51/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 1.4824 - val_accuracy: 0.7751\n","Epoch 52/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 1.7713 - val_accuracy: 0.7906\n","Epoch 53/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 1.8950 - val_accuracy: 0.7572\n","Epoch 54/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.5383 - val_accuracy: 0.7859\n","Epoch 55/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 1.8960 - val_accuracy: 0.7640\n","Epoch 56/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 1.3920 - val_accuracy: 0.7830\n","Epoch 57/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 1.5708 - val_accuracy: 0.7827\n","Epoch 58/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 1.5096 - val_accuracy: 0.7709\n","Epoch 59/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 1.8078 - val_accuracy: 0.7373\n","Epoch 60/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 1.5016 - val_accuracy: 0.7824\n","Epoch 61/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 1.4762 - val_accuracy: 0.7667\n","Epoch 62/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0304 - accuracy: 0.9916 - val_loss: 1.4878 - val_accuracy: 0.7879\n","Epoch 63/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.6468 - val_accuracy: 0.7935\n","Epoch 64/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 1.6930 - val_accuracy: 0.7950\n","Epoch 65/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9941 - val_loss: 2.3794 - val_accuracy: 0.5429\n","Epoch 66/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 1.3783 - val_accuracy: 0.7918\n","Epoch 67/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.8399 - val_accuracy: 0.7869\n","Epoch 68/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 1.5584 - val_accuracy: 0.7967\n","Epoch 69/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 1.6467 - val_accuracy: 0.7900\n","Epoch 70/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 1.5702 - val_accuracy: 0.7794\n","Epoch 71/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.7952 - val_accuracy: 0.7671\n","Epoch 72/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.6862 - val_accuracy: 0.7860\n","Epoch 73/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 1.5561 - val_accuracy: 0.7884\n","Epoch 74/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 1.8055 - val_accuracy: 0.7897\n","Epoch 75/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 1.5583 - val_accuracy: 0.7765\n","Epoch 76/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 1.8307 - val_accuracy: 0.7693\n","Epoch 77/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 1.6076 - val_accuracy: 0.7731\n","Epoch 78/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 1.4281 - val_accuracy: 0.7963\n","Epoch 79/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 1.7898 - val_accuracy: 0.7840\n","Epoch 80/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.5419 - val_accuracy: 0.7815\n","Epoch 81/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 1.5952 - val_accuracy: 0.7743\n","Epoch 82/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 1.7219 - val_accuracy: 0.7801\n","Epoch 83/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 1.6540 - val_accuracy: 0.7820\n","Epoch 84/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 1.4903 - val_accuracy: 0.7838\n","Epoch 85/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 1.8500 - val_accuracy: 0.7732\n","Epoch 86/100\n","391/391 [==============================] - 12s 32ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 1.4455 - val_accuracy: 0.7923\n","Epoch 87/100\n","391/391 [==============================] - 12s 30ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.7450 - val_accuracy: 0.7752\n","Epoch 88/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.4802 - val_accuracy: 0.7883\n","Epoch 89/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 1.6553 - val_accuracy: 0.7663\n","Epoch 90/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 1.5959 - val_accuracy: 0.7719\n","Epoch 91/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 1.6058 - val_accuracy: 0.7790\n","Epoch 92/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 1.7284 - val_accuracy: 0.7727\n","Epoch 93/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 1.4949 - val_accuracy: 0.7818\n","Epoch 94/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0365 - accuracy: 0.9917 - val_loss: 1.3465 - val_accuracy: 0.7931\n","Epoch 95/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.8410 - val_accuracy: 0.7944\n","Epoch 96/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 1.6479 - val_accuracy: 0.7939\n","Epoch 97/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.6887 - val_accuracy: 0.7771\n","Epoch 98/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 1.7304 - val_accuracy: 0.7976\n","Epoch 99/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.4620 - val_accuracy: 0.7854\n","Epoch 100/100\n","391/391 [==============================] - 12s 31ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 2.3416 - val_accuracy: 0.7128\n","Saved!\n","Accuracy of model 5:  0.7128000259399414\n","Epoch 1/100\n","391/391 [==============================] - 20s 41ms/step - loss: 0.0494 - accuracy: 0.9893 - val_loss: 1.5065 - val_accuracy: 0.7696\n","Epoch 2/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 1.5305 - val_accuracy: 0.7762\n","Epoch 3/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.2155 - accuracy: 0.9916 - val_loss: 2.7985 - val_accuracy: 0.3972\n","Epoch 4/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.3368 - accuracy: 0.9239 - val_loss: 1.0606 - val_accuracy: 0.7640\n","Epoch 5/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0606 - accuracy: 0.9819 - val_loss: 1.2567 - val_accuracy: 0.7808\n","Epoch 6/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 1.4211 - val_accuracy: 0.7880\n","Epoch 7/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 1.6449 - val_accuracy: 0.7910\n","Epoch 8/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.6082 - val_accuracy: 0.7973\n","Epoch 9/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 1.7205 - val_accuracy: 0.7946\n","Epoch 10/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.9216 - val_accuracy: 0.7898\n","Epoch 11/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 1.9245 - val_accuracy: 0.7910\n","Epoch 12/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 1.7864 - val_accuracy: 0.7921\n","Epoch 13/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 1.8514 - val_accuracy: 0.7916\n","Epoch 14/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 1.6936 - val_accuracy: 0.7964\n","Epoch 15/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 1.6159 - val_accuracy: 0.7963\n","Epoch 16/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 1.8906 - val_accuracy: 0.7922\n","Epoch 17/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.6821 - val_accuracy: 0.7866\n","Epoch 18/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 1.6730 - val_accuracy: 0.7936\n","Epoch 19/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 1.4979 - val_accuracy: 0.7874\n","Epoch 20/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 1.5269 - val_accuracy: 0.7859\n","Epoch 21/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 1.8015 - val_accuracy: 0.7677\n","Epoch 22/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 1.3924 - val_accuracy: 0.7916\n","Epoch 23/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 1.5832 - val_accuracy: 0.7666\n","Epoch 24/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 1.3644 - val_accuracy: 0.7892\n","Epoch 25/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.5214 - val_accuracy: 0.7852\n","Epoch 26/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 1.5058 - val_accuracy: 0.7858\n","Epoch 27/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 1.5312 - val_accuracy: 0.7629\n","Epoch 28/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 1.6526 - val_accuracy: 0.7912\n","Epoch 29/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 1.6762 - val_accuracy: 0.7760\n","Epoch 30/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 1.7657 - val_accuracy: 0.7758\n","Epoch 31/100\n","391/391 [==============================] - 15s 37ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 1.5127 - val_accuracy: 0.7818\n","Epoch 32/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 1.5213 - val_accuracy: 0.7866\n","Epoch 33/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 1.4431 - val_accuracy: 0.7880\n","Epoch 34/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 1.7470 - val_accuracy: 0.7694\n","Epoch 35/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 1.4735 - val_accuracy: 0.7933\n","Epoch 36/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 1.5751 - val_accuracy: 0.7851\n","Epoch 37/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 1.5900 - val_accuracy: 0.7893\n","Epoch 38/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 1.5114 - val_accuracy: 0.7911\n","Epoch 39/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 1.5683 - val_accuracy: 0.7870\n","Epoch 40/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 1.5658 - val_accuracy: 0.7798\n","Epoch 41/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.5544 - val_accuracy: 0.7878\n","Epoch 42/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 1.7435 - val_accuracy: 0.7691\n","Epoch 43/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.5944 - val_accuracy: 0.7845\n","Epoch 44/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 1.6245 - val_accuracy: 0.7753\n","Epoch 45/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 1.8197 - val_accuracy: 0.7656\n","Epoch 46/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 1.7070 - val_accuracy: 0.7784\n","Epoch 47/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 1.5719 - val_accuracy: 0.7949\n","Epoch 48/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 1.6895 - val_accuracy: 0.7826\n","Epoch 49/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 1.7737 - val_accuracy: 0.7865\n","Epoch 50/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.5382 - val_accuracy: 0.7690\n","Epoch 51/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 1.4951 - val_accuracy: 0.7845\n","Epoch 52/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.5779 - val_accuracy: 0.7899\n","Epoch 53/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 1.6183 - val_accuracy: 0.7827\n","Epoch 54/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 1.7656 - val_accuracy: 0.7716\n","Epoch 55/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.6628 - val_accuracy: 0.7821\n","Epoch 56/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 1.7036 - val_accuracy: 0.7799\n","Epoch 57/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 1.7663 - val_accuracy: 0.7764\n","Epoch 58/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.1741 - accuracy: 0.9746 - val_loss: 1.7540 - val_accuracy: 0.6750\n","Epoch 59/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0897 - accuracy: 0.9724 - val_loss: 1.2488 - val_accuracy: 0.7892\n","Epoch 60/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 1.5536 - val_accuracy: 0.7886\n","Epoch 61/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 1.9364 - val_accuracy: 0.7915\n","Epoch 62/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 2.0079 - val_accuracy: 0.7892\n","Epoch 63/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 1.9280 - val_accuracy: 0.7877\n","Epoch 64/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 1.8913 - val_accuracy: 0.7842\n","Epoch 65/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 1.9476 - val_accuracy: 0.7899\n","Epoch 66/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 1.6636 - val_accuracy: 0.7889\n","Epoch 67/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 1.7544 - val_accuracy: 0.7936\n","Epoch 68/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 1.9010 - val_accuracy: 0.7824\n","Epoch 69/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 1.7821 - val_accuracy: 0.7748\n","Epoch 70/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 1.5351 - val_accuracy: 0.7873\n","Epoch 71/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 1.8634 - val_accuracy: 0.7731\n","Epoch 72/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 1.4970 - val_accuracy: 0.7846\n","Epoch 73/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 1.5264 - val_accuracy: 0.7823\n","Epoch 74/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 1.7315 - val_accuracy: 0.7863\n","Epoch 75/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 1.6230 - val_accuracy: 0.7721\n","Epoch 76/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 1.6037 - val_accuracy: 0.7868\n","Epoch 77/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 1.6116 - val_accuracy: 0.7665\n","Epoch 78/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.6918 - val_accuracy: 0.7773\n","Epoch 79/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 1.7262 - val_accuracy: 0.7854\n","Epoch 80/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 1.7348 - val_accuracy: 0.7686\n","Epoch 81/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.5050 - val_accuracy: 0.7895\n","Epoch 82/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 1.6604 - val_accuracy: 0.7886\n","Epoch 83/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 1.6633 - val_accuracy: 0.7826\n","Epoch 84/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 1.5319 - val_accuracy: 0.7710\n","Epoch 85/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 1.6457 - val_accuracy: 0.7554\n","Epoch 86/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 1.5103 - val_accuracy: 0.7860\n","Epoch 87/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 1.7873 - val_accuracy: 0.7754\n","Epoch 88/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.5733 - val_accuracy: 0.7861\n","Epoch 89/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.5701 - val_accuracy: 0.7894\n","Epoch 90/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 1.9345 - val_accuracy: 0.7782\n","Epoch 91/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 1.6071 - val_accuracy: 0.7855\n","Epoch 92/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 1.8181 - val_accuracy: 0.7837\n","Epoch 93/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.9356 - val_accuracy: 0.7773\n","Epoch 94/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.5601 - val_accuracy: 0.7902\n","Epoch 95/100\n","391/391 [==============================] - 16s 40ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 1.6478 - val_accuracy: 0.7675\n","Epoch 96/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 1.8392 - val_accuracy: 0.7857\n","Epoch 97/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 1.5987 - val_accuracy: 0.7823\n","Epoch 98/100\n","391/391 [==============================] - 15s 38ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 1.5759 - val_accuracy: 0.7836\n","Epoch 99/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 2.0434 - val_accuracy: 0.7706\n","Epoch 100/100\n","391/391 [==============================] - 15s 39ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 1.4414 - val_accuracy: 0.7695\n","Saved!\n","Accuracy of model 6:  0.7695000171661377\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pM1cIwzUTGyt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626684222125,"user_tz":-330,"elapsed":17,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"41a00da7-34ee-4242-b18b-aa68c857c4bf"},"source":["accuracies_time"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0.6980000138282776, 40.56347780227661),\n"," (0.692300021648407, 60.84521670341492),\n"," (0.675599992275238, 81.12695560455322),\n"," (0.6973000168800354, 101.40869450569153),\n"," (0.6948999762535095, 121.69043340682984),\n"," (0.691100001335144, 141.97217230796815),\n"," (0.6947000026702881, 162.25391120910643),\n"," (0.6565999984741211, 182.53565011024475),\n"," (0.6820999979972839, 202.81738901138306),\n"," (0.7282000184059143, 95.09768390655518),\n"," (0.7702999711036682, 142.64652585983276),\n"," (0.7720000147819519, 190.19536781311035),\n"," (0.7681000232696533, 237.74420976638794),\n"," (0.7684999704360962, 285.2930517196655),\n"," (0.7516000270843506, 332.8418936729431),\n"," (0.7728999853134155, 380.3907356262207),\n"," (0.767799973487854, 427.9395775794983),\n"," (0.761900007724762, 475.4884195327759),\n"," (0.7692999839782715, 172.77028665542602),\n"," (0.7601000070571899, 259.155429983139),\n"," (0.7623000144958496, 345.54057331085204),\n"," (0.7728999853134155, 431.92571663856506),\n"," (0.7796000242233276, 518.310859966278),\n"," (0.7631000280380249, 604.6960032939911),\n"," (0.7705000042915344, 691.0811466217041),\n"," (0.7831000089645386, 777.4662899494172),\n"," (0.7649999856948853, 863.8514332771301),\n"," (0.7544000148773193, 205.3241527080536),\n"," (0.7785999774932861, 307.9862290620804),\n"," (0.7854999899864197, 410.6483054161072),\n"," (0.7774999737739563, 513.310381770134),\n"," (0.7896999716758728, 615.9724581241608),\n"," (0.7639999985694885, 718.6345344781876),\n"," (0.7803000211715698, 821.2966108322144),\n"," (0.7950000166893005, 923.9586871862411),\n"," (0.785099983215332, 1026.620763540268),\n"," (0.7854999899864197, 244.9989736557007),\n"," (0.7871000170707703, 367.498460483551),\n"," (0.781000018119812, 489.9979473114014),\n"," (0.7888000011444092, 612.4974341392517),\n"," (0.7824000120162964, 734.996920967102),\n"," (0.7793999910354614, 857.4964077949523),\n"," (0.781499981880188, 979.9958946228028),\n"," (0.7718999981880188, 1102.495381450653),\n"," (0.7128000259399414, 1224.9948682785034),\n"," (0.7858999967575073, 301.69433946609496),\n"," (0.7757999897003174, 452.54150919914247),\n"," (0.7797999978065491, 603.3886789321899),\n"," (0.7689999938011169, 754.2358486652374),\n"," (0.7886000275611877, 905.0830183982849),\n"," (0.7872999906539917, 1055.9301881313324),\n"," (0.7685999870300293, 1206.7773578643798),\n"," (0.7781999707221985, 1357.6245275974275),\n"," (0.7695000171661377, 1508.4716973304749)]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"aYAjhUDQ_2DN"},"source":[""],"execution_count":null,"outputs":[]}]}