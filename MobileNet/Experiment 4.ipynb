{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Experiment 4.ipynb","provenance":[{"file_id":"1qQ_0RaSDUXo_uEbw1vvx3nPGsLtg7iBu","timestamp":1623870104154},{"file_id":"1cGXeoDEMw72Qwq_JddSrkccvR6jR01V_","timestamp":1622991507291}],"collapsed_sections":[],"mount_file_id":"1KABijJhMwMpD1PGGKUW6C5H4fFHgD0r7","authorship_tag":"ABX9TyPfbBWeASsCbCttam3wvmxK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"EhRVl-j9XISJ"},"source":["from tensorflow.keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSpWlE_jfAFQ","executionInfo":{"status":"ok","timestamp":1627298494864,"user_tz":-330,"elapsed":3000,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"24a0e6db-a4aa-4768-95b8-b543b79f226d"},"source":["# example of loading the MobileNet model\n","from tensorflow.keras.applications.mobilenet import MobileNet\n","# load model\n","model = MobileNet(input_shape=(32,32,3), include_top=False, weights=None)\n","# summarize the model\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"mobilenet_1.00_32\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)         2304      \n","_________________________________________________________________\n","conv_dw_6_bn (BatchNormaliza (None, 2, 2, 256)         1024      \n","_________________________________________________________________\n","conv_dw_6_relu (ReLU)        (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","conv_pw_6 (Conv2D)           (None, 2, 2, 512)         131072    \n","_________________________________________________________________\n","conv_pw_6_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_6_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_7 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_8 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_9 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_10 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_10 (Conv2D)          (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_11 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_11 (Conv2D)          (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n","_________________________________________________________________\n","conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n","_________________________________________________________________\n","conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n","_________________________________________________________________\n","conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n","_________________________________________________________________\n","conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n","_________________________________________________________________\n","conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n","_________________________________________________________________\n","conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n","=================================================================\n","Total params: 3,228,864\n","Trainable params: 3,206,976\n","Non-trainable params: 21,888\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWPVP0KFNY_P","executionInfo":{"status":"ok","timestamp":1627298494864,"user_tz":-330,"elapsed":31,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"ff1ccadb-a1f5-4b70-ba1c-a7a9a7d3f0d0"},"source":["len(model.layers)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["86"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"6enOD5B6OAiZ"},"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QYrda208Nh56","executionInfo":{"status":"ok","timestamp":1627298494866,"user_tz":-330,"elapsed":23,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"77b62b9f-5861-4b12-f5f1-8843cb3623c2"},"source":["i = 0\n","exits = []\n","for layer in model.layers:\n","  if 'pad' in layer.name:\n","    print(i, layer.output_shape)\n","    exits.append(i)\n","  i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10 (None, 17, 17, 64)\n","23 (None, 9, 9, 128)\n","36 (None, 5, 5, 256)\n","73 (None, 3, 3, 512)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p9tH_ROcvkFj"},"source":["## **ADDITION OF EXIT NETWORK**"]},{"cell_type":"code","metadata":{"id":"5AzuwnTDSOSf"},"source":["exit_layer1 = model.layers[10]\n","exit_layer2 = model.layers[23]\n","exit_layer3 = model.layers[36]\n","exit_layer4 = model.layers[73]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vII6zf4pNIK"},"source":["exit_models = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gz-OYNBTdRO","executionInfo":{"status":"ok","timestamp":1627298494869,"user_tz":-330,"elapsed":22,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"b433e387-3ecc-4222-f45c-208b073465fa"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","pool1 = MaxPooling2D((3,3), strides=(3,3))(exit_layer1.output)\n","conv1 = Conv2D(128, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model1 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model1)\n","exit_model1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 5, 5, 128)         73856     \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 128)               65664     \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 144,522\n","Trainable params: 144,266\n","Non-trainable params: 256\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5OL3CceSEEL","executionInfo":{"status":"ok","timestamp":1627298494869,"user_tz":-330,"elapsed":19,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"967b1e99-d34e-4843-dfaa-c65d00cb7881"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","pool1 = MaxPooling2D((3,3), strides=(3,3))(exit_layer2.output)\n","conv1 = Conv2D(256, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model2 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model2)\n","exit_model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 3, 3, 128)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 3, 3, 256)         295168    \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 1, 1, 256)         0         \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 256)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 128)               32896     \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 10)                1290      \n","=================================================================\n","Total params: 361,162\n","Trainable params: 360,010\n","Non-trainable params: 1,152\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jW--RdXSSfj","executionInfo":{"status":"ok","timestamp":1627298494870,"user_tz":-330,"elapsed":16,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"28795356-626b-4c6c-9956-da42afe774e3"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer3.output)\n","conv1 = Conv2D(512, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model3 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model3)\n","exit_model3.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 2, 2, 512)         1180160   \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 128)               65664     \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 10)                1290      \n","=================================================================\n","Total params: 1,384,266\n","Trainable params: 1,381,322\n","Non-trainable params: 2,944\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XwmZ_Ntorkl","executionInfo":{"status":"ok","timestamp":1627298495326,"user_tz":-330,"elapsed":468,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"c6805cce-e071-4d9e-df75-f97bd56f816a"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer4.output)\n","#conv1 = Conv2D(512, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","#pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool1)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model4 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model4)\n","exit_model4.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)         2304      \n","_________________________________________________________________\n","conv_dw_6_bn (BatchNormaliza (None, 2, 2, 256)         1024      \n","_________________________________________________________________\n","conv_dw_6_relu (ReLU)        (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","conv_pw_6 (Conv2D)           (None, 2, 2, 512)         131072    \n","_________________________________________________________________\n","conv_pw_6_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_6_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_7 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_8 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_9 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_10 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_10 (Conv2D)          (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_11 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_11 (Conv2D)          (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 128)               65664     \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 10)                1290      \n","=================================================================\n","Total params: 1,694,794\n","Trainable params: 1,680,074\n","Non-trainable params: 14,720\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDdgNEwKpf_8","executionInfo":{"status":"ok","timestamp":1627298495327,"user_tz":-330,"elapsed":32,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"58fdc1ad-cf54-4ec6-d5ee-4ecad74a4add"},"source":["exit_models"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tensorflow.python.keras.engine.functional.Functional at 0x7fa4c461f6d0>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7fa4c4632f90>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7fa4c467dc90>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7fa4c45d2290>]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"qs5OkuHGkCcX"},"source":["for model in exit_models:\n","  model.compile(\n","          optimizer='adam',\n","          loss='sparse_categorical_crossentropy',\n","          metrics=['accuracy']\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKX9VncqPueb"},"source":["import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5GvpA1ElIqe","executionInfo":{"status":"ok","timestamp":1627300207212,"user_tz":-330,"elapsed":931678,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"84f27d8b-7e70-4b04-87e8-ad248d099664"},"source":["accuracies_time = []\n","\n","for i in range(len(exits)):\n","  model = exit_models[i]\n","  model.load_weights(f\"/MobileNet/Main_till_exit{i+1}_weights.h5\", by_name=True)\n","  for layer in range(exits[i] + 1):\n","    model.layers[layer].trainable = False\n","  accuracies_time.append('-------------')\n","  start = time.time()\n","  history = model.fit(\n","      x=x_train,\n","      y=y_train,\n","      epochs=100,\n","      verbose=1,\n","      validation_data=(x_test, y_test),\n","      batch_size=128\n","  )\n","  end = time.time()\n","  accuracies_time.append(((history.history.get('val_accuracy')[19]), (end-start)*2/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[29]), (end-start)*3/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[39]), (end-start)*4/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[49]), (end-start)*5/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[59]), (end-start)*6/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[69]), (end-start)*7/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[79]), (end-start)*8/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[89]), (end-start)*9/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[99]), (end-start)*10/10))\n","  print(f\"Accuracy of model {i+1}: \", history.history.get('val_accuracy')[len(history.history.get('val_accuracy')) - 1])\n","  i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","391/391 [==============================] - 3s 5ms/step - loss: 1.3619 - accuracy: 0.5142 - val_loss: 1.1858 - val_accuracy: 0.5813\n","Epoch 2/100\n","391/391 [==============================] - 2s 5ms/step - loss: 1.0486 - accuracy: 0.6322 - val_loss: 1.0509 - val_accuracy: 0.6280\n","Epoch 3/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.9348 - accuracy: 0.6743 - val_loss: 0.9445 - val_accuracy: 0.6699\n","Epoch 4/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.8472 - accuracy: 0.7056 - val_loss: 0.9910 - val_accuracy: 0.6526\n","Epoch 5/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.7817 - accuracy: 0.7267 - val_loss: 0.8865 - val_accuracy: 0.6966\n","Epoch 6/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.7354 - accuracy: 0.7451 - val_loss: 0.9566 - val_accuracy: 0.6706\n","Epoch 7/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.6847 - accuracy: 0.7606 - val_loss: 0.8785 - val_accuracy: 0.6956\n","Epoch 8/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.6503 - accuracy: 0.7715 - val_loss: 0.9052 - val_accuracy: 0.6949\n","Epoch 9/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.6134 - accuracy: 0.7869 - val_loss: 0.8612 - val_accuracy: 0.7076\n","Epoch 10/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.5721 - accuracy: 0.8010 - val_loss: 0.9132 - val_accuracy: 0.7013\n","Epoch 11/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.5455 - accuracy: 0.8079 - val_loss: 0.8806 - val_accuracy: 0.7066\n","Epoch 12/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.5114 - accuracy: 0.8191 - val_loss: 0.8886 - val_accuracy: 0.7143\n","Epoch 13/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.4804 - accuracy: 0.8296 - val_loss: 0.9213 - val_accuracy: 0.7037\n","Epoch 14/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.4587 - accuracy: 0.8369 - val_loss: 0.9543 - val_accuracy: 0.7048\n","Epoch 15/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.4294 - accuracy: 0.8476 - val_loss: 1.0337 - val_accuracy: 0.6979\n","Epoch 16/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.4059 - accuracy: 0.8555 - val_loss: 0.9937 - val_accuracy: 0.7084\n","Epoch 17/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.3830 - accuracy: 0.8632 - val_loss: 0.9773 - val_accuracy: 0.7138\n","Epoch 18/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.3570 - accuracy: 0.8727 - val_loss: 1.0193 - val_accuracy: 0.7104\n","Epoch 19/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.3362 - accuracy: 0.8795 - val_loss: 1.1270 - val_accuracy: 0.6912\n","Epoch 20/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.3179 - accuracy: 0.8858 - val_loss: 1.0641 - val_accuracy: 0.7115\n","Epoch 21/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2981 - accuracy: 0.8940 - val_loss: 1.1205 - val_accuracy: 0.7129\n","Epoch 22/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2750 - accuracy: 0.9010 - val_loss: 1.1643 - val_accuracy: 0.7004\n","Epoch 23/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2563 - accuracy: 0.9083 - val_loss: 1.2429 - val_accuracy: 0.7047\n","Epoch 24/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2429 - accuracy: 0.9116 - val_loss: 1.1829 - val_accuracy: 0.7026\n","Epoch 25/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2252 - accuracy: 0.9201 - val_loss: 1.2892 - val_accuracy: 0.7086\n","Epoch 26/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2145 - accuracy: 0.9222 - val_loss: 1.3607 - val_accuracy: 0.7009\n","Epoch 27/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2015 - accuracy: 0.9284 - val_loss: 1.3868 - val_accuracy: 0.6954\n","Epoch 28/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1831 - accuracy: 0.9341 - val_loss: 1.4138 - val_accuracy: 0.7082\n","Epoch 29/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1840 - accuracy: 0.9319 - val_loss: 1.4456 - val_accuracy: 0.7060\n","Epoch 30/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1702 - accuracy: 0.9385 - val_loss: 1.5299 - val_accuracy: 0.6975\n","Epoch 31/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1602 - accuracy: 0.9425 - val_loss: 1.5437 - val_accuracy: 0.6938\n","Epoch 32/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1574 - accuracy: 0.9424 - val_loss: 1.5652 - val_accuracy: 0.6966\n","Epoch 33/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1331 - accuracy: 0.9529 - val_loss: 1.5967 - val_accuracy: 0.6958\n","Epoch 34/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1376 - accuracy: 0.9495 - val_loss: 1.7876 - val_accuracy: 0.6766\n","Epoch 35/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1251 - accuracy: 0.9548 - val_loss: 1.7709 - val_accuracy: 0.6817\n","Epoch 36/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1232 - accuracy: 0.9557 - val_loss: 1.8177 - val_accuracy: 0.6916\n","Epoch 37/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1406 - accuracy: 0.9490 - val_loss: 1.8086 - val_accuracy: 0.6891\n","Epoch 38/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1277 - accuracy: 0.9525 - val_loss: 1.9392 - val_accuracy: 0.6858\n","Epoch 39/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1134 - accuracy: 0.9590 - val_loss: 1.9271 - val_accuracy: 0.6932\n","Epoch 40/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1092 - accuracy: 0.9607 - val_loss: 2.0120 - val_accuracy: 0.6845\n","Epoch 41/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1014 - accuracy: 0.9637 - val_loss: 1.8835 - val_accuracy: 0.6947\n","Epoch 42/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1062 - accuracy: 0.9619 - val_loss: 1.9615 - val_accuracy: 0.6897\n","Epoch 43/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0964 - accuracy: 0.9651 - val_loss: 2.0137 - val_accuracy: 0.6928\n","Epoch 44/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0976 - accuracy: 0.9649 - val_loss: 2.0201 - val_accuracy: 0.6918\n","Epoch 45/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0919 - accuracy: 0.9667 - val_loss: 2.0700 - val_accuracy: 0.6964\n","Epoch 46/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0891 - accuracy: 0.9684 - val_loss: 2.1453 - val_accuracy: 0.6928\n","Epoch 47/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1009 - accuracy: 0.9643 - val_loss: 2.1225 - val_accuracy: 0.6947\n","Epoch 48/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0951 - accuracy: 0.9649 - val_loss: 2.2503 - val_accuracy: 0.6817\n","Epoch 49/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0864 - accuracy: 0.9694 - val_loss: 2.1321 - val_accuracy: 0.6950\n","Epoch 50/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0789 - accuracy: 0.9714 - val_loss: 2.2425 - val_accuracy: 0.6887\n","Epoch 51/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0747 - accuracy: 0.9733 - val_loss: 2.4087 - val_accuracy: 0.6820\n","Epoch 52/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0827 - accuracy: 0.9703 - val_loss: 2.2331 - val_accuracy: 0.6947\n","Epoch 53/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0850 - accuracy: 0.9688 - val_loss: 2.3729 - val_accuracy: 0.6855\n","Epoch 54/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0882 - accuracy: 0.9679 - val_loss: 2.2528 - val_accuracy: 0.6934\n","Epoch 55/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0863 - accuracy: 0.9691 - val_loss: 2.3883 - val_accuracy: 0.6853\n","Epoch 56/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0735 - accuracy: 0.9736 - val_loss: 2.3275 - val_accuracy: 0.6897\n","Epoch 57/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0705 - accuracy: 0.9746 - val_loss: 2.3596 - val_accuracy: 0.6898\n","Epoch 58/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0745 - accuracy: 0.9735 - val_loss: 2.5501 - val_accuracy: 0.6704\n","Epoch 59/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0722 - accuracy: 0.9745 - val_loss: 2.4236 - val_accuracy: 0.6993\n","Epoch 60/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0707 - accuracy: 0.9749 - val_loss: 2.3612 - val_accuracy: 0.6941\n","Epoch 61/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0768 - accuracy: 0.9723 - val_loss: 2.3689 - val_accuracy: 0.6922\n","Epoch 62/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0695 - accuracy: 0.9755 - val_loss: 2.7482 - val_accuracy: 0.6768\n","Epoch 63/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0608 - accuracy: 0.9786 - val_loss: 2.6330 - val_accuracy: 0.6864\n","Epoch 64/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0776 - accuracy: 0.9725 - val_loss: 2.4582 - val_accuracy: 0.6933\n","Epoch 65/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0730 - accuracy: 0.9740 - val_loss: 2.5368 - val_accuracy: 0.6880\n","Epoch 66/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0701 - accuracy: 0.9751 - val_loss: 2.6198 - val_accuracy: 0.6870\n","Epoch 67/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0637 - accuracy: 0.9767 - val_loss: 2.5854 - val_accuracy: 0.6924\n","Epoch 68/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0708 - accuracy: 0.9749 - val_loss: 2.5437 - val_accuracy: 0.6862\n","Epoch 69/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0653 - accuracy: 0.9767 - val_loss: 2.5896 - val_accuracy: 0.6920\n","Epoch 70/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0621 - accuracy: 0.9780 - val_loss: 2.7117 - val_accuracy: 0.6900\n","Epoch 71/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 2.6857 - val_accuracy: 0.6924\n","Epoch 72/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0610 - accuracy: 0.9788 - val_loss: 2.6650 - val_accuracy: 0.6845\n","Epoch 73/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0562 - accuracy: 0.9798 - val_loss: 2.7562 - val_accuracy: 0.6864\n","Epoch 74/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 2.6647 - val_accuracy: 0.6903\n","Epoch 75/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0679 - accuracy: 0.9760 - val_loss: 2.6271 - val_accuracy: 0.6978\n","Epoch 76/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0639 - accuracy: 0.9779 - val_loss: 2.6217 - val_accuracy: 0.6938\n","Epoch 77/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0475 - accuracy: 0.9836 - val_loss: 2.9156 - val_accuracy: 0.6861\n","Epoch 78/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0663 - accuracy: 0.9769 - val_loss: 2.7684 - val_accuracy: 0.6939\n","Epoch 79/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0532 - accuracy: 0.9814 - val_loss: 2.7331 - val_accuracy: 0.6975\n","Epoch 80/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 2.7240 - val_accuracy: 0.6976\n","Epoch 81/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 2.7380 - val_accuracy: 0.6925\n","Epoch 82/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0616 - accuracy: 0.9788 - val_loss: 2.7552 - val_accuracy: 0.6926\n","Epoch 83/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.9813 - val_loss: 2.8445 - val_accuracy: 0.6900\n","Epoch 84/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0542 - accuracy: 0.9817 - val_loss: 2.9081 - val_accuracy: 0.6886\n","Epoch 85/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0595 - accuracy: 0.9789 - val_loss: 2.8127 - val_accuracy: 0.6962\n","Epoch 86/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 2.8969 - val_accuracy: 0.6911\n","Epoch 87/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0534 - accuracy: 0.9818 - val_loss: 3.0675 - val_accuracy: 0.6851\n","Epoch 88/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.9830 - val_loss: 2.9649 - val_accuracy: 0.6899\n","Epoch 89/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0533 - accuracy: 0.9816 - val_loss: 2.9915 - val_accuracy: 0.6917\n","Epoch 90/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0523 - accuracy: 0.9817 - val_loss: 2.8363 - val_accuracy: 0.6979\n","Epoch 91/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 2.8337 - val_accuracy: 0.7047\n","Epoch 92/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0516 - accuracy: 0.9824 - val_loss: 2.8915 - val_accuracy: 0.6991\n","Epoch 93/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0565 - accuracy: 0.9812 - val_loss: 2.9492 - val_accuracy: 0.6975\n","Epoch 94/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0502 - accuracy: 0.9820 - val_loss: 2.8856 - val_accuracy: 0.6904\n","Epoch 95/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 3.2562 - val_accuracy: 0.6798\n","Epoch 96/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0464 - accuracy: 0.9845 - val_loss: 2.8539 - val_accuracy: 0.6966\n","Epoch 97/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0438 - accuracy: 0.9851 - val_loss: 3.0547 - val_accuracy: 0.6871\n","Epoch 98/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0629 - accuracy: 0.9786 - val_loss: 2.8071 - val_accuracy: 0.6907\n","Epoch 99/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0364 - accuracy: 0.9874 - val_loss: 2.9915 - val_accuracy: 0.6908\n","Epoch 100/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0594 - accuracy: 0.9799 - val_loss: 3.1014 - val_accuracy: 0.6915\n","Accuracy of model 1:  0.6915000081062317\n","Epoch 1/100\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1901 - accuracy: 0.5731 - val_loss: 1.1316 - val_accuracy: 0.5925\n","Epoch 2/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.8855 - accuracy: 0.6868 - val_loss: 1.0399 - val_accuracy: 0.6406\n","Epoch 3/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.7775 - accuracy: 0.7241 - val_loss: 0.8720 - val_accuracy: 0.6884\n","Epoch 4/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.6971 - accuracy: 0.7539 - val_loss: 0.8510 - val_accuracy: 0.7005\n","Epoch 5/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.6341 - accuracy: 0.7757 - val_loss: 0.8685 - val_accuracy: 0.7025\n","Epoch 6/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.5839 - accuracy: 0.7929 - val_loss: 0.8928 - val_accuracy: 0.6966\n","Epoch 7/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.5290 - accuracy: 0.8138 - val_loss: 0.8833 - val_accuracy: 0.7048\n","Epoch 8/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.4906 - accuracy: 0.8264 - val_loss: 0.8331 - val_accuracy: 0.7258\n","Epoch 9/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.4607 - accuracy: 0.8369 - val_loss: 0.7841 - val_accuracy: 0.7429\n","Epoch 10/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.4110 - accuracy: 0.8534 - val_loss: 0.8853 - val_accuracy: 0.7214\n","Epoch 11/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.3800 - accuracy: 0.8658 - val_loss: 0.8906 - val_accuracy: 0.7315\n","Epoch 12/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.3494 - accuracy: 0.8764 - val_loss: 0.8963 - val_accuracy: 0.7367\n","Epoch 13/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.3138 - accuracy: 0.8883 - val_loss: 0.9649 - val_accuracy: 0.7205\n","Epoch 14/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.2937 - accuracy: 0.8943 - val_loss: 0.9384 - val_accuracy: 0.7339\n","Epoch 15/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.2703 - accuracy: 0.9038 - val_loss: 1.0083 - val_accuracy: 0.7299\n","Epoch 16/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.2478 - accuracy: 0.9108 - val_loss: 1.0195 - val_accuracy: 0.7291\n","Epoch 17/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.2349 - accuracy: 0.9143 - val_loss: 1.1243 - val_accuracy: 0.7202\n","Epoch 18/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.2053 - accuracy: 0.9247 - val_loss: 1.1483 - val_accuracy: 0.7233\n","Epoch 19/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1857 - accuracy: 0.9340 - val_loss: 1.1007 - val_accuracy: 0.7347\n","Epoch 20/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1810 - accuracy: 0.9351 - val_loss: 1.1047 - val_accuracy: 0.7441\n","Epoch 21/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1549 - accuracy: 0.9437 - val_loss: 1.3776 - val_accuracy: 0.7138\n","Epoch 22/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1466 - accuracy: 0.9486 - val_loss: 1.2187 - val_accuracy: 0.7410\n","Epoch 23/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1461 - accuracy: 0.9475 - val_loss: 1.3410 - val_accuracy: 0.7265\n","Epoch 24/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1325 - accuracy: 0.9512 - val_loss: 1.3508 - val_accuracy: 0.7256\n","Epoch 25/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1332 - accuracy: 0.9517 - val_loss: 1.2551 - val_accuracy: 0.7350\n","Epoch 26/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1150 - accuracy: 0.9601 - val_loss: 1.4581 - val_accuracy: 0.7292\n","Epoch 27/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1221 - accuracy: 0.9559 - val_loss: 1.3370 - val_accuracy: 0.7397\n","Epoch 28/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1207 - accuracy: 0.9568 - val_loss: 1.3752 - val_accuracy: 0.7313\n","Epoch 29/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.1121 - accuracy: 0.9606 - val_loss: 1.3937 - val_accuracy: 0.7275\n","Epoch 30/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0864 - accuracy: 0.9691 - val_loss: 1.5712 - val_accuracy: 0.7153\n","Epoch 31/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0927 - accuracy: 0.9667 - val_loss: 1.4440 - val_accuracy: 0.7348\n","Epoch 32/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0901 - accuracy: 0.9670 - val_loss: 1.4646 - val_accuracy: 0.7332\n","Epoch 33/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0887 - accuracy: 0.9679 - val_loss: 1.6207 - val_accuracy: 0.7285\n","Epoch 34/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0957 - accuracy: 0.9655 - val_loss: 1.5190 - val_accuracy: 0.7347\n","Epoch 35/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0836 - accuracy: 0.9697 - val_loss: 1.4997 - val_accuracy: 0.7382\n","Epoch 36/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0834 - accuracy: 0.9696 - val_loss: 1.7074 - val_accuracy: 0.7125\n","Epoch 37/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0798 - accuracy: 0.9720 - val_loss: 1.6571 - val_accuracy: 0.7132\n","Epoch 38/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0805 - accuracy: 0.9715 - val_loss: 1.5366 - val_accuracy: 0.7417\n","Epoch 39/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0735 - accuracy: 0.9745 - val_loss: 1.7515 - val_accuracy: 0.7175\n","Epoch 40/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 1.6862 - val_accuracy: 0.7320\n","Epoch 41/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0733 - accuracy: 0.9743 - val_loss: 1.6220 - val_accuracy: 0.7380\n","Epoch 42/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0790 - accuracy: 0.9721 - val_loss: 1.6223 - val_accuracy: 0.7358\n","Epoch 43/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0692 - accuracy: 0.9752 - val_loss: 1.6355 - val_accuracy: 0.7376\n","Epoch 44/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0644 - accuracy: 0.9775 - val_loss: 1.6085 - val_accuracy: 0.7317\n","Epoch 45/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0637 - accuracy: 0.9779 - val_loss: 1.6364 - val_accuracy: 0.7390\n","Epoch 46/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0722 - accuracy: 0.9736 - val_loss: 1.6796 - val_accuracy: 0.7368\n","Epoch 47/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0711 - accuracy: 0.9743 - val_loss: 1.6961 - val_accuracy: 0.7409\n","Epoch 48/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0666 - accuracy: 0.9773 - val_loss: 1.6946 - val_accuracy: 0.7314\n","Epoch 49/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 1.7663 - val_accuracy: 0.7297\n","Epoch 50/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0578 - accuracy: 0.9803 - val_loss: 1.7507 - val_accuracy: 0.7353\n","Epoch 51/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0614 - accuracy: 0.9788 - val_loss: 1.8080 - val_accuracy: 0.7363\n","Epoch 52/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0621 - accuracy: 0.9779 - val_loss: 1.7561 - val_accuracy: 0.7325\n","Epoch 53/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0559 - accuracy: 0.9803 - val_loss: 1.7148 - val_accuracy: 0.7306\n","Epoch 54/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0638 - accuracy: 0.9778 - val_loss: 1.8973 - val_accuracy: 0.7193\n","Epoch 55/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 2.0054 - val_accuracy: 0.7190\n","Epoch 56/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0576 - accuracy: 0.9798 - val_loss: 1.7126 - val_accuracy: 0.7293\n","Epoch 57/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0527 - accuracy: 0.9812 - val_loss: 1.7523 - val_accuracy: 0.7426\n","Epoch 58/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0517 - accuracy: 0.9824 - val_loss: 1.8650 - val_accuracy: 0.7337\n","Epoch 59/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0596 - accuracy: 0.9794 - val_loss: 1.7931 - val_accuracy: 0.7332\n","Epoch 60/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0470 - accuracy: 0.9830 - val_loss: 1.8083 - val_accuracy: 0.7394\n","Epoch 61/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0444 - accuracy: 0.9851 - val_loss: 1.8040 - val_accuracy: 0.7432\n","Epoch 62/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0597 - accuracy: 0.9790 - val_loss: 1.8563 - val_accuracy: 0.7282\n","Epoch 63/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0486 - accuracy: 0.9829 - val_loss: 1.8655 - val_accuracy: 0.7341\n","Epoch 64/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0579 - accuracy: 0.9800 - val_loss: 1.8404 - val_accuracy: 0.7403\n","Epoch 65/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 1.8960 - val_accuracy: 0.7423\n","Epoch 66/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0457 - accuracy: 0.9838 - val_loss: 1.8537 - val_accuracy: 0.7416\n","Epoch 67/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0415 - accuracy: 0.9856 - val_loss: 2.0019 - val_accuracy: 0.7317\n","Epoch 68/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0520 - accuracy: 0.9820 - val_loss: 1.9406 - val_accuracy: 0.7364\n","Epoch 69/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 1.9561 - val_accuracy: 0.7348\n","Epoch 70/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0536 - accuracy: 0.9819 - val_loss: 1.9573 - val_accuracy: 0.7312\n","Epoch 71/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0451 - accuracy: 0.9841 - val_loss: 1.8468 - val_accuracy: 0.7347\n","Epoch 72/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0482 - accuracy: 0.9834 - val_loss: 1.9782 - val_accuracy: 0.7301\n","Epoch 73/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0485 - accuracy: 0.9829 - val_loss: 2.0256 - val_accuracy: 0.7418\n","Epoch 74/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0375 - accuracy: 0.9869 - val_loss: 1.8929 - val_accuracy: 0.7313\n","Epoch 75/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0433 - accuracy: 0.9849 - val_loss: 2.0053 - val_accuracy: 0.7326\n","Epoch 76/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0500 - accuracy: 0.9827 - val_loss: 1.9601 - val_accuracy: 0.7271\n","Epoch 77/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 1.9874 - val_accuracy: 0.7373\n","Epoch 78/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 1.9537 - val_accuracy: 0.7396\n","Epoch 79/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0346 - accuracy: 0.9883 - val_loss: 2.0071 - val_accuracy: 0.7473\n","Epoch 80/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0492 - accuracy: 0.9825 - val_loss: 1.8859 - val_accuracy: 0.7440\n","Epoch 81/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0488 - accuracy: 0.9836 - val_loss: 1.9198 - val_accuracy: 0.7421\n","Epoch 82/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 1.9970 - val_accuracy: 0.7351\n","Epoch 83/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0318 - accuracy: 0.9889 - val_loss: 1.9680 - val_accuracy: 0.7385\n","Epoch 84/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 1.9271 - val_accuracy: 0.7367\n","Epoch 85/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0377 - accuracy: 0.9868 - val_loss: 2.0185 - val_accuracy: 0.7336\n","Epoch 86/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0479 - accuracy: 0.9844 - val_loss: 1.9832 - val_accuracy: 0.7219\n","Epoch 87/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 1.9658 - val_accuracy: 0.7428\n","Epoch 88/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0360 - accuracy: 0.9876 - val_loss: 2.0482 - val_accuracy: 0.7305\n","Epoch 89/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 2.0439 - val_accuracy: 0.7377\n","Epoch 90/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 2.1241 - val_accuracy: 0.7357\n","Epoch 91/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0362 - accuracy: 0.9880 - val_loss: 2.0314 - val_accuracy: 0.7229\n","Epoch 92/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0362 - accuracy: 0.9870 - val_loss: 1.9893 - val_accuracy: 0.7383\n","Epoch 93/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 2.0787 - val_accuracy: 0.7322\n","Epoch 94/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 2.0161 - val_accuracy: 0.7427\n","Epoch 95/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 2.2482 - val_accuracy: 0.7262\n","Epoch 96/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0360 - accuracy: 0.9875 - val_loss: 2.0734 - val_accuracy: 0.7367\n","Epoch 97/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 2.0789 - val_accuracy: 0.7402\n","Epoch 98/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0357 - accuracy: 0.9871 - val_loss: 2.0497 - val_accuracy: 0.7361\n","Epoch 99/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 2.1213 - val_accuracy: 0.7407\n","Epoch 100/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 1.9648 - val_accuracy: 0.7429\n","Accuracy of model 2:  0.742900013923645\n","Epoch 1/100\n","391/391 [==============================] - 6s 13ms/step - loss: 0.9337 - accuracy: 0.6736 - val_loss: 1.1497 - val_accuracy: 0.6116\n","Epoch 2/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.6542 - accuracy: 0.7691 - val_loss: 1.0089 - val_accuracy: 0.6626\n","Epoch 3/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.5372 - accuracy: 0.8106 - val_loss: 0.9100 - val_accuracy: 0.6992\n","Epoch 4/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.4620 - accuracy: 0.8363 - val_loss: 1.1374 - val_accuracy: 0.6719\n","Epoch 5/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.4060 - accuracy: 0.8551 - val_loss: 0.9988 - val_accuracy: 0.6993\n","Epoch 6/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.3348 - accuracy: 0.8807 - val_loss: 1.0544 - val_accuracy: 0.7055\n","Epoch 7/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.2992 - accuracy: 0.8929 - val_loss: 1.0521 - val_accuracy: 0.7090\n","Epoch 8/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.2666 - accuracy: 0.9050 - val_loss: 1.0722 - val_accuracy: 0.7090\n","Epoch 9/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.2321 - accuracy: 0.9168 - val_loss: 1.2260 - val_accuracy: 0.7037\n","Epoch 10/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.2061 - accuracy: 0.9258 - val_loss: 1.3033 - val_accuracy: 0.6832\n","Epoch 11/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1851 - accuracy: 0.9335 - val_loss: 1.3715 - val_accuracy: 0.6944\n","Epoch 12/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1677 - accuracy: 0.9397 - val_loss: 1.3085 - val_accuracy: 0.7037\n","Epoch 13/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1557 - accuracy: 0.9440 - val_loss: 1.4744 - val_accuracy: 0.6795\n","Epoch 14/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1465 - accuracy: 0.9476 - val_loss: 1.4142 - val_accuracy: 0.6918\n","Epoch 15/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1347 - accuracy: 0.9511 - val_loss: 1.5301 - val_accuracy: 0.6962\n","Epoch 16/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1266 - accuracy: 0.9531 - val_loss: 1.5654 - val_accuracy: 0.6965\n","Epoch 17/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1201 - accuracy: 0.9574 - val_loss: 1.5811 - val_accuracy: 0.6992\n","Epoch 18/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1131 - accuracy: 0.9600 - val_loss: 1.5828 - val_accuracy: 0.6884\n","Epoch 19/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1066 - accuracy: 0.9623 - val_loss: 1.4848 - val_accuracy: 0.6997\n","Epoch 20/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.1114 - accuracy: 0.9601 - val_loss: 1.4334 - val_accuracy: 0.7028\n","Epoch 21/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0967 - accuracy: 0.9654 - val_loss: 1.5685 - val_accuracy: 0.7012\n","Epoch 22/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0960 - accuracy: 0.9662 - val_loss: 1.5874 - val_accuracy: 0.6977\n","Epoch 23/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0990 - accuracy: 0.9652 - val_loss: 1.6239 - val_accuracy: 0.7054\n","Epoch 24/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0876 - accuracy: 0.9687 - val_loss: 1.6217 - val_accuracy: 0.7047\n","Epoch 25/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0832 - accuracy: 0.9705 - val_loss: 1.5148 - val_accuracy: 0.7141\n","Epoch 26/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0887 - accuracy: 0.9680 - val_loss: 1.8524 - val_accuracy: 0.6954\n","Epoch 27/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0928 - accuracy: 0.9675 - val_loss: 2.0255 - val_accuracy: 0.6738\n","Epoch 28/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0819 - accuracy: 0.9706 - val_loss: 1.6207 - val_accuracy: 0.6995\n","Epoch 29/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0827 - accuracy: 0.9714 - val_loss: 1.5207 - val_accuracy: 0.7136\n","Epoch 30/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0748 - accuracy: 0.9739 - val_loss: 1.8878 - val_accuracy: 0.6923\n","Epoch 31/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0752 - accuracy: 0.9739 - val_loss: 1.8287 - val_accuracy: 0.6847\n","Epoch 32/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0784 - accuracy: 0.9732 - val_loss: 1.7059 - val_accuracy: 0.7070\n","Epoch 33/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0666 - accuracy: 0.9772 - val_loss: 1.6864 - val_accuracy: 0.7104\n","Epoch 34/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0727 - accuracy: 0.9746 - val_loss: 1.7608 - val_accuracy: 0.6951\n","Epoch 35/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0716 - accuracy: 0.9750 - val_loss: 1.5875 - val_accuracy: 0.7101\n","Epoch 36/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0683 - accuracy: 0.9765 - val_loss: 1.6504 - val_accuracy: 0.7154\n","Epoch 37/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 1.7082 - val_accuracy: 0.7035\n","Epoch 38/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0703 - accuracy: 0.9760 - val_loss: 1.7053 - val_accuracy: 0.7125\n","Epoch 39/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0554 - accuracy: 0.9801 - val_loss: 1.8443 - val_accuracy: 0.7044\n","Epoch 40/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0626 - accuracy: 0.9775 - val_loss: 1.6894 - val_accuracy: 0.7060\n","Epoch 41/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0679 - accuracy: 0.9762 - val_loss: 1.7208 - val_accuracy: 0.7091\n","Epoch 42/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0645 - accuracy: 0.9776 - val_loss: 1.6393 - val_accuracy: 0.7106\n","Epoch 43/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0534 - accuracy: 0.9815 - val_loss: 1.8069 - val_accuracy: 0.7096\n","Epoch 44/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0689 - accuracy: 0.9765 - val_loss: 1.7012 - val_accuracy: 0.7170\n","Epoch 45/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0609 - accuracy: 0.9789 - val_loss: 1.6279 - val_accuracy: 0.7235\n","Epoch 46/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0565 - accuracy: 0.9805 - val_loss: 1.7200 - val_accuracy: 0.7187\n","Epoch 47/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0550 - accuracy: 0.9804 - val_loss: 1.7309 - val_accuracy: 0.7084\n","Epoch 48/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0490 - accuracy: 0.9835 - val_loss: 1.7206 - val_accuracy: 0.7210\n","Epoch 49/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0568 - accuracy: 0.9806 - val_loss: 1.6868 - val_accuracy: 0.7188\n","Epoch 50/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 1.6734 - val_accuracy: 0.7194\n","Epoch 51/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0538 - accuracy: 0.9814 - val_loss: 1.8603 - val_accuracy: 0.7017\n","Epoch 52/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0469 - accuracy: 0.9839 - val_loss: 1.8904 - val_accuracy: 0.7090\n","Epoch 53/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0560 - accuracy: 0.9806 - val_loss: 1.8024 - val_accuracy: 0.7199\n","Epoch 54/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0529 - accuracy: 0.9816 - val_loss: 1.6863 - val_accuracy: 0.7187\n","Epoch 55/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0504 - accuracy: 0.9831 - val_loss: 1.6856 - val_accuracy: 0.7156\n","Epoch 56/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 1.7625 - val_accuracy: 0.7136\n","Epoch 57/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 2.0573 - val_accuracy: 0.6918\n","Epoch 58/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0527 - accuracy: 0.9816 - val_loss: 1.8326 - val_accuracy: 0.6999\n","Epoch 59/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0448 - accuracy: 0.9849 - val_loss: 1.9066 - val_accuracy: 0.7118\n","Epoch 60/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 1.7996 - val_accuracy: 0.7210\n","Epoch 61/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0413 - accuracy: 0.9862 - val_loss: 1.9189 - val_accuracy: 0.7141\n","Epoch 62/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 1.7864 - val_accuracy: 0.7177\n","Epoch 63/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0474 - accuracy: 0.9834 - val_loss: 1.8538 - val_accuracy: 0.7133\n","Epoch 64/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0421 - accuracy: 0.9853 - val_loss: 1.8286 - val_accuracy: 0.7094\n","Epoch 65/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0432 - accuracy: 0.9854 - val_loss: 1.7784 - val_accuracy: 0.7201\n","Epoch 66/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 1.9691 - val_accuracy: 0.7093\n","Epoch 67/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 1.8903 - val_accuracy: 0.7105\n","Epoch 68/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0421 - accuracy: 0.9859 - val_loss: 1.8641 - val_accuracy: 0.7181\n","Epoch 69/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0427 - accuracy: 0.9848 - val_loss: 1.8521 - val_accuracy: 0.7187\n","Epoch 70/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 1.9041 - val_accuracy: 0.7086\n","Epoch 71/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0427 - accuracy: 0.9854 - val_loss: 1.7996 - val_accuracy: 0.7100\n","Epoch 72/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 1.8801 - val_accuracy: 0.7226\n","Epoch 73/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0360 - accuracy: 0.9876 - val_loss: 1.8444 - val_accuracy: 0.7166\n","Epoch 74/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0351 - accuracy: 0.9881 - val_loss: 2.0025 - val_accuracy: 0.7093\n","Epoch 75/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0427 - accuracy: 0.9855 - val_loss: 1.7571 - val_accuracy: 0.7191\n","Epoch 76/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 2.0511 - val_accuracy: 0.7047\n","Epoch 77/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 1.8744 - val_accuracy: 0.7134\n","Epoch 78/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0395 - accuracy: 0.9862 - val_loss: 1.9561 - val_accuracy: 0.7078\n","Epoch 79/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 1.9864 - val_accuracy: 0.7142\n","Epoch 80/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0354 - accuracy: 0.9879 - val_loss: 1.8825 - val_accuracy: 0.7206\n","Epoch 81/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 1.8569 - val_accuracy: 0.7214\n","Epoch 82/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 1.9802 - val_accuracy: 0.7163\n","Epoch 83/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 2.0582 - val_accuracy: 0.7075\n","Epoch 84/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0405 - accuracy: 0.9859 - val_loss: 1.8584 - val_accuracy: 0.7262\n","Epoch 85/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0419 - accuracy: 0.9854 - val_loss: 1.8612 - val_accuracy: 0.7116\n","Epoch 86/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 2.1712 - val_accuracy: 0.7135\n","Epoch 87/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0304 - accuracy: 0.9894 - val_loss: 1.8963 - val_accuracy: 0.7126\n","Epoch 88/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0385 - accuracy: 0.9873 - val_loss: 1.9787 - val_accuracy: 0.7049\n","Epoch 89/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 1.8949 - val_accuracy: 0.7100\n","Epoch 90/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0360 - accuracy: 0.9881 - val_loss: 1.8479 - val_accuracy: 0.7227\n","Epoch 91/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 2.0640 - val_accuracy: 0.7132\n","Epoch 92/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0331 - accuracy: 0.9889 - val_loss: 1.9432 - val_accuracy: 0.7186\n","Epoch 93/100\n","391/391 [==============================] - 5s 13ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 1.8826 - val_accuracy: 0.7200\n","Epoch 94/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 1.9437 - val_accuracy: 0.7196\n","Epoch 95/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 1.9825 - val_accuracy: 0.7163\n","Epoch 96/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 2.0324 - val_accuracy: 0.7131\n","Epoch 97/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 2.1120 - val_accuracy: 0.7032\n","Epoch 98/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 2.0676 - val_accuracy: 0.7072\n","Epoch 99/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0314 - accuracy: 0.9895 - val_loss: 1.9106 - val_accuracy: 0.7200\n","Epoch 100/100\n","391/391 [==============================] - 5s 12ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 2.1056 - val_accuracy: 0.7209\n","Accuracy of model 3:  0.7208999991416931\n","Epoch 1/100\n","391/391 [==============================] - 8s 17ms/step - loss: 0.3631 - accuracy: 0.8835 - val_loss: 1.2373 - val_accuracy: 0.6793\n","Epoch 2/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.2721 - accuracy: 0.9093 - val_loss: 1.4354 - val_accuracy: 0.6726\n","Epoch 3/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.2433 - accuracy: 0.9167 - val_loss: 1.3411 - val_accuracy: 0.6725\n","Epoch 4/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.2217 - accuracy: 0.9248 - val_loss: 1.4793 - val_accuracy: 0.6586\n","Epoch 5/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.2092 - accuracy: 0.9293 - val_loss: 1.3444 - val_accuracy: 0.6731\n","Epoch 6/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1904 - accuracy: 0.9357 - val_loss: 1.3884 - val_accuracy: 0.6752\n","Epoch 7/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1762 - accuracy: 0.9410 - val_loss: 1.4582 - val_accuracy: 0.6707\n","Epoch 8/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1687 - accuracy: 0.9421 - val_loss: 1.4737 - val_accuracy: 0.6724\n","Epoch 9/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1609 - accuracy: 0.9461 - val_loss: 1.4339 - val_accuracy: 0.6778\n","Epoch 10/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1512 - accuracy: 0.9474 - val_loss: 1.4581 - val_accuracy: 0.6810\n","Epoch 11/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1438 - accuracy: 0.9516 - val_loss: 1.4564 - val_accuracy: 0.6899\n","Epoch 12/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1376 - accuracy: 0.9531 - val_loss: 1.6039 - val_accuracy: 0.6609\n","Epoch 13/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1361 - accuracy: 0.9532 - val_loss: 1.4519 - val_accuracy: 0.6906\n","Epoch 14/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1277 - accuracy: 0.9566 - val_loss: 1.5833 - val_accuracy: 0.6680\n","Epoch 15/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1180 - accuracy: 0.9601 - val_loss: 1.5263 - val_accuracy: 0.6868\n","Epoch 16/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1232 - accuracy: 0.9582 - val_loss: 1.4663 - val_accuracy: 0.6884\n","Epoch 17/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1104 - accuracy: 0.9617 - val_loss: 1.5277 - val_accuracy: 0.6880\n","Epoch 18/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1125 - accuracy: 0.9622 - val_loss: 1.4701 - val_accuracy: 0.6831\n","Epoch 19/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1101 - accuracy: 0.9625 - val_loss: 1.6638 - val_accuracy: 0.6780\n","Epoch 20/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1049 - accuracy: 0.9655 - val_loss: 1.4644 - val_accuracy: 0.6925\n","Epoch 21/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1032 - accuracy: 0.9646 - val_loss: 1.5578 - val_accuracy: 0.6844\n","Epoch 22/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0949 - accuracy: 0.9680 - val_loss: 1.5437 - val_accuracy: 0.6936\n","Epoch 23/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1015 - accuracy: 0.9647 - val_loss: 1.6557 - val_accuracy: 0.6692\n","Epoch 24/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0932 - accuracy: 0.9682 - val_loss: 1.5351 - val_accuracy: 0.6876\n","Epoch 25/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0898 - accuracy: 0.9704 - val_loss: 1.4820 - val_accuracy: 0.6967\n","Epoch 26/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0891 - accuracy: 0.9694 - val_loss: 1.5726 - val_accuracy: 0.6919\n","Epoch 27/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0898 - accuracy: 0.9695 - val_loss: 1.5457 - val_accuracy: 0.6959\n","Epoch 28/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0855 - accuracy: 0.9712 - val_loss: 1.5906 - val_accuracy: 0.6726\n","Epoch 29/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0790 - accuracy: 0.9734 - val_loss: 1.6284 - val_accuracy: 0.6891\n","Epoch 30/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0819 - accuracy: 0.9726 - val_loss: 1.5524 - val_accuracy: 0.6949\n","Epoch 31/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0795 - accuracy: 0.9736 - val_loss: 1.6116 - val_accuracy: 0.6881\n","Epoch 32/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0823 - accuracy: 0.9722 - val_loss: 1.5436 - val_accuracy: 0.6871\n","Epoch 33/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0774 - accuracy: 0.9739 - val_loss: 1.6504 - val_accuracy: 0.6870\n","Epoch 34/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 1.6219 - val_accuracy: 0.6915\n","Epoch 35/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0712 - accuracy: 0.9758 - val_loss: 1.6640 - val_accuracy: 0.6943\n","Epoch 36/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0762 - accuracy: 0.9753 - val_loss: 1.5843 - val_accuracy: 0.6879\n","Epoch 37/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0721 - accuracy: 0.9760 - val_loss: 1.5639 - val_accuracy: 0.6928\n","Epoch 38/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0679 - accuracy: 0.9774 - val_loss: 1.6735 - val_accuracy: 0.6960\n","Epoch 39/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0686 - accuracy: 0.9768 - val_loss: 1.6719 - val_accuracy: 0.6967\n","Epoch 40/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0673 - accuracy: 0.9774 - val_loss: 1.7021 - val_accuracy: 0.6934\n","Epoch 41/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0679 - accuracy: 0.9768 - val_loss: 1.6503 - val_accuracy: 0.6892\n","Epoch 42/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0636 - accuracy: 0.9780 - val_loss: 1.6678 - val_accuracy: 0.6956\n","Epoch 43/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0619 - accuracy: 0.9795 - val_loss: 1.6673 - val_accuracy: 0.6960\n","Epoch 44/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0603 - accuracy: 0.9795 - val_loss: 1.6635 - val_accuracy: 0.7051\n","Epoch 45/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 1.6994 - val_accuracy: 0.6875\n","Epoch 46/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0597 - accuracy: 0.9797 - val_loss: 1.5960 - val_accuracy: 0.7046\n","Epoch 47/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0595 - accuracy: 0.9798 - val_loss: 1.5864 - val_accuracy: 0.7102\n","Epoch 48/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 1.7698 - val_accuracy: 0.6801\n","Epoch 49/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0620 - accuracy: 0.9793 - val_loss: 1.5866 - val_accuracy: 0.6991\n","Epoch 50/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0566 - accuracy: 0.9809 - val_loss: 1.6024 - val_accuracy: 0.6990\n","Epoch 51/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0529 - accuracy: 0.9825 - val_loss: 1.7449 - val_accuracy: 0.6926\n","Epoch 52/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0536 - accuracy: 0.9814 - val_loss: 1.7591 - val_accuracy: 0.6888\n","Epoch 53/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0529 - accuracy: 0.9821 - val_loss: 1.6543 - val_accuracy: 0.7050\n","Epoch 54/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0607 - accuracy: 0.9792 - val_loss: 1.5855 - val_accuracy: 0.6968\n","Epoch 55/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0520 - accuracy: 0.9823 - val_loss: 1.7314 - val_accuracy: 0.6941\n","Epoch 56/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0476 - accuracy: 0.9839 - val_loss: 1.6841 - val_accuracy: 0.6976\n","Epoch 57/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0531 - accuracy: 0.9822 - val_loss: 1.6305 - val_accuracy: 0.7037\n","Epoch 58/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 1.5542 - val_accuracy: 0.6964\n","Epoch 59/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0476 - accuracy: 0.9836 - val_loss: 1.7238 - val_accuracy: 0.6988\n","Epoch 60/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0513 - accuracy: 0.9824 - val_loss: 1.6558 - val_accuracy: 0.7014\n","Epoch 61/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 1.7062 - val_accuracy: 0.7029\n","Epoch 62/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 1.6324 - val_accuracy: 0.7056\n","Epoch 63/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 1.6624 - val_accuracy: 0.7096\n","Epoch 64/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0442 - accuracy: 0.9849 - val_loss: 1.6967 - val_accuracy: 0.6973\n","Epoch 65/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0487 - accuracy: 0.9834 - val_loss: 1.6247 - val_accuracy: 0.7077\n","Epoch 66/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0453 - accuracy: 0.9844 - val_loss: 1.7402 - val_accuracy: 0.7034\n","Epoch 67/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 1.6777 - val_accuracy: 0.6999\n","Epoch 68/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0426 - accuracy: 0.9856 - val_loss: 1.6622 - val_accuracy: 0.7053\n","Epoch 69/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0407 - accuracy: 0.9866 - val_loss: 1.6218 - val_accuracy: 0.7071\n","Epoch 70/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 1.7371 - val_accuracy: 0.7049\n","Epoch 71/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0433 - accuracy: 0.9853 - val_loss: 1.7792 - val_accuracy: 0.7035\n","Epoch 72/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 1.7607 - val_accuracy: 0.6997\n","Epoch 73/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 1.7036 - val_accuracy: 0.7060\n","Epoch 74/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 1.6970 - val_accuracy: 0.7122\n","Epoch 75/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 1.7279 - val_accuracy: 0.7006\n","Epoch 76/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0412 - accuracy: 0.9864 - val_loss: 1.7604 - val_accuracy: 0.6957\n","Epoch 77/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0385 - accuracy: 0.9871 - val_loss: 1.7344 - val_accuracy: 0.7028\n","Epoch 78/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0382 - accuracy: 0.9875 - val_loss: 1.7391 - val_accuracy: 0.7021\n","Epoch 79/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0445 - accuracy: 0.9849 - val_loss: 1.6515 - val_accuracy: 0.7141\n","Epoch 80/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0366 - accuracy: 0.9877 - val_loss: 1.7622 - val_accuracy: 0.7122\n","Epoch 81/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 1.7427 - val_accuracy: 0.7014\n","Epoch 82/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 1.6671 - val_accuracy: 0.7018\n","Epoch 83/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 1.7155 - val_accuracy: 0.7049\n","Epoch 84/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0360 - accuracy: 0.9880 - val_loss: 1.6046 - val_accuracy: 0.7082\n","Epoch 85/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 1.6763 - val_accuracy: 0.7086\n","Epoch 86/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0360 - accuracy: 0.9875 - val_loss: 1.8232 - val_accuracy: 0.6883\n","Epoch 87/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 1.6866 - val_accuracy: 0.7065\n","Epoch 88/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 1.7320 - val_accuracy: 0.7101\n","Epoch 89/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 1.7952 - val_accuracy: 0.7077\n","Epoch 90/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 1.6909 - val_accuracy: 0.7069\n","Epoch 91/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0311 - accuracy: 0.9894 - val_loss: 1.8577 - val_accuracy: 0.7071\n","Epoch 92/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 1.6513 - val_accuracy: 0.7116\n","Epoch 93/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 1.6993 - val_accuracy: 0.7047\n","Epoch 94/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0347 - accuracy: 0.9880 - val_loss: 1.7970 - val_accuracy: 0.7069\n","Epoch 95/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 1.6918 - val_accuracy: 0.7090\n","Epoch 96/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0331 - accuracy: 0.9892 - val_loss: 1.7083 - val_accuracy: 0.7114\n","Epoch 97/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 1.6734 - val_accuracy: 0.7151\n","Epoch 98/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 1.7357 - val_accuracy: 0.7131\n","Epoch 99/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 1.7609 - val_accuracy: 0.7026\n","Epoch 100/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 1.6881 - val_accuracy: 0.7127\n","Accuracy of model 4:  0.7127000093460083\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pM1cIwzUTGyt","executionInfo":{"status":"ok","timestamp":1627300207215,"user_tz":-330,"elapsed":13,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"aeffad34-4785-436e-d244-d76a781dcac8"},"source":["accuracies_time"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['-------------',\n"," (0.7114999890327454, 40.577197790145874),\n"," (0.6974999904632568, 60.86579668521881),\n"," (0.684499979019165, 81.15439558029175),\n"," (0.6887000203132629, 101.44299447536469),\n"," (0.694100022315979, 121.73159337043762),\n"," (0.6899999976158142, 142.02019226551056),\n"," (0.6976000070571899, 162.3087911605835),\n"," (0.6978999972343445, 182.59739005565643),\n"," (0.6915000081062317, 202.88598895072937),\n"," '-------------',\n"," (0.7440999746322632, 76.60340957641601),\n"," (0.7153000235557556, 114.90511436462403),\n"," (0.7319999933242798, 153.20681915283203),\n"," (0.7353000044822693, 191.50852394104004),\n"," (0.7394000291824341, 229.81022872924805),\n"," (0.7311999797821045, 268.11193351745607),\n"," (0.7440000176429749, 306.41363830566405),\n"," (0.7357000112533569, 344.7153430938721),\n"," (0.742900013923645, 383.0170478820801),\n"," '-------------',\n"," (0.7027999758720398, 100.65457973480224),\n"," (0.692300021648407, 150.98186960220337),\n"," (0.7059999704360962, 201.30915946960448),\n"," (0.7193999886512756, 251.63644933700562),\n"," (0.7210000157356262, 301.96373920440675),\n"," (0.7085999846458435, 352.2910290718079),\n"," (0.7206000089645386, 402.61831893920896),\n"," (0.7226999998092651, 452.9456088066101),\n"," (0.7208999991416931, 503.27289867401123),\n"," '-------------',\n"," (0.6924999952316284, 124.78872542381286),\n"," (0.6948999762535095, 187.1830881357193),\n"," (0.6934000253677368, 249.57745084762573),\n"," (0.6990000009536743, 311.97181355953217),\n"," (0.7013999819755554, 374.3661762714386),\n"," (0.7049000263214111, 436.76053898334504),\n"," (0.7121999859809875, 499.15490169525145),\n"," (0.7069000005722046, 561.5492644071579),\n"," (0.7127000093460083, 623.9436271190643)]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"95vdrneiPkvh"},"source":[""],"execution_count":null,"outputs":[]}]}