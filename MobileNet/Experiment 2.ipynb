{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment 2.ipynb","provenance":[{"file_id":"1qQ_0RaSDUXo_uEbw1vvx3nPGsLtg7iBu","timestamp":1623870104154},{"file_id":"1cGXeoDEMw72Qwq_JddSrkccvR6jR01V_","timestamp":1622991507291}],"collapsed_sections":[],"mount_file_id":"17Iz4RRd3kwVu86Q6pXnivCS8HLyCt1V3","authorship_tag":"ABX9TyObZWT6e3cmq0/Q8Ht2i1Vd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iA1lWtoCvBnP"},"source":["### **HERE EXIT NETWORKS HAVE BEEN ADDED IN MOBILENET NETWORK**"]},{"cell_type":"code","metadata":{"id":"EhRVl-j9XISJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627298029635,"user_tz":-330,"elapsed":10628,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"b1877d74-6839-49f0-ab65-399c6b533999"},"source":["from tensorflow.keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 6s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSpWlE_jfAFQ","executionInfo":{"status":"ok","timestamp":1627298033524,"user_tz":-330,"elapsed":3902,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"7580bb81-f39b-4491-ce96-7191497f6f43"},"source":["# example of loading the MobileNet model\n","from tensorflow.keras.applications.mobilenet import MobileNet\n","# load model\n","model = MobileNet(input_shape=(32,32,3), include_top=False, weights=None)\n","# summarize the model\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"mobilenet_1.00_32\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)         2304      \n","_________________________________________________________________\n","conv_dw_6_bn (BatchNormaliza (None, 2, 2, 256)         1024      \n","_________________________________________________________________\n","conv_dw_6_relu (ReLU)        (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","conv_pw_6 (Conv2D)           (None, 2, 2, 512)         131072    \n","_________________________________________________________________\n","conv_pw_6_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_6_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_7 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_8 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_9 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_10 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_10 (Conv2D)          (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_11 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_11 (Conv2D)          (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n","_________________________________________________________________\n","conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n","_________________________________________________________________\n","conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n","_________________________________________________________________\n","conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n","_________________________________________________________________\n","conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n","_________________________________________________________________\n","conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n","_________________________________________________________________\n","conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n","=================================================================\n","Total params: 3,228,864\n","Trainable params: 3,206,976\n","Non-trainable params: 21,888\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWPVP0KFNY_P","executionInfo":{"status":"ok","timestamp":1627298033525,"user_tz":-330,"elapsed":94,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"e317e5d3-e6af-4265-a463-9d1785030175"},"source":["len(model.layers)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["86"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"6enOD5B6OAiZ"},"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QYrda208Nh56","executionInfo":{"status":"ok","timestamp":1627298033527,"user_tz":-330,"elapsed":65,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"87ae8612-cf1d-47a9-a5d8-a2f2abb0c37e"},"source":["i = 0\n","exits = []\n","for layer in model.layers:\n","  if 'pad' in layer.name:\n","    print(i, layer.output_shape)\n","    exits.append(i)\n","  i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10 (None, 17, 17, 64)\n","23 (None, 9, 9, 128)\n","36 (None, 5, 5, 256)\n","73 (None, 3, 3, 512)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p9tH_ROcvkFj"},"source":["## **ADDITION OF EXIT NETWORK**"]},{"cell_type":"code","metadata":{"id":"5AzuwnTDSOSf"},"source":["exit_layer1 = model.layers[10]\n","exit_layer2 = model.layers[23]\n","exit_layer3 = model.layers[36]\n","exit_layer4 = model.layers[73]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vII6zf4pNIK"},"source":["exit_models = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gz-OYNBTdRO","executionInfo":{"status":"ok","timestamp":1627298033531,"user_tz":-330,"elapsed":63,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"e191c5e4-cc92-4174-da0f-b3d9ac868c47"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","pool1 = MaxPooling2D((3,3), strides=(3,3))(exit_layer1.output)\n","conv1 = Conv2D(128, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model1 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model1)\n","exit_model1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 5, 5, 128)         73856     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               65664     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 144,522\n","Trainable params: 144,266\n","Non-trainable params: 256\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5OL3CceSEEL","executionInfo":{"status":"ok","timestamp":1627298033532,"user_tz":-330,"elapsed":60,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"2b472905-a34c-4475-932a-467b06b3c62b"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","pool1 = MaxPooling2D((3,3), strides=(3,3))(exit_layer2.output)\n","conv1 = Conv2D(256, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model2 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model2)\n","exit_model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 3, 3, 256)         295168    \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 361,162\n","Trainable params: 360,010\n","Non-trainable params: 1,152\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jW--RdXSSfj","executionInfo":{"status":"ok","timestamp":1627298033533,"user_tz":-330,"elapsed":54,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"06b51fac-ca77-43f4-9bca-11b14cdf0392"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer3.output)\n","conv1 = Conv2D(512, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model3 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model3)\n","exit_model3.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 2, 2, 512)         1180160   \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               65664     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,384,266\n","Trainable params: 1,381,322\n","Non-trainable params: 2,944\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XwmZ_Ntorkl","executionInfo":{"status":"ok","timestamp":1627298033534,"user_tz":-330,"elapsed":46,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"0814a56b-da49-4f22-cc86-8776e1581ff4"},"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer4.output)\n","#conv1 = Conv2D(512, (3,3), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","#pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool1)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model4 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model4)\n","exit_model4.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 16, 16, 32)        864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)         2304      \n","_________________________________________________________________\n","conv_dw_6_bn (BatchNormaliza (None, 2, 2, 256)         1024      \n","_________________________________________________________________\n","conv_dw_6_relu (ReLU)        (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","conv_pw_6 (Conv2D)           (None, 2, 2, 512)         131072    \n","_________________________________________________________________\n","conv_pw_6_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_6_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_7 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_8 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_9 (Conv2D)           (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_10 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_10 (Conv2D)          (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_dw_11 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n","_________________________________________________________________\n","conv_dw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_dw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pw_11 (Conv2D)          (None, 2, 2, 512)         262144    \n","_________________________________________________________________\n","conv_pw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","conv_pw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               65664     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,694,794\n","Trainable params: 1,680,074\n","Non-trainable params: 14,720\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDdgNEwKpf_8","executionInfo":{"status":"ok","timestamp":1627298033534,"user_tz":-330,"elapsed":37,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"8a087e56-2151-4274-c469-2287fad76ff9"},"source":["exit_models"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tensorflow.python.keras.engine.functional.Functional at 0x7f052211f810>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f0503fbc3d0>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f0503fd5e10>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f05220929d0>]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"qs5OkuHGkCcX"},"source":["for model in exit_models:\n","  model.compile(\n","          optimizer='adam',\n","          loss='sparse_categorical_crossentropy',\n","          metrics=['accuracy']\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"674iH9cpNURO"},"source":["import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5GvpA1ElIqe","executionInfo":{"status":"ok","timestamp":1627299570551,"user_tz":-330,"elapsed":290269,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"fb72937e-283d-4790-e47a-7dcfafa86738"},"source":["i = 1\n","accuracies_time = []\n","for model in exit_models:\n","  accuracies_time.append('-------------')\n","  start = time.time()\n","  history = model.fit(\n","      x=x_train,\n","      y=y_train,\n","      epochs=100,\n","      verbose=1,\n","      validation_data=(x_test, y_test),\n","      batch_size=128\n","  )\n","  end = time.time()\n","  accuracies_time.append(((history.history.get('val_accuracy')[19]), (end-start)*2/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[29]), (end-start)*3/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[39]), (end-start)*4/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[49]), (end-start)*5/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[59]), (end-start)*6/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[69]), (end-start)*7/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[79]), (end-start)*8/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[89]), (end-start)*9/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[99]), (end-start)*10/10))\n","  Model(inputs = model.inputs, outputs = model.layers[exits[i-1]].output).save_weights(f\"/MobileNet/EarlyExit_till_exit{i}_weights.h5\")\n","  print(\"Saved!\")\n","  print(f\"Accuracy of model {i}: \", history.history.get('val_accuracy')[len(history.history.get('val_accuracy')) - 1])\n","  i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","391/391 [==============================] - 18s 5ms/step - loss: 1.5227 - accuracy: 0.4506 - val_loss: 1.4665 - val_accuracy: 0.4605\n","Epoch 2/100\n","391/391 [==============================] - 2s 4ms/step - loss: 1.1530 - accuracy: 0.5927 - val_loss: 1.1101 - val_accuracy: 0.5994\n","Epoch 3/100\n","391/391 [==============================] - 2s 4ms/step - loss: 1.0123 - accuracy: 0.6444 - val_loss: 1.0881 - val_accuracy: 0.6124\n","Epoch 4/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.9182 - accuracy: 0.6784 - val_loss: 0.9568 - val_accuracy: 0.6660\n","Epoch 5/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.8427 - accuracy: 0.7035 - val_loss: 0.9531 - val_accuracy: 0.6638\n","Epoch 6/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.7871 - accuracy: 0.7257 - val_loss: 0.9297 - val_accuracy: 0.6794\n","Epoch 7/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.7325 - accuracy: 0.7428 - val_loss: 0.9958 - val_accuracy: 0.6616\n","Epoch 8/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.6850 - accuracy: 0.7600 - val_loss: 0.9999 - val_accuracy: 0.6619\n","Epoch 9/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.6443 - accuracy: 0.7745 - val_loss: 0.9233 - val_accuracy: 0.6902\n","Epoch 10/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.6061 - accuracy: 0.7885 - val_loss: 0.9985 - val_accuracy: 0.6748\n","Epoch 11/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.5682 - accuracy: 0.8005 - val_loss: 0.8960 - val_accuracy: 0.7061\n","Epoch 12/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.5403 - accuracy: 0.8072 - val_loss: 0.9448 - val_accuracy: 0.6898\n","Epoch 13/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.5038 - accuracy: 0.8217 - val_loss: 0.9282 - val_accuracy: 0.7054\n","Epoch 14/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4706 - accuracy: 0.8307 - val_loss: 1.0119 - val_accuracy: 0.6913\n","Epoch 15/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4462 - accuracy: 0.8418 - val_loss: 0.9798 - val_accuracy: 0.6999\n","Epoch 16/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.4081 - accuracy: 0.8544 - val_loss: 1.1281 - val_accuracy: 0.6709\n","Epoch 17/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3823 - accuracy: 0.8654 - val_loss: 1.0636 - val_accuracy: 0.6905\n","Epoch 18/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8739 - val_loss: 1.0878 - val_accuracy: 0.6939\n","Epoch 19/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.3306 - accuracy: 0.8820 - val_loss: 1.1013 - val_accuracy: 0.6893\n","Epoch 20/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.3122 - accuracy: 0.8892 - val_loss: 1.2252 - val_accuracy: 0.6849\n","Epoch 21/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2910 - accuracy: 0.8966 - val_loss: 1.3603 - val_accuracy: 0.6653\n","Epoch 22/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2718 - accuracy: 0.9035 - val_loss: 1.2412 - val_accuracy: 0.6858\n","Epoch 23/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2533 - accuracy: 0.9094 - val_loss: 1.3292 - val_accuracy: 0.6830\n","Epoch 24/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2315 - accuracy: 0.9171 - val_loss: 1.3320 - val_accuracy: 0.6925\n","Epoch 25/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.2214 - accuracy: 0.9216 - val_loss: 1.3472 - val_accuracy: 0.6857\n","Epoch 26/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.2143 - accuracy: 0.9234 - val_loss: 1.3767 - val_accuracy: 0.7006\n","Epoch 27/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1910 - accuracy: 0.9310 - val_loss: 1.5566 - val_accuracy: 0.6750\n","Epoch 28/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1813 - accuracy: 0.9354 - val_loss: 1.5238 - val_accuracy: 0.6801\n","Epoch 29/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1746 - accuracy: 0.9365 - val_loss: 1.6087 - val_accuracy: 0.6761\n","Epoch 30/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1596 - accuracy: 0.9417 - val_loss: 1.6665 - val_accuracy: 0.6808\n","Epoch 31/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1459 - accuracy: 0.9484 - val_loss: 1.7282 - val_accuracy: 0.6782\n","Epoch 32/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1400 - accuracy: 0.9495 - val_loss: 1.7322 - val_accuracy: 0.6747\n","Epoch 33/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1426 - accuracy: 0.9489 - val_loss: 1.7842 - val_accuracy: 0.6770\n","Epoch 34/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1249 - accuracy: 0.9560 - val_loss: 1.7784 - val_accuracy: 0.6841\n","Epoch 35/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1289 - accuracy: 0.9535 - val_loss: 1.8147 - val_accuracy: 0.6853\n","Epoch 36/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1189 - accuracy: 0.9569 - val_loss: 2.0164 - val_accuracy: 0.6715\n","Epoch 37/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1187 - accuracy: 0.9571 - val_loss: 1.9801 - val_accuracy: 0.6666\n","Epoch 38/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1065 - accuracy: 0.9622 - val_loss: 1.9298 - val_accuracy: 0.6867\n","Epoch 39/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0994 - accuracy: 0.9650 - val_loss: 2.0974 - val_accuracy: 0.6739\n","Epoch 40/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1180 - accuracy: 0.9561 - val_loss: 2.0129 - val_accuracy: 0.6809\n","Epoch 41/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0996 - accuracy: 0.9632 - val_loss: 2.0853 - val_accuracy: 0.6850\n","Epoch 42/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0984 - accuracy: 0.9641 - val_loss: 2.1390 - val_accuracy: 0.6724\n","Epoch 43/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.1100 - accuracy: 0.9607 - val_loss: 2.3600 - val_accuracy: 0.6577\n","Epoch 44/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.1062 - accuracy: 0.9616 - val_loss: 2.0651 - val_accuracy: 0.6823\n","Epoch 45/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0838 - accuracy: 0.9698 - val_loss: 2.1684 - val_accuracy: 0.6834\n","Epoch 46/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0780 - accuracy: 0.9716 - val_loss: 2.2603 - val_accuracy: 0.6798\n","Epoch 47/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0761 - accuracy: 0.9733 - val_loss: 2.2850 - val_accuracy: 0.6752\n","Epoch 48/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0915 - accuracy: 0.9678 - val_loss: 2.4940 - val_accuracy: 0.6652\n","Epoch 49/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9710 - val_loss: 2.5822 - val_accuracy: 0.6619\n","Epoch 50/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.9737 - val_loss: 2.3265 - val_accuracy: 0.6837\n","Epoch 51/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0851 - accuracy: 0.9696 - val_loss: 2.3402 - val_accuracy: 0.6806\n","Epoch 52/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0749 - accuracy: 0.9736 - val_loss: 2.5365 - val_accuracy: 0.6778\n","Epoch 53/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0792 - accuracy: 0.9716 - val_loss: 2.3957 - val_accuracy: 0.6788\n","Epoch 54/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0857 - accuracy: 0.9693 - val_loss: 2.4649 - val_accuracy: 0.6804\n","Epoch 55/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0584 - accuracy: 0.9797 - val_loss: 2.4001 - val_accuracy: 0.6796\n","Epoch 56/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0600 - accuracy: 0.9790 - val_loss: 2.4102 - val_accuracy: 0.6789\n","Epoch 57/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0898 - accuracy: 0.9684 - val_loss: 2.4924 - val_accuracy: 0.6831\n","Epoch 58/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0728 - accuracy: 0.9739 - val_loss: 2.4938 - val_accuracy: 0.6834\n","Epoch 59/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9739 - val_loss: 2.5457 - val_accuracy: 0.6802\n","Epoch 60/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0698 - accuracy: 0.9750 - val_loss: 2.6884 - val_accuracy: 0.6789\n","Epoch 61/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0666 - accuracy: 0.9768 - val_loss: 2.4979 - val_accuracy: 0.6733\n","Epoch 62/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.9774 - val_loss: 2.5833 - val_accuracy: 0.6870\n","Epoch 63/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0674 - accuracy: 0.9771 - val_loss: 2.5987 - val_accuracy: 0.6780\n","Epoch 64/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.9768 - val_loss: 2.5365 - val_accuracy: 0.6829\n","Epoch 65/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0561 - accuracy: 0.9801 - val_loss: 2.6735 - val_accuracy: 0.6810\n","Epoch 66/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0695 - accuracy: 0.9757 - val_loss: 2.5440 - val_accuracy: 0.6878\n","Epoch 67/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 2.5946 - val_accuracy: 0.6763\n","Epoch 68/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0681 - accuracy: 0.9749 - val_loss: 2.6849 - val_accuracy: 0.6751\n","Epoch 69/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0675 - accuracy: 0.9763 - val_loss: 2.7253 - val_accuracy: 0.6838\n","Epoch 70/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0582 - accuracy: 0.9800 - val_loss: 2.7997 - val_accuracy: 0.6859\n","Epoch 71/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0546 - accuracy: 0.9811 - val_loss: 2.7497 - val_accuracy: 0.6758\n","Epoch 72/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0592 - accuracy: 0.9794 - val_loss: 2.7261 - val_accuracy: 0.6691\n","Epoch 73/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0615 - accuracy: 0.9782 - val_loss: 2.8395 - val_accuracy: 0.6763\n","Epoch 74/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0673 - accuracy: 0.9771 - val_loss: 2.7688 - val_accuracy: 0.6718\n","Epoch 75/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0490 - accuracy: 0.9825 - val_loss: 2.7541 - val_accuracy: 0.6783\n","Epoch 76/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0461 - accuracy: 0.9841 - val_loss: 2.8949 - val_accuracy: 0.6798\n","Epoch 77/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 2.8391 - val_accuracy: 0.6842\n","Epoch 78/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0601 - accuracy: 0.9792 - val_loss: 2.8858 - val_accuracy: 0.6780\n","Epoch 79/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0772 - accuracy: 0.9733 - val_loss: 3.0252 - val_accuracy: 0.6749\n","Epoch 80/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0495 - accuracy: 0.9821 - val_loss: 2.8099 - val_accuracy: 0.6847\n","Epoch 81/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0442 - accuracy: 0.9845 - val_loss: 2.8953 - val_accuracy: 0.6762\n","Epoch 82/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0490 - accuracy: 0.9831 - val_loss: 2.9896 - val_accuracy: 0.6760\n","Epoch 83/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0601 - accuracy: 0.9794 - val_loss: 2.8583 - val_accuracy: 0.6834\n","Epoch 84/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0483 - accuracy: 0.9833 - val_loss: 2.9421 - val_accuracy: 0.6690\n","Epoch 85/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0640 - accuracy: 0.9773 - val_loss: 3.0793 - val_accuracy: 0.6737\n","Epoch 86/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0540 - accuracy: 0.9812 - val_loss: 2.8977 - val_accuracy: 0.6916\n","Epoch 87/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0510 - accuracy: 0.9821 - val_loss: 2.9768 - val_accuracy: 0.6808\n","Epoch 88/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0470 - accuracy: 0.9838 - val_loss: 3.0236 - val_accuracy: 0.6769\n","Epoch 89/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.9828 - val_loss: 3.2662 - val_accuracy: 0.6665\n","Epoch 90/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 3.0874 - val_accuracy: 0.6845\n","Epoch 91/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 3.0431 - val_accuracy: 0.6733\n","Epoch 92/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 3.1370 - val_accuracy: 0.6770\n","Epoch 93/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 3.1148 - val_accuracy: 0.6831\n","Epoch 94/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 3.2094 - val_accuracy: 0.6691\n","Epoch 95/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0588 - accuracy: 0.9798 - val_loss: 3.2189 - val_accuracy: 0.6710\n","Epoch 96/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0577 - accuracy: 0.9797 - val_loss: 3.2625 - val_accuracy: 0.6778\n","Epoch 97/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 3.0844 - val_accuracy: 0.6843\n","Epoch 98/100\n","391/391 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.9868 - val_loss: 3.1708 - val_accuracy: 0.6801\n","Epoch 99/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 3.1777 - val_accuracy: 0.6843\n","Epoch 100/100\n","391/391 [==============================] - 2s 5ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 3.0943 - val_accuracy: 0.6845\n","Saved!\n","Accuracy of model 1:  0.684499979019165\n","Epoch 1/100\n","391/391 [==============================] - 4s 8ms/step - loss: 1.3613 - accuracy: 0.5124 - val_loss: 1.5092 - val_accuracy: 0.4713\n","Epoch 2/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.9420 - accuracy: 0.6657 - val_loss: 1.0305 - val_accuracy: 0.6443\n","Epoch 3/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.8106 - accuracy: 0.7139 - val_loss: 1.0078 - val_accuracy: 0.6565\n","Epoch 4/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.7179 - accuracy: 0.7469 - val_loss: 0.8341 - val_accuracy: 0.7107\n","Epoch 5/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.6545 - accuracy: 0.7704 - val_loss: 0.8342 - val_accuracy: 0.7129\n","Epoch 6/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.6001 - accuracy: 0.7881 - val_loss: 0.7936 - val_accuracy: 0.7279\n","Epoch 7/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.5500 - accuracy: 0.8059 - val_loss: 0.8470 - val_accuracy: 0.7227\n","Epoch 8/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.5072 - accuracy: 0.8206 - val_loss: 0.8336 - val_accuracy: 0.7206\n","Epoch 9/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.4664 - accuracy: 0.8365 - val_loss: 0.8775 - val_accuracy: 0.7306\n","Epoch 10/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.4361 - accuracy: 0.8455 - val_loss: 0.8780 - val_accuracy: 0.7274\n","Epoch 11/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.3933 - accuracy: 0.8616 - val_loss: 0.9141 - val_accuracy: 0.7239\n","Epoch 12/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.3707 - accuracy: 0.8676 - val_loss: 0.9602 - val_accuracy: 0.7149\n","Epoch 13/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.3376 - accuracy: 0.8795 - val_loss: 0.9535 - val_accuracy: 0.7304\n","Epoch 14/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.3142 - accuracy: 0.8891 - val_loss: 0.9281 - val_accuracy: 0.7478\n","Epoch 15/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.2881 - accuracy: 0.8974 - val_loss: 0.9534 - val_accuracy: 0.7319\n","Epoch 16/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.2619 - accuracy: 0.9055 - val_loss: 0.9696 - val_accuracy: 0.7309\n","Epoch 17/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.2515 - accuracy: 0.9103 - val_loss: 1.0136 - val_accuracy: 0.7162\n","Epoch 18/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.2308 - accuracy: 0.9175 - val_loss: 1.0555 - val_accuracy: 0.7284\n","Epoch 19/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.2145 - accuracy: 0.9247 - val_loss: 1.0680 - val_accuracy: 0.7385\n","Epoch 20/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1951 - accuracy: 0.9300 - val_loss: 1.0831 - val_accuracy: 0.7396\n","Epoch 21/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.1877 - accuracy: 0.9323 - val_loss: 1.2804 - val_accuracy: 0.7165\n","Epoch 22/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.1754 - accuracy: 0.9365 - val_loss: 1.2243 - val_accuracy: 0.7225\n","Epoch 23/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.1559 - accuracy: 0.9433 - val_loss: 1.2649 - val_accuracy: 0.7244\n","Epoch 24/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1599 - accuracy: 0.9425 - val_loss: 1.3034 - val_accuracy: 0.7137\n","Epoch 25/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1393 - accuracy: 0.9496 - val_loss: 1.2711 - val_accuracy: 0.7351\n","Epoch 26/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1390 - accuracy: 0.9492 - val_loss: 1.2488 - val_accuracy: 0.7388\n","Epoch 27/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1281 - accuracy: 0.9540 - val_loss: 1.2903 - val_accuracy: 0.7334\n","Epoch 28/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1290 - accuracy: 0.9533 - val_loss: 1.4185 - val_accuracy: 0.7197\n","Epoch 29/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1133 - accuracy: 0.9594 - val_loss: 1.3550 - val_accuracy: 0.7371\n","Epoch 30/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1155 - accuracy: 0.9582 - val_loss: 1.4185 - val_accuracy: 0.7251\n","Epoch 31/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0992 - accuracy: 0.9631 - val_loss: 1.4336 - val_accuracy: 0.7297\n","Epoch 32/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1006 - accuracy: 0.9637 - val_loss: 1.5332 - val_accuracy: 0.7349\n","Epoch 33/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.1104 - accuracy: 0.9604 - val_loss: 1.5320 - val_accuracy: 0.7201\n","Epoch 34/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0993 - accuracy: 0.9642 - val_loss: 1.4950 - val_accuracy: 0.7340\n","Epoch 35/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0964 - accuracy: 0.9652 - val_loss: 1.5175 - val_accuracy: 0.7236\n","Epoch 36/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0971 - accuracy: 0.9645 - val_loss: 1.5639 - val_accuracy: 0.7266\n","Epoch 37/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0750 - accuracy: 0.9734 - val_loss: 1.6408 - val_accuracy: 0.7266\n","Epoch 38/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0894 - accuracy: 0.9684 - val_loss: 1.6747 - val_accuracy: 0.7145\n","Epoch 39/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0916 - accuracy: 0.9665 - val_loss: 1.5443 - val_accuracy: 0.7361\n","Epoch 40/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0851 - accuracy: 0.9699 - val_loss: 1.7010 - val_accuracy: 0.7214\n","Epoch 41/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0848 - accuracy: 0.9688 - val_loss: 1.5713 - val_accuracy: 0.7351\n","Epoch 42/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0699 - accuracy: 0.9744 - val_loss: 1.6728 - val_accuracy: 0.7361\n","Epoch 43/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0783 - accuracy: 0.9717 - val_loss: 1.6567 - val_accuracy: 0.7298\n","Epoch 44/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0715 - accuracy: 0.9746 - val_loss: 1.7549 - val_accuracy: 0.7194\n","Epoch 45/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0848 - accuracy: 0.9702 - val_loss: 1.7258 - val_accuracy: 0.7224\n","Epoch 46/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9764 - val_loss: 1.6757 - val_accuracy: 0.7409\n","Epoch 47/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0732 - accuracy: 0.9732 - val_loss: 1.7085 - val_accuracy: 0.7367\n","Epoch 48/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0690 - accuracy: 0.9757 - val_loss: 1.6402 - val_accuracy: 0.7407\n","Epoch 49/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0600 - accuracy: 0.9789 - val_loss: 1.8379 - val_accuracy: 0.7253\n","Epoch 50/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0721 - accuracy: 0.9741 - val_loss: 1.7737 - val_accuracy: 0.7313\n","Epoch 51/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0720 - accuracy: 0.9743 - val_loss: 1.7421 - val_accuracy: 0.7313\n","Epoch 52/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0618 - accuracy: 0.9781 - val_loss: 1.7452 - val_accuracy: 0.7327\n","Epoch 53/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0706 - accuracy: 0.9752 - val_loss: 1.9093 - val_accuracy: 0.7166\n","Epoch 54/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0613 - accuracy: 0.9788 - val_loss: 1.7491 - val_accuracy: 0.7416\n","Epoch 55/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0625 - accuracy: 0.9776 - val_loss: 1.7573 - val_accuracy: 0.7400\n","Epoch 56/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0596 - accuracy: 0.9787 - val_loss: 1.9555 - val_accuracy: 0.7204\n","Epoch 57/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0746 - accuracy: 0.9745 - val_loss: 1.7149 - val_accuracy: 0.7348\n","Epoch 58/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0517 - accuracy: 0.9815 - val_loss: 1.7766 - val_accuracy: 0.7375\n","Epoch 59/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0535 - accuracy: 0.9808 - val_loss: 1.8027 - val_accuracy: 0.7217\n","Epoch 60/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 1.8902 - val_accuracy: 0.7324\n","Epoch 61/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0581 - accuracy: 0.9797 - val_loss: 1.9407 - val_accuracy: 0.7157\n","Epoch 62/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.0526 - accuracy: 0.9816 - val_loss: 1.8492 - val_accuracy: 0.7279\n","Epoch 63/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0687 - accuracy: 0.9762 - val_loss: 1.9359 - val_accuracy: 0.7281\n","Epoch 64/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0573 - accuracy: 0.9800 - val_loss: 1.8518 - val_accuracy: 0.7313\n","Epoch 65/100\n","391/391 [==============================] - 2s 6ms/step - loss: 0.0533 - accuracy: 0.9816 - val_loss: 1.8686 - val_accuracy: 0.7355\n","Epoch 66/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0519 - accuracy: 0.9819 - val_loss: 1.9243 - val_accuracy: 0.7242\n","Epoch 67/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0548 - accuracy: 0.9813 - val_loss: 1.8185 - val_accuracy: 0.7287\n","Epoch 68/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0519 - accuracy: 0.9814 - val_loss: 1.8651 - val_accuracy: 0.7409\n","Epoch 69/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0455 - accuracy: 0.9841 - val_loss: 1.8699 - val_accuracy: 0.7207\n","Epoch 70/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0555 - accuracy: 0.9808 - val_loss: 1.9320 - val_accuracy: 0.7323\n","Epoch 71/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 1.8239 - val_accuracy: 0.7291\n","Epoch 72/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0409 - accuracy: 0.9861 - val_loss: 2.0119 - val_accuracy: 0.7261\n","Epoch 73/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 1.9589 - val_accuracy: 0.7370\n","Epoch 74/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0382 - accuracy: 0.9866 - val_loss: 2.0441 - val_accuracy: 0.7291\n","Epoch 75/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 1.8895 - val_accuracy: 0.7350\n","Epoch 76/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 1.8699 - val_accuracy: 0.7300\n","Epoch 77/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 1.9739 - val_accuracy: 0.7375\n","Epoch 78/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 1.9246 - val_accuracy: 0.7374\n","Epoch 79/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 1.9253 - val_accuracy: 0.7393\n","Epoch 80/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 1.9477 - val_accuracy: 0.7432\n","Epoch 81/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0454 - accuracy: 0.9842 - val_loss: 1.9043 - val_accuracy: 0.7311\n","Epoch 82/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0436 - accuracy: 0.9846 - val_loss: 1.9497 - val_accuracy: 0.7296\n","Epoch 83/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 1.8273 - val_accuracy: 0.7450\n","Epoch 84/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0380 - accuracy: 0.9870 - val_loss: 1.9512 - val_accuracy: 0.7360\n","Epoch 85/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0461 - accuracy: 0.9840 - val_loss: 1.9527 - val_accuracy: 0.7250\n","Epoch 86/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0387 - accuracy: 0.9859 - val_loss: 1.9504 - val_accuracy: 0.7415\n","Epoch 87/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0456 - accuracy: 0.9839 - val_loss: 1.9659 - val_accuracy: 0.7370\n","Epoch 88/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 1.9254 - val_accuracy: 0.7437\n","Epoch 89/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0341 - accuracy: 0.9874 - val_loss: 1.9167 - val_accuracy: 0.7461\n","Epoch 90/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0509 - accuracy: 0.9822 - val_loss: 2.0167 - val_accuracy: 0.7313\n","Epoch 91/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0521 - accuracy: 0.9822 - val_loss: 1.9154 - val_accuracy: 0.7396\n","Epoch 92/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 2.0374 - val_accuracy: 0.7328\n","Epoch 93/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 1.9558 - val_accuracy: 0.7377\n","Epoch 94/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0383 - accuracy: 0.9869 - val_loss: 1.9671 - val_accuracy: 0.7381\n","Epoch 95/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 1.9584 - val_accuracy: 0.7365\n","Epoch 96/100\n","391/391 [==============================] - 3s 6ms/step - loss: 0.0390 - accuracy: 0.9864 - val_loss: 1.9334 - val_accuracy: 0.7389\n","Epoch 97/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0444 - accuracy: 0.9846 - val_loss: 2.0438 - val_accuracy: 0.7294\n","Epoch 98/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 2.0306 - val_accuracy: 0.7334\n","Epoch 99/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0422 - accuracy: 0.9852 - val_loss: 2.1314 - val_accuracy: 0.7254\n","Epoch 100/100\n","391/391 [==============================] - 3s 7ms/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 2.1644 - val_accuracy: 0.7307\n","Saved!\n","Accuracy of model 2:  0.7307000160217285\n","Epoch 1/100\n","391/391 [==============================] - 5s 11ms/step - loss: 1.0188 - accuracy: 0.6395 - val_loss: 1.7451 - val_accuracy: 0.3776\n","Epoch 2/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.6443 - accuracy: 0.7754 - val_loss: 0.7841 - val_accuracy: 0.7341\n","Epoch 3/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.5198 - accuracy: 0.8151 - val_loss: 0.8144 - val_accuracy: 0.7366\n","Epoch 4/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.4337 - accuracy: 0.8471 - val_loss: 0.8203 - val_accuracy: 0.7454\n","Epoch 5/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.3683 - accuracy: 0.8717 - val_loss: 0.9322 - val_accuracy: 0.7276\n","Epoch 6/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.3062 - accuracy: 0.8936 - val_loss: 0.9232 - val_accuracy: 0.7406\n","Epoch 7/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.2623 - accuracy: 0.9082 - val_loss: 1.0344 - val_accuracy: 0.7275\n","Epoch 8/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.2219 - accuracy: 0.9218 - val_loss: 0.9923 - val_accuracy: 0.7514\n","Epoch 9/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1867 - accuracy: 0.9342 - val_loss: 1.2144 - val_accuracy: 0.7226\n","Epoch 10/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1673 - accuracy: 0.9405 - val_loss: 1.3194 - val_accuracy: 0.7206\n","Epoch 11/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1535 - accuracy: 0.9456 - val_loss: 1.2020 - val_accuracy: 0.7353\n","Epoch 12/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1401 - accuracy: 0.9498 - val_loss: 1.2302 - val_accuracy: 0.7320\n","Epoch 13/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1220 - accuracy: 0.9569 - val_loss: 1.2002 - val_accuracy: 0.7477\n","Epoch 14/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1154 - accuracy: 0.9585 - val_loss: 1.3112 - val_accuracy: 0.7370\n","Epoch 15/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1034 - accuracy: 0.9632 - val_loss: 1.3793 - val_accuracy: 0.7340\n","Epoch 16/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1006 - accuracy: 0.9643 - val_loss: 1.3549 - val_accuracy: 0.7356\n","Epoch 17/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.1003 - accuracy: 0.9643 - val_loss: 1.3195 - val_accuracy: 0.7479\n","Epoch 18/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0896 - accuracy: 0.9686 - val_loss: 1.3446 - val_accuracy: 0.7450\n","Epoch 19/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0921 - accuracy: 0.9671 - val_loss: 1.3795 - val_accuracy: 0.7436\n","Epoch 20/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0932 - accuracy: 0.9658 - val_loss: 1.4519 - val_accuracy: 0.7439\n","Epoch 21/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 1.3875 - val_accuracy: 0.7475\n","Epoch 22/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0723 - accuracy: 0.9750 - val_loss: 1.3836 - val_accuracy: 0.7519\n","Epoch 23/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0715 - accuracy: 0.9752 - val_loss: 1.4660 - val_accuracy: 0.7370\n","Epoch 24/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0760 - accuracy: 0.9733 - val_loss: 1.4240 - val_accuracy: 0.7427\n","Epoch 25/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0767 - accuracy: 0.9736 - val_loss: 1.4271 - val_accuracy: 0.7442\n","Epoch 26/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0703 - accuracy: 0.9747 - val_loss: 1.4901 - val_accuracy: 0.7458\n","Epoch 27/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0651 - accuracy: 0.9777 - val_loss: 1.5355 - val_accuracy: 0.7404\n","Epoch 28/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0693 - accuracy: 0.9752 - val_loss: 1.4172 - val_accuracy: 0.7451\n","Epoch 29/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0647 - accuracy: 0.9767 - val_loss: 1.5363 - val_accuracy: 0.7368\n","Epoch 30/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0643 - accuracy: 0.9778 - val_loss: 1.4100 - val_accuracy: 0.7402\n","Epoch 31/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0535 - accuracy: 0.9816 - val_loss: 1.4749 - val_accuracy: 0.7452\n","Epoch 32/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0617 - accuracy: 0.9781 - val_loss: 1.5154 - val_accuracy: 0.7501\n","Epoch 33/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0584 - accuracy: 0.9800 - val_loss: 1.4265 - val_accuracy: 0.7450\n","Epoch 34/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0550 - accuracy: 0.9814 - val_loss: 1.5253 - val_accuracy: 0.7458\n","Epoch 35/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0615 - accuracy: 0.9785 - val_loss: 1.4989 - val_accuracy: 0.7427\n","Epoch 36/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0581 - accuracy: 0.9798 - val_loss: 1.4966 - val_accuracy: 0.7446\n","Epoch 37/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0524 - accuracy: 0.9822 - val_loss: 1.5546 - val_accuracy: 0.7436\n","Epoch 38/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0539 - accuracy: 0.9809 - val_loss: 1.5019 - val_accuracy: 0.7466\n","Epoch 39/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0548 - accuracy: 0.9818 - val_loss: 1.5685 - val_accuracy: 0.7369\n","Epoch 40/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0527 - accuracy: 0.9818 - val_loss: 1.6086 - val_accuracy: 0.7550\n","Epoch 41/100\n","391/391 [==============================] - 3s 8ms/step - loss: 0.0517 - accuracy: 0.9818 - val_loss: 1.5589 - val_accuracy: 0.7462\n","Epoch 42/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0461 - accuracy: 0.9840 - val_loss: 1.5220 - val_accuracy: 0.7559\n","Epoch 43/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0461 - accuracy: 0.9836 - val_loss: 1.5675 - val_accuracy: 0.7456\n","Epoch 44/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 1.5300 - val_accuracy: 0.7487\n","Epoch 45/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0548 - accuracy: 0.9807 - val_loss: 1.5603 - val_accuracy: 0.7454\n","Epoch 46/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0469 - accuracy: 0.9841 - val_loss: 1.5976 - val_accuracy: 0.7404\n","Epoch 47/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 1.5105 - val_accuracy: 0.7524\n","Epoch 48/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0547 - accuracy: 0.9808 - val_loss: 1.5785 - val_accuracy: 0.7486\n","Epoch 49/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0448 - accuracy: 0.9842 - val_loss: 1.6293 - val_accuracy: 0.7427\n","Epoch 50/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0430 - accuracy: 0.9850 - val_loss: 1.5349 - val_accuracy: 0.7598\n","Epoch 51/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 1.5665 - val_accuracy: 0.7546\n","Epoch 52/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0387 - accuracy: 0.9868 - val_loss: 1.6837 - val_accuracy: 0.7507\n","Epoch 53/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0436 - accuracy: 0.9855 - val_loss: 1.6479 - val_accuracy: 0.7455\n","Epoch 54/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 1.6299 - val_accuracy: 0.7395\n","Epoch 55/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0450 - accuracy: 0.9846 - val_loss: 1.5893 - val_accuracy: 0.7472\n","Epoch 56/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0393 - accuracy: 0.9866 - val_loss: 1.5485 - val_accuracy: 0.7567\n","Epoch 57/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0384 - accuracy: 0.9865 - val_loss: 1.5671 - val_accuracy: 0.7500\n","Epoch 58/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 1.4991 - val_accuracy: 0.7515\n","Epoch 59/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0406 - accuracy: 0.9860 - val_loss: 1.6813 - val_accuracy: 0.7444\n","Epoch 60/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 1.6776 - val_accuracy: 0.7426\n","Epoch 61/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0407 - accuracy: 0.9857 - val_loss: 1.6338 - val_accuracy: 0.7509\n","Epoch 62/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 1.7868 - val_accuracy: 0.7321\n","Epoch 63/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 1.5316 - val_accuracy: 0.7562\n","Epoch 64/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 1.6058 - val_accuracy: 0.7495\n","Epoch 65/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0365 - accuracy: 0.9877 - val_loss: 1.6155 - val_accuracy: 0.7572\n","Epoch 66/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0342 - accuracy: 0.9883 - val_loss: 1.7648 - val_accuracy: 0.7476\n","Epoch 67/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0448 - accuracy: 0.9843 - val_loss: 1.5476 - val_accuracy: 0.7517\n","Epoch 68/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 1.6019 - val_accuracy: 0.7455\n","Epoch 69/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 1.6098 - val_accuracy: 0.7499\n","Epoch 70/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 1.7455 - val_accuracy: 0.7414\n","Epoch 71/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 1.6037 - val_accuracy: 0.7593\n","Epoch 72/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0341 - accuracy: 0.9881 - val_loss: 1.7063 - val_accuracy: 0.7457\n","Epoch 73/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 1.4761 - val_accuracy: 0.7616\n","Epoch 74/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0303 - accuracy: 0.9898 - val_loss: 1.5466 - val_accuracy: 0.7611\n","Epoch 75/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0294 - accuracy: 0.9898 - val_loss: 1.6152 - val_accuracy: 0.7607\n","Epoch 76/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0299 - accuracy: 0.9901 - val_loss: 1.5819 - val_accuracy: 0.7515\n","Epoch 77/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 1.6286 - val_accuracy: 0.7522\n","Epoch 78/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 1.6062 - val_accuracy: 0.7550\n","Epoch 79/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 1.6387 - val_accuracy: 0.7670\n","Epoch 80/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 1.9530 - val_accuracy: 0.7396\n","Epoch 81/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0338 - accuracy: 0.9888 - val_loss: 1.5908 - val_accuracy: 0.7644\n","Epoch 82/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0297 - accuracy: 0.9899 - val_loss: 1.7484 - val_accuracy: 0.7559\n","Epoch 83/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 1.7193 - val_accuracy: 0.7558\n","Epoch 84/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 1.7642 - val_accuracy: 0.7540\n","Epoch 85/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0303 - accuracy: 0.9904 - val_loss: 1.7547 - val_accuracy: 0.7481\n","Epoch 86/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0316 - accuracy: 0.9895 - val_loss: 1.5869 - val_accuracy: 0.7636\n","Epoch 87/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 1.7515 - val_accuracy: 0.7521\n","Epoch 88/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 1.6492 - val_accuracy: 0.7570\n","Epoch 89/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 1.7290 - val_accuracy: 0.7562\n","Epoch 90/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 1.6538 - val_accuracy: 0.7548\n","Epoch 91/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 1.6672 - val_accuracy: 0.7484\n","Epoch 92/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 1.6360 - val_accuracy: 0.7503\n","Epoch 93/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 1.7667 - val_accuracy: 0.7519\n","Epoch 94/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 1.6254 - val_accuracy: 0.7527\n","Epoch 95/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 1.6022 - val_accuracy: 0.7562\n","Epoch 96/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 1.6943 - val_accuracy: 0.7598\n","Epoch 97/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0290 - accuracy: 0.9902 - val_loss: 1.7481 - val_accuracy: 0.7506\n","Epoch 98/100\n","391/391 [==============================] - 4s 9ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 1.6578 - val_accuracy: 0.7563\n","Epoch 99/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 1.7460 - val_accuracy: 0.7510\n","Epoch 100/100\n","391/391 [==============================] - 3s 9ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 1.6849 - val_accuracy: 0.7639\n","Saved!\n","Accuracy of model 3:  0.7638999819755554\n","Epoch 1/100\n","391/391 [==============================] - 8s 17ms/step - loss: 0.5858 - accuracy: 0.7987 - val_loss: 2.4651 - val_accuracy: 0.1000\n","Epoch 2/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.2530 - accuracy: 0.9150 - val_loss: 0.9513 - val_accuracy: 0.7399\n","Epoch 3/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.1777 - accuracy: 0.9404 - val_loss: 1.2087 - val_accuracy: 0.7448\n","Epoch 4/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1360 - accuracy: 0.9543 - val_loss: 1.3184 - val_accuracy: 0.7347\n","Epoch 5/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1256 - accuracy: 0.9576 - val_loss: 1.2694 - val_accuracy: 0.7423\n","Epoch 6/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.1043 - accuracy: 0.9653 - val_loss: 1.3404 - val_accuracy: 0.7472\n","Epoch 7/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0968 - accuracy: 0.9668 - val_loss: 1.3444 - val_accuracy: 0.7455\n","Epoch 8/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0869 - accuracy: 0.9718 - val_loss: 1.4293 - val_accuracy: 0.7409\n","Epoch 9/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0858 - accuracy: 0.9720 - val_loss: 1.3483 - val_accuracy: 0.7406\n","Epoch 10/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0838 - accuracy: 0.9721 - val_loss: 1.4470 - val_accuracy: 0.7413\n","Epoch 11/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0768 - accuracy: 0.9744 - val_loss: 1.3738 - val_accuracy: 0.7510\n","Epoch 12/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0705 - accuracy: 0.9764 - val_loss: 1.4766 - val_accuracy: 0.7382\n","Epoch 13/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0732 - accuracy: 0.9764 - val_loss: 1.4043 - val_accuracy: 0.7539\n","Epoch 14/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0658 - accuracy: 0.9780 - val_loss: 1.4267 - val_accuracy: 0.7458\n","Epoch 15/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0669 - accuracy: 0.9776 - val_loss: 1.4290 - val_accuracy: 0.7478\n","Epoch 16/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0615 - accuracy: 0.9799 - val_loss: 1.3434 - val_accuracy: 0.7551\n","Epoch 17/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 1.3924 - val_accuracy: 0.7507\n","Epoch 18/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0634 - accuracy: 0.9796 - val_loss: 1.4132 - val_accuracy: 0.7546\n","Epoch 19/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0558 - accuracy: 0.9819 - val_loss: 1.4610 - val_accuracy: 0.7464\n","Epoch 20/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0558 - accuracy: 0.9818 - val_loss: 1.5363 - val_accuracy: 0.7448\n","Epoch 21/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0620 - accuracy: 0.9802 - val_loss: 1.5850 - val_accuracy: 0.7446\n","Epoch 22/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0557 - accuracy: 0.9817 - val_loss: 1.4303 - val_accuracy: 0.7524\n","Epoch 23/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0537 - accuracy: 0.9828 - val_loss: 1.3880 - val_accuracy: 0.7470\n","Epoch 24/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 1.4077 - val_accuracy: 0.7531\n","Epoch 25/100\n","391/391 [==============================] - 6s 17ms/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 1.4378 - val_accuracy: 0.7487\n","Epoch 26/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0509 - accuracy: 0.9843 - val_loss: 1.2832 - val_accuracy: 0.7577\n","Epoch 27/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 1.5675 - val_accuracy: 0.7360\n","Epoch 28/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 1.4414 - val_accuracy: 0.7574\n","Epoch 29/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 1.4527 - val_accuracy: 0.7484\n","Epoch 30/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 1.4895 - val_accuracy: 0.7507\n","Epoch 31/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0461 - accuracy: 0.9854 - val_loss: 1.5797 - val_accuracy: 0.7439\n","Epoch 32/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 1.3817 - val_accuracy: 0.7560\n","Epoch 33/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 1.4584 - val_accuracy: 0.7536\n","Epoch 34/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0428 - accuracy: 0.9858 - val_loss: 1.5138 - val_accuracy: 0.7459\n","Epoch 35/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 1.4552 - val_accuracy: 0.7425\n","Epoch 36/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0415 - accuracy: 0.9866 - val_loss: 1.5379 - val_accuracy: 0.7538\n","Epoch 37/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0405 - accuracy: 0.9864 - val_loss: 1.5278 - val_accuracy: 0.7529\n","Epoch 38/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0370 - accuracy: 0.9879 - val_loss: 1.6417 - val_accuracy: 0.7411\n","Epoch 39/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 1.4988 - val_accuracy: 0.7427\n","Epoch 40/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 1.5983 - val_accuracy: 0.7501\n","Epoch 41/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0389 - accuracy: 0.9873 - val_loss: 1.5556 - val_accuracy: 0.7506\n","Epoch 42/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0392 - accuracy: 0.9878 - val_loss: 1.4798 - val_accuracy: 0.7562\n","Epoch 43/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 1.5484 - val_accuracy: 0.7559\n","Epoch 44/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0364 - accuracy: 0.9883 - val_loss: 1.5131 - val_accuracy: 0.7514\n","Epoch 45/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 1.4909 - val_accuracy: 0.7582\n","Epoch 46/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0366 - accuracy: 0.9880 - val_loss: 1.5863 - val_accuracy: 0.7522\n","Epoch 47/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 1.5752 - val_accuracy: 0.7478\n","Epoch 48/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0364 - accuracy: 0.9882 - val_loss: 1.5326 - val_accuracy: 0.7554\n","Epoch 49/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0303 - accuracy: 0.9898 - val_loss: 1.5766 - val_accuracy: 0.7598\n","Epoch 50/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 1.5649 - val_accuracy: 0.7546\n","Epoch 51/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 1.5206 - val_accuracy: 0.7548\n","Epoch 52/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 1.4673 - val_accuracy: 0.7561\n","Epoch 53/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 1.4205 - val_accuracy: 0.7612\n","Epoch 54/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 1.4613 - val_accuracy: 0.7578\n","Epoch 55/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 1.6619 - val_accuracy: 0.7495\n","Epoch 56/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 1.6136 - val_accuracy: 0.7540\n","Epoch 57/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 1.5572 - val_accuracy: 0.7551\n","Epoch 58/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 1.5552 - val_accuracy: 0.7590\n","Epoch 59/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 1.5563 - val_accuracy: 0.7588\n","Epoch 60/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 1.6657 - val_accuracy: 0.7582\n","Epoch 61/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 1.6094 - val_accuracy: 0.7558\n","Epoch 62/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 1.5326 - val_accuracy: 0.7504\n","Epoch 63/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 1.5978 - val_accuracy: 0.7571\n","Epoch 64/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 1.4335 - val_accuracy: 0.7584\n","Epoch 65/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 1.5876 - val_accuracy: 0.7559\n","Epoch 66/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 1.5086 - val_accuracy: 0.7537\n","Epoch 67/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 1.5269 - val_accuracy: 0.7606\n","Epoch 68/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 1.4733 - val_accuracy: 0.7609\n","Epoch 69/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 1.6118 - val_accuracy: 0.7544\n","Epoch 70/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0281 - accuracy: 0.9904 - val_loss: 1.5451 - val_accuracy: 0.7607\n","Epoch 71/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 1.5347 - val_accuracy: 0.7587\n","Epoch 72/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 1.6337 - val_accuracy: 0.7557\n","Epoch 73/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 1.6416 - val_accuracy: 0.7509\n","Epoch 74/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 1.6196 - val_accuracy: 0.7533\n","Epoch 75/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 1.6576 - val_accuracy: 0.7493\n","Epoch 76/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 1.6451 - val_accuracy: 0.7531\n","Epoch 77/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 1.7327 - val_accuracy: 0.7489\n","Epoch 78/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 1.7352 - val_accuracy: 0.7513\n","Epoch 79/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 1.6160 - val_accuracy: 0.7571\n","Epoch 80/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 1.5864 - val_accuracy: 0.7588\n","Epoch 81/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 1.5678 - val_accuracy: 0.7549\n","Epoch 82/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 1.6284 - val_accuracy: 0.7613\n","Epoch 83/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 1.6856 - val_accuracy: 0.7576\n","Epoch 84/100\n","391/391 [==============================] - 6s 17ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 1.7901 - val_accuracy: 0.7567\n","Epoch 85/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 1.6709 - val_accuracy: 0.7592\n","Epoch 86/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 1.7621 - val_accuracy: 0.7556\n","Epoch 87/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 1.5613 - val_accuracy: 0.7620\n","Epoch 88/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 1.7629 - val_accuracy: 0.7523\n","Epoch 89/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 1.6202 - val_accuracy: 0.7625\n","Epoch 90/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 1.6272 - val_accuracy: 0.7569\n","Epoch 91/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 1.6748 - val_accuracy: 0.7597\n","Epoch 92/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 1.6271 - val_accuracy: 0.7575\n","Epoch 93/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 1.5400 - val_accuracy: 0.7606\n","Epoch 94/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 1.6367 - val_accuracy: 0.7643\n","Epoch 95/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 1.6312 - val_accuracy: 0.7612\n","Epoch 96/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 1.6823 - val_accuracy: 0.7584\n","Epoch 97/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 1.5821 - val_accuracy: 0.7689\n","Epoch 98/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 1.6800 - val_accuracy: 0.7608\n","Epoch 99/100\n","391/391 [==============================] - 6s 16ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 1.6611 - val_accuracy: 0.7583\n","Epoch 100/100\n","391/391 [==============================] - 6s 15ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 1.6977 - val_accuracy: 0.7567\n","Saved!\n","Accuracy of model 4:  0.7566999793052673\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pM1cIwzUTGyt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627299570553,"user_tz":-330,"elapsed":6,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"91ccf6c4-8ff3-4104-9a07-19215e544d12"},"source":["accuracies_time"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['-------------',\n"," (0.6848999857902527, 40.579360246658325),\n"," (0.6808000206947327, 60.86904036998749),\n"," (0.680899977684021, 81.15872049331665),\n"," (0.6837000250816345, 101.44840061664581),\n"," (0.6789000034332275, 121.73808073997498),\n"," (0.6858999729156494, 142.02776086330414),\n"," (0.6847000122070312, 162.3174409866333),\n"," (0.684499979019165, 182.60712110996246),\n"," (0.684499979019165, 202.89680123329163),\n"," '-------------',\n"," (0.7396000027656555, 52.65029816627502),\n"," (0.7250999808311462, 78.97544724941254),\n"," (0.7214000225067139, 105.30059633255004),\n"," (0.7312999963760376, 131.62574541568756),\n"," (0.7324000000953674, 157.95089449882508),\n"," (0.7322999835014343, 184.2760435819626),\n"," (0.7432000041007996, 210.6011926651001),\n"," (0.7312999963760376, 236.9263417482376),\n"," (0.7307000160217285, 263.2514908313751),\n"," '-------------',\n"," (0.7439000010490417, 76.66891846656799),\n"," (0.7401999831199646, 115.003377699852),\n"," (0.7549999952316284, 153.33783693313597),\n"," (0.7598000168800354, 191.67229616641998),\n"," (0.7426000237464905, 230.006755399704),\n"," (0.7414000034332275, 268.341214632988),\n"," (0.7396000027656555, 306.67567386627195),\n"," (0.754800021648407, 345.01013309955596),\n"," (0.7638999819755554, 383.34459233283997),\n"," '-------------',\n"," (0.7447999715805054, 136.78605570793152),\n"," (0.7506999969482422, 205.17908356189727),\n"," (0.7501000165939331, 273.57211141586305),\n"," (0.7545999884605408, 341.9651392698288),\n"," (0.7581999897956848, 410.35816712379454),\n"," (0.760699987411499, 478.7511949777603),\n"," (0.7588000297546387, 547.1442228317261),\n"," (0.7569000124931335, 615.5372506856918),\n"," (0.7566999793052673, 683.9302785396576)]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"8uEcDcUCNiDf"},"source":[""],"execution_count":null,"outputs":[]}]}