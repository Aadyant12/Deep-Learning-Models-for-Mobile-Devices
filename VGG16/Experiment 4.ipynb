{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment 4.ipynb","provenance":[{"file_id":"1qQ_0RaSDUXo_uEbw1vvx3nPGsLtg7iBu","timestamp":1623870104154},{"file_id":"1cGXeoDEMw72Qwq_JddSrkccvR6jR01V_","timestamp":1622991507291}],"collapsed_sections":[],"mount_file_id":"1ISXVWpyGGr6byooZJzxIccln_QkEMyer","authorship_tag":"ABX9TyOUVN1D3AfqEnq8Vjdsip/M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EhRVl-j9XISJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627288887784,"user_tz":-330,"elapsed":15790,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"85af39be-a17e-4958-d456-911d299779bc"},"source":["from tensorflow.keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSpWlE_jfAFQ","executionInfo":{"status":"ok","timestamp":1627288891368,"user_tz":-330,"elapsed":3594,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"7c09ee1e-edf7-43f1-b91b-92932085ea92"},"source":["# example of loading the MobileNet model\n","from tensorflow.keras.applications.vgg16 import VGG16\n","model = VGG16(input_shape=(32, 32, 3),weights=None, include_top=False)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWPVP0KFNY_P","executionInfo":{"status":"ok","timestamp":1627288891368,"user_tz":-330,"elapsed":24,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"194b73c4-6e3f-4018-efad-2bbc27d1b92c"},"source":["len(model.layers)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"6enOD5B6OAiZ"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYrda208Nh56"},"source":["exits = [3, 6, 10, 14]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p9tH_ROcvkFj"},"source":["## **ADDITION OF EXIT NETWORK**"]},{"cell_type":"code","metadata":{"id":"5AzuwnTDSOSf"},"source":["exit_layer1 = model.layers[3]\n","exit_layer2 = model.layers[6]\n","exit_layer3 = model.layers[10]\n","exit_layer4 = model.layers[14]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vII6zf4pNIK"},"source":["exit_models = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gz-OYNBTdRO","executionInfo":{"status":"ok","timestamp":1627288891370,"user_tz":-330,"elapsed":19,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"0d016abc-fc97-43d5-f842-1a10c4b7733c"},"source":["pool1 = MaxPooling2D((3,3), strides=(3,3))(exit_layer1.output)\n","conv1 = Conv2D(128, (5,5), padding='same', activation='relu')(pool1)\n","conv2 = Conv2D(128, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv2)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model1 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model1)\n","exit_model1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 5, 5, 128)         204928    \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 5, 5, 128)         409728    \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               65664     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 720,330\n","Trainable params: 720,330\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5OL3CceSEEL","executionInfo":{"status":"ok","timestamp":1627288891370,"user_tz":-330,"elapsed":17,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"1d7fd4d2-f193-4cfe-e3cf-47b096cd0683"},"source":["pool1 = MaxPooling2D((3,3), strides=(3,3))(exit_layer2.output)\n","conv1 = Conv2D(256, (5,5), padding='same', activation='relu')(pool1)\n","conv2 = Conv2D(256, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv2)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model2 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model2)\n","exit_model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 2, 2, 256)         819456    \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 2, 2, 256)         1638656   \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 2,752,458\n","Trainable params: 2,752,458\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jW--RdXSSfj","executionInfo":{"status":"ok","timestamp":1627288891370,"user_tz":-330,"elapsed":15,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"807a47f9-aec3-4ea1-b35c-fd37f0a1e46a"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer3.output)\n","conv1 = Conv2D(512, (5,5), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(512, (5,5), padding='same', activation='relu')(conv1)\n","pool2 = MaxPooling2D((2,2), strides=(2,2))(conv1)\n","\n","flat1 = Flatten()(pool2)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model3 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model3)\n","exit_model3.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 2, 2, 512)         3277312   \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               65664     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 5,079,754\n","Trainable params: 5,079,754\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XwmZ_Ntorkl","executionInfo":{"status":"ok","timestamp":1627288891371,"user_tz":-330,"elapsed":13,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"0f2cfdd1-9982-464a-d3c0-325c0b179ff2"},"source":["pool1 = MaxPooling2D((2,2), strides=(2,2))(exit_layer4.output)\n","#conv1 = Conv2D(512, (5,5), padding='same', activation='relu')(pool1)\n","#conv2 = Conv2D(512, (5,5), padding='same', activation='relu')(conv1)\n","#pool2 = MaxPooling2D((2,2), strides=(2,2))(conv2)\n","\n","flat1 = Flatten()(pool1)\n","class1 = Dense(128, activation='relu')(flat1)\n","\n","prediction = Dense(10, activation='softmax')(class1)\n","\n","exit_model4 = Model(inputs=model.inputs, outputs=prediction)\n","exit_models.append(exit_model4)\n","exit_model4.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               65664     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 7,702,218\n","Trainable params: 7,702,218\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDdgNEwKpf_8","executionInfo":{"status":"ok","timestamp":1627288891371,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"56b2463f-b191-49c6-e571-e2033b6fb077"},"source":["exit_models"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tensorflow.python.keras.engine.functional.Functional at 0x7f7bc017dd10>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f7bc0120a10>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f7bc013a2d0>,\n"," <tensorflow.python.keras.engine.functional.Functional at 0x7f7bc014e110>]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"qs5OkuHGkCcX"},"source":["for model in exit_models:\n","  model.compile(\n","          optimizer='adam',\n","          loss='sparse_categorical_crossentropy',\n","          metrics=['accuracy']\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWeZWmIe0un2"},"source":["import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5GvpA1ElIqe","executionInfo":{"status":"ok","timestamp":1627292121606,"user_tz":-330,"elapsed":3216374,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"a6e80d3c-3864-478f-fae9-c7d51d642abe"},"source":["accuracies_time = []\n","\n","for i in range(len(exits)):\n","  model = exit_models[i]\n","  model.load_weights(f\"/VGG16/Main_till_exit{i+1}_weights.h5\", by_name=True)\n","  for layer in range(exits[i] + 1):\n","    model.layers[layer].trainable = False\n","  accuracies_time.append('-------------')\n","  start = time.time()\n","  history = model.fit(\n","      x=x_train,\n","      y=y_train,\n","      epochs=100,\n","      verbose=1,\n","      validation_data=(x_test, y_test),\n","      batch_size=128\n","  )\n","  end = time.time()\n","  accuracies_time.append(((history.history.get('val_accuracy')[19]), (end-start)*2/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[29]), (end-start)*3/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[39]), (end-start)*4/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[49]), (end-start)*5/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[59]), (end-start)*6/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[69]), (end-start)*7/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[79]), (end-start)*8/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[89]), (end-start)*9/10))\n","  accuracies_time.append(((history.history.get('val_accuracy')[99]), (end-start)*10/10))\n","  print(f\"Accuracy of model {i+1}: \", history.history.get('val_accuracy')[len(history.history.get('val_accuracy')) - 1])\n","  i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","391/391 [==============================] - 20s 12ms/step - loss: 1.5758 - accuracy: 0.5221 - val_loss: 1.0163 - val_accuracy: 0.6477\n","Epoch 2/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.9164 - accuracy: 0.6778 - val_loss: 0.9348 - val_accuracy: 0.6727\n","Epoch 3/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.7663 - accuracy: 0.7337 - val_loss: 0.9112 - val_accuracy: 0.6904\n","Epoch 4/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.6612 - accuracy: 0.7700 - val_loss: 0.9092 - val_accuracy: 0.6892\n","Epoch 5/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.5521 - accuracy: 0.8057 - val_loss: 0.9001 - val_accuracy: 0.6995\n","Epoch 6/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.4672 - accuracy: 0.8366 - val_loss: 0.9555 - val_accuracy: 0.7077\n","Epoch 7/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.3885 - accuracy: 0.8640 - val_loss: 1.0300 - val_accuracy: 0.7003\n","Epoch 8/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.3317 - accuracy: 0.8840 - val_loss: 1.1156 - val_accuracy: 0.7026\n","Epoch 9/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.2695 - accuracy: 0.9045 - val_loss: 1.1306 - val_accuracy: 0.7162\n","Epoch 10/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.2447 - accuracy: 0.9147 - val_loss: 1.3088 - val_accuracy: 0.7008\n","Epoch 11/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.2215 - accuracy: 0.9235 - val_loss: 1.3546 - val_accuracy: 0.7035\n","Epoch 12/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.1972 - accuracy: 0.9315 - val_loss: 1.4156 - val_accuracy: 0.7001\n","Epoch 13/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.1729 - accuracy: 0.9406 - val_loss: 1.4979 - val_accuracy: 0.7032\n","Epoch 14/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.1632 - accuracy: 0.9441 - val_loss: 1.5051 - val_accuracy: 0.7021\n","Epoch 15/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.1539 - accuracy: 0.9479 - val_loss: 1.6254 - val_accuracy: 0.7013\n","Epoch 16/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.1481 - accuracy: 0.9489 - val_loss: 1.5918 - val_accuracy: 0.7072\n","Epoch 17/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.1253 - accuracy: 0.9571 - val_loss: 1.7007 - val_accuracy: 0.7069\n","Epoch 18/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.1265 - accuracy: 0.9573 - val_loss: 1.6431 - val_accuracy: 0.7085\n","Epoch 19/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.1258 - accuracy: 0.9582 - val_loss: 1.6579 - val_accuracy: 0.7066\n","Epoch 20/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.1214 - accuracy: 0.9595 - val_loss: 1.8060 - val_accuracy: 0.6971\n","Epoch 21/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.1053 - accuracy: 0.9646 - val_loss: 1.8367 - val_accuracy: 0.7023\n","Epoch 22/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.1083 - accuracy: 0.9642 - val_loss: 1.8325 - val_accuracy: 0.7067\n","Epoch 23/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.1071 - accuracy: 0.9652 - val_loss: 1.8337 - val_accuracy: 0.7106\n","Epoch 24/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0938 - accuracy: 0.9703 - val_loss: 1.8704 - val_accuracy: 0.7083\n","Epoch 25/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0965 - accuracy: 0.9684 - val_loss: 1.9037 - val_accuracy: 0.7090\n","Epoch 26/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0987 - accuracy: 0.9682 - val_loss: 1.8472 - val_accuracy: 0.7061\n","Epoch 27/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0951 - accuracy: 0.9698 - val_loss: 1.9054 - val_accuracy: 0.7076\n","Epoch 28/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0877 - accuracy: 0.9727 - val_loss: 2.0287 - val_accuracy: 0.7084\n","Epoch 29/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0908 - accuracy: 0.9718 - val_loss: 1.9634 - val_accuracy: 0.6940\n","Epoch 30/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0868 - accuracy: 0.9720 - val_loss: 1.9314 - val_accuracy: 0.7070\n","Epoch 31/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0856 - accuracy: 0.9729 - val_loss: 1.8884 - val_accuracy: 0.7190\n","Epoch 32/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0718 - accuracy: 0.9777 - val_loss: 2.1254 - val_accuracy: 0.7068\n","Epoch 33/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0868 - accuracy: 0.9728 - val_loss: 2.0337 - val_accuracy: 0.7037\n","Epoch 34/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0757 - accuracy: 0.9762 - val_loss: 2.0982 - val_accuracy: 0.7073\n","Epoch 35/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0813 - accuracy: 0.9746 - val_loss: 2.0945 - val_accuracy: 0.7026\n","Epoch 36/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0736 - accuracy: 0.9763 - val_loss: 2.1287 - val_accuracy: 0.7094\n","Epoch 37/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0637 - accuracy: 0.9801 - val_loss: 2.0712 - val_accuracy: 0.7111\n","Epoch 38/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0857 - accuracy: 0.9730 - val_loss: 2.2048 - val_accuracy: 0.7081\n","Epoch 39/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0657 - accuracy: 0.9791 - val_loss: 2.1923 - val_accuracy: 0.7005\n","Epoch 40/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0734 - accuracy: 0.9772 - val_loss: 2.1224 - val_accuracy: 0.7083\n","Epoch 41/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0712 - accuracy: 0.9775 - val_loss: 2.0610 - val_accuracy: 0.7084\n","Epoch 42/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0685 - accuracy: 0.9778 - val_loss: 2.2348 - val_accuracy: 0.7025\n","Epoch 43/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0669 - accuracy: 0.9790 - val_loss: 2.2152 - val_accuracy: 0.7144\n","Epoch 44/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0699 - accuracy: 0.9782 - val_loss: 2.2330 - val_accuracy: 0.7146\n","Epoch 45/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0647 - accuracy: 0.9796 - val_loss: 2.1154 - val_accuracy: 0.7163\n","Epoch 46/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0620 - accuracy: 0.9807 - val_loss: 2.3420 - val_accuracy: 0.7087\n","Epoch 47/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0667 - accuracy: 0.9797 - val_loss: 2.2764 - val_accuracy: 0.7212\n","Epoch 48/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0665 - accuracy: 0.9798 - val_loss: 2.1419 - val_accuracy: 0.7186\n","Epoch 49/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0609 - accuracy: 0.9818 - val_loss: 2.2485 - val_accuracy: 0.7064\n","Epoch 50/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0570 - accuracy: 0.9825 - val_loss: 2.3328 - val_accuracy: 0.7140\n","Epoch 51/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0582 - accuracy: 0.9816 - val_loss: 2.3886 - val_accuracy: 0.7019\n","Epoch 52/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0626 - accuracy: 0.9803 - val_loss: 2.2048 - val_accuracy: 0.7049\n","Epoch 53/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0664 - accuracy: 0.9809 - val_loss: 2.2403 - val_accuracy: 0.7149\n","Epoch 54/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0695 - accuracy: 0.9795 - val_loss: 2.3726 - val_accuracy: 0.7113\n","Epoch 55/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0586 - accuracy: 0.9822 - val_loss: 2.3537 - val_accuracy: 0.7114\n","Epoch 56/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0622 - accuracy: 0.9813 - val_loss: 2.2619 - val_accuracy: 0.7116\n","Epoch 57/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0637 - accuracy: 0.9814 - val_loss: 2.3102 - val_accuracy: 0.7049\n","Epoch 58/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0572 - accuracy: 0.9833 - val_loss: 2.1678 - val_accuracy: 0.7190\n","Epoch 59/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0556 - accuracy: 0.9840 - val_loss: 2.2740 - val_accuracy: 0.7176\n","Epoch 60/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0492 - accuracy: 0.9854 - val_loss: 2.2289 - val_accuracy: 0.7125\n","Epoch 61/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0568 - accuracy: 0.9831 - val_loss: 2.4115 - val_accuracy: 0.7072\n","Epoch 62/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0638 - accuracy: 0.9818 - val_loss: 2.5111 - val_accuracy: 0.7069\n","Epoch 63/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0561 - accuracy: 0.9841 - val_loss: 2.3758 - val_accuracy: 0.7135\n","Epoch 64/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0644 - accuracy: 0.9816 - val_loss: 2.3139 - val_accuracy: 0.7224\n","Epoch 65/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0502 - accuracy: 0.9854 - val_loss: 2.4234 - val_accuracy: 0.7187\n","Epoch 66/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0619 - accuracy: 0.9832 - val_loss: 2.2723 - val_accuracy: 0.7103\n","Epoch 67/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0505 - accuracy: 0.9855 - val_loss: 2.4710 - val_accuracy: 0.7109\n","Epoch 68/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0515 - accuracy: 0.9854 - val_loss: 2.3636 - val_accuracy: 0.7106\n","Epoch 69/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0508 - accuracy: 0.9857 - val_loss: 2.5063 - val_accuracy: 0.7130\n","Epoch 70/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0541 - accuracy: 0.9848 - val_loss: 2.4276 - val_accuracy: 0.7209\n","Epoch 71/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0442 - accuracy: 0.9876 - val_loss: 2.5437 - val_accuracy: 0.7049\n","Epoch 72/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0693 - accuracy: 0.9810 - val_loss: 2.5090 - val_accuracy: 0.7117\n","Epoch 73/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0567 - accuracy: 0.9835 - val_loss: 2.5708 - val_accuracy: 0.7135\n","Epoch 74/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0565 - accuracy: 0.9839 - val_loss: 2.5402 - val_accuracy: 0.7154\n","Epoch 75/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0527 - accuracy: 0.9850 - val_loss: 2.6298 - val_accuracy: 0.7094\n","Epoch 76/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0447 - accuracy: 0.9875 - val_loss: 2.6924 - val_accuracy: 0.7046\n","Epoch 77/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0518 - accuracy: 0.9855 - val_loss: 2.5545 - val_accuracy: 0.7169\n","Epoch 78/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0445 - accuracy: 0.9873 - val_loss: 2.4530 - val_accuracy: 0.7149\n","Epoch 79/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0439 - accuracy: 0.9878 - val_loss: 2.5400 - val_accuracy: 0.7182\n","Epoch 80/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0581 - accuracy: 0.9841 - val_loss: 2.4722 - val_accuracy: 0.7113\n","Epoch 81/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0576 - accuracy: 0.9841 - val_loss: 2.3914 - val_accuracy: 0.7127\n","Epoch 82/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0520 - accuracy: 0.9856 - val_loss: 2.5235 - val_accuracy: 0.7125\n","Epoch 83/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0457 - accuracy: 0.9870 - val_loss: 2.6866 - val_accuracy: 0.7149\n","Epoch 84/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0549 - accuracy: 0.9848 - val_loss: 2.5703 - val_accuracy: 0.7116\n","Epoch 85/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0518 - accuracy: 0.9859 - val_loss: 2.6204 - val_accuracy: 0.7064\n","Epoch 86/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0534 - accuracy: 0.9857 - val_loss: 2.4635 - val_accuracy: 0.7127\n","Epoch 87/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0407 - accuracy: 0.9889 - val_loss: 2.6580 - val_accuracy: 0.7114\n","Epoch 88/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 2.6369 - val_accuracy: 0.7183\n","Epoch 89/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0633 - accuracy: 0.9833 - val_loss: 2.3901 - val_accuracy: 0.7139\n","Epoch 90/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0432 - accuracy: 0.9883 - val_loss: 2.6725 - val_accuracy: 0.7179\n","Epoch 91/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0518 - accuracy: 0.9864 - val_loss: 2.5127 - val_accuracy: 0.7005\n","Epoch 92/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0423 - accuracy: 0.9888 - val_loss: 2.6326 - val_accuracy: 0.7200\n","Epoch 93/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0487 - accuracy: 0.9871 - val_loss: 2.6422 - val_accuracy: 0.7184\n","Epoch 94/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0525 - accuracy: 0.9868 - val_loss: 2.5083 - val_accuracy: 0.7145\n","Epoch 95/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0366 - accuracy: 0.9906 - val_loss: 2.5238 - val_accuracy: 0.7179\n","Epoch 96/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0476 - accuracy: 0.9875 - val_loss: 2.5739 - val_accuracy: 0.7190\n","Epoch 97/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0453 - accuracy: 0.9881 - val_loss: 2.8485 - val_accuracy: 0.7157\n","Epoch 98/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0502 - accuracy: 0.9874 - val_loss: 2.6153 - val_accuracy: 0.7160\n","Epoch 99/100\n","391/391 [==============================] - 4s 11ms/step - loss: 0.0462 - accuracy: 0.9885 - val_loss: 2.4622 - val_accuracy: 0.7235\n","Epoch 100/100\n","391/391 [==============================] - 4s 10ms/step - loss: 0.0493 - accuracy: 0.9874 - val_loss: 2.5484 - val_accuracy: 0.7109\n","Accuracy of model 1:  0.7109000086784363\n","Epoch 1/100\n","391/391 [==============================] - 8s 19ms/step - loss: 1.1529 - accuracy: 0.6027 - val_loss: 1.0085 - val_accuracy: 0.6523\n","Epoch 2/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.8227 - accuracy: 0.7169 - val_loss: 0.9244 - val_accuracy: 0.6845\n","Epoch 3/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.6752 - accuracy: 0.7685 - val_loss: 0.8939 - val_accuracy: 0.7078\n","Epoch 4/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.5580 - accuracy: 0.8070 - val_loss: 0.8702 - val_accuracy: 0.7238\n","Epoch 5/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.4653 - accuracy: 0.8390 - val_loss: 0.9815 - val_accuracy: 0.7024\n","Epoch 6/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.3801 - accuracy: 0.8661 - val_loss: 1.0140 - val_accuracy: 0.7191\n","Epoch 7/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.3183 - accuracy: 0.8899 - val_loss: 1.0001 - val_accuracy: 0.7214\n","Epoch 8/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.2769 - accuracy: 0.9044 - val_loss: 1.0691 - val_accuracy: 0.7077\n","Epoch 9/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.2432 - accuracy: 0.9165 - val_loss: 1.1786 - val_accuracy: 0.7132\n","Epoch 10/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.2139 - accuracy: 0.9272 - val_loss: 1.1178 - val_accuracy: 0.7148\n","Epoch 11/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.1911 - accuracy: 0.9355 - val_loss: 1.2949 - val_accuracy: 0.7169\n","Epoch 12/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.1661 - accuracy: 0.9442 - val_loss: 1.4092 - val_accuracy: 0.7146\n","Epoch 13/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.1666 - accuracy: 0.9447 - val_loss: 1.3683 - val_accuracy: 0.7130\n","Epoch 14/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.1522 - accuracy: 0.9504 - val_loss: 1.4773 - val_accuracy: 0.7205\n","Epoch 15/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.1462 - accuracy: 0.9521 - val_loss: 1.4706 - val_accuracy: 0.7178\n","Epoch 16/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.1342 - accuracy: 0.9549 - val_loss: 1.5000 - val_accuracy: 0.7096\n","Epoch 17/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.1209 - accuracy: 0.9606 - val_loss: 1.5840 - val_accuracy: 0.7184\n","Epoch 18/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.1085 - accuracy: 0.9655 - val_loss: 1.6505 - val_accuracy: 0.7134\n","Epoch 19/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.1152 - accuracy: 0.9627 - val_loss: 1.5927 - val_accuracy: 0.7174\n","Epoch 20/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.1125 - accuracy: 0.9626 - val_loss: 1.6825 - val_accuracy: 0.7142\n","Epoch 21/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.1178 - accuracy: 0.9619 - val_loss: 1.5715 - val_accuracy: 0.7190\n","Epoch 22/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0965 - accuracy: 0.9688 - val_loss: 1.7284 - val_accuracy: 0.7193\n","Epoch 23/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0962 - accuracy: 0.9686 - val_loss: 1.5996 - val_accuracy: 0.7163\n","Epoch 24/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0897 - accuracy: 0.9711 - val_loss: 1.6904 - val_accuracy: 0.7169\n","Epoch 25/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0967 - accuracy: 0.9694 - val_loss: 1.7084 - val_accuracy: 0.7161\n","Epoch 26/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0969 - accuracy: 0.9695 - val_loss: 1.7335 - val_accuracy: 0.7223\n","Epoch 27/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0930 - accuracy: 0.9704 - val_loss: 1.6204 - val_accuracy: 0.7221\n","Epoch 28/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0918 - accuracy: 0.9711 - val_loss: 1.7017 - val_accuracy: 0.7185\n","Epoch 29/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0953 - accuracy: 0.9709 - val_loss: 1.6349 - val_accuracy: 0.7194\n","Epoch 30/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0834 - accuracy: 0.9740 - val_loss: 1.7221 - val_accuracy: 0.7230\n","Epoch 31/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0869 - accuracy: 0.9733 - val_loss: 1.7655 - val_accuracy: 0.7248\n","Epoch 32/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0776 - accuracy: 0.9756 - val_loss: 1.7533 - val_accuracy: 0.7213\n","Epoch 33/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0912 - accuracy: 0.9720 - val_loss: 1.5811 - val_accuracy: 0.7215\n","Epoch 34/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0727 - accuracy: 0.9772 - val_loss: 1.7472 - val_accuracy: 0.7179\n","Epoch 35/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0873 - accuracy: 0.9738 - val_loss: 1.5915 - val_accuracy: 0.7236\n","Epoch 36/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0734 - accuracy: 0.9770 - val_loss: 1.6851 - val_accuracy: 0.7299\n","Epoch 37/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0716 - accuracy: 0.9778 - val_loss: 1.7732 - val_accuracy: 0.7180\n","Epoch 38/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0806 - accuracy: 0.9757 - val_loss: 1.8696 - val_accuracy: 0.7135\n","Epoch 39/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0741 - accuracy: 0.9769 - val_loss: 1.9682 - val_accuracy: 0.7301\n","Epoch 40/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0800 - accuracy: 0.9760 - val_loss: 1.7084 - val_accuracy: 0.7256\n","Epoch 41/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0595 - accuracy: 0.9822 - val_loss: 1.9829 - val_accuracy: 0.7214\n","Epoch 42/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0778 - accuracy: 0.9775 - val_loss: 1.9593 - val_accuracy: 0.7237\n","Epoch 43/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0763 - accuracy: 0.9776 - val_loss: 1.8005 - val_accuracy: 0.7159\n","Epoch 44/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0668 - accuracy: 0.9808 - val_loss: 1.8315 - val_accuracy: 0.7213\n","Epoch 45/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0658 - accuracy: 0.9803 - val_loss: 1.7716 - val_accuracy: 0.7270\n","Epoch 46/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0698 - accuracy: 0.9793 - val_loss: 1.7722 - val_accuracy: 0.7311\n","Epoch 47/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0662 - accuracy: 0.9808 - val_loss: 1.8625 - val_accuracy: 0.7181\n","Epoch 48/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0660 - accuracy: 0.9812 - val_loss: 1.8794 - val_accuracy: 0.7161\n","Epoch 49/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0679 - accuracy: 0.9800 - val_loss: 1.8580 - val_accuracy: 0.7234\n","Epoch 50/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0660 - accuracy: 0.9814 - val_loss: 1.7948 - val_accuracy: 0.7224\n","Epoch 51/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0551 - accuracy: 0.9835 - val_loss: 1.8344 - val_accuracy: 0.7302\n","Epoch 52/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0660 - accuracy: 0.9807 - val_loss: 1.8994 - val_accuracy: 0.7224\n","Epoch 53/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0689 - accuracy: 0.9810 - val_loss: 1.8350 - val_accuracy: 0.7261\n","Epoch 54/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0656 - accuracy: 0.9812 - val_loss: 1.7784 - val_accuracy: 0.7241\n","Epoch 55/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0670 - accuracy: 0.9806 - val_loss: 1.8353 - val_accuracy: 0.7151\n","Epoch 56/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0636 - accuracy: 0.9821 - val_loss: 1.8317 - val_accuracy: 0.7202\n","Epoch 57/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0607 - accuracy: 0.9832 - val_loss: 1.6926 - val_accuracy: 0.7328\n","Epoch 58/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0552 - accuracy: 0.9847 - val_loss: 1.8912 - val_accuracy: 0.7304\n","Epoch 59/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0511 - accuracy: 0.9859 - val_loss: 2.0209 - val_accuracy: 0.7196\n","Epoch 60/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0715 - accuracy: 0.9800 - val_loss: 1.6962 - val_accuracy: 0.7211\n","Epoch 61/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0593 - accuracy: 0.9835 - val_loss: 1.7115 - val_accuracy: 0.7171\n","Epoch 62/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0521 - accuracy: 0.9861 - val_loss: 1.9481 - val_accuracy: 0.7314\n","Epoch 63/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0546 - accuracy: 0.9850 - val_loss: 1.9403 - val_accuracy: 0.7319\n","Epoch 64/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0643 - accuracy: 0.9825 - val_loss: 1.7301 - val_accuracy: 0.7229\n","Epoch 65/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0563 - accuracy: 0.9845 - val_loss: 1.7611 - val_accuracy: 0.7242\n","Epoch 66/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0518 - accuracy: 0.9856 - val_loss: 2.1045 - val_accuracy: 0.7136\n","Epoch 67/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0605 - accuracy: 0.9837 - val_loss: 1.8462 - val_accuracy: 0.7233\n","Epoch 68/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0586 - accuracy: 0.9846 - val_loss: 1.9068 - val_accuracy: 0.7280\n","Epoch 69/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 1.8601 - val_accuracy: 0.7298\n","Epoch 70/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0534 - accuracy: 0.9852 - val_loss: 1.7186 - val_accuracy: 0.7298\n","Epoch 71/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0544 - accuracy: 0.9857 - val_loss: 1.9292 - val_accuracy: 0.7301\n","Epoch 72/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0616 - accuracy: 0.9841 - val_loss: 1.8433 - val_accuracy: 0.7221\n","Epoch 73/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0552 - accuracy: 0.9853 - val_loss: 1.7910 - val_accuracy: 0.7276\n","Epoch 74/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0616 - accuracy: 0.9839 - val_loss: 1.8219 - val_accuracy: 0.7363\n","Epoch 75/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0407 - accuracy: 0.9889 - val_loss: 1.9283 - val_accuracy: 0.7369\n","Epoch 76/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0560 - accuracy: 0.9856 - val_loss: 1.9837 - val_accuracy: 0.7260\n","Epoch 77/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0614 - accuracy: 0.9844 - val_loss: 1.8165 - val_accuracy: 0.7199\n","Epoch 78/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0548 - accuracy: 0.9864 - val_loss: 2.0895 - val_accuracy: 0.7317\n","Epoch 79/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0483 - accuracy: 0.9880 - val_loss: 2.1961 - val_accuracy: 0.7179\n","Epoch 80/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0548 - accuracy: 0.9869 - val_loss: 1.9347 - val_accuracy: 0.7233\n","Epoch 81/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0670 - accuracy: 0.9843 - val_loss: 1.7645 - val_accuracy: 0.7255\n","Epoch 82/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0587 - accuracy: 0.9853 - val_loss: 2.0363 - val_accuracy: 0.7196\n","Epoch 83/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0471 - accuracy: 0.9886 - val_loss: 2.0389 - val_accuracy: 0.7231\n","Epoch 84/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0609 - accuracy: 0.9849 - val_loss: 2.2334 - val_accuracy: 0.7245\n","Epoch 85/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0462 - accuracy: 0.9885 - val_loss: 2.1009 - val_accuracy: 0.7270\n","Epoch 86/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0578 - accuracy: 0.9863 - val_loss: 1.9750 - val_accuracy: 0.7201\n","Epoch 87/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0739 - accuracy: 0.9823 - val_loss: 2.1109 - val_accuracy: 0.7272\n","Epoch 88/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0410 - accuracy: 0.9897 - val_loss: 2.2843 - val_accuracy: 0.7298\n","Epoch 89/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0575 - accuracy: 0.9864 - val_loss: 1.9636 - val_accuracy: 0.7270\n","Epoch 90/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0530 - accuracy: 0.9873 - val_loss: 2.1009 - val_accuracy: 0.7275\n","Epoch 91/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0681 - accuracy: 0.9851 - val_loss: 2.0570 - val_accuracy: 0.7274\n","Epoch 92/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0510 - accuracy: 0.9881 - val_loss: 1.9599 - val_accuracy: 0.7306\n","Epoch 93/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0532 - accuracy: 0.9879 - val_loss: 2.0184 - val_accuracy: 0.7283\n","Epoch 94/100\n","391/391 [==============================] - 7s 17ms/step - loss: 0.0506 - accuracy: 0.9879 - val_loss: 2.1378 - val_accuracy: 0.7343\n","Epoch 95/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0543 - accuracy: 0.9877 - val_loss: 1.9245 - val_accuracy: 0.7343\n","Epoch 96/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0859 - accuracy: 0.9812 - val_loss: 1.8823 - val_accuracy: 0.7314\n","Epoch 97/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0544 - accuracy: 0.9878 - val_loss: 2.1227 - val_accuracy: 0.7211\n","Epoch 98/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0572 - accuracy: 0.9866 - val_loss: 2.0626 - val_accuracy: 0.7080\n","Epoch 99/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0693 - accuracy: 0.9841 - val_loss: 2.1566 - val_accuracy: 0.7243\n","Epoch 100/100\n","391/391 [==============================] - 7s 18ms/step - loss: 0.0490 - accuracy: 0.9891 - val_loss: 2.1475 - val_accuracy: 0.7335\n","Accuracy of model 2:  0.7335000038146973\n","Epoch 1/100\n","391/391 [==============================] - 10s 24ms/step - loss: 1.0365 - accuracy: 0.6735 - val_loss: 0.8691 - val_accuracy: 0.7273\n","Epoch 2/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.4765 - accuracy: 0.8375 - val_loss: 0.8775 - val_accuracy: 0.7366\n","Epoch 3/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.3753 - accuracy: 0.8731 - val_loss: 0.9551 - val_accuracy: 0.7330\n","Epoch 4/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.3146 - accuracy: 0.8922 - val_loss: 0.9792 - val_accuracy: 0.7416\n","Epoch 5/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.2839 - accuracy: 0.9016 - val_loss: 1.0511 - val_accuracy: 0.7425\n","Epoch 6/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.2409 - accuracy: 0.9190 - val_loss: 1.0596 - val_accuracy: 0.7384\n","Epoch 7/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.2233 - accuracy: 0.9239 - val_loss: 1.1839 - val_accuracy: 0.7257\n","Epoch 8/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.2109 - accuracy: 0.9287 - val_loss: 1.1436 - val_accuracy: 0.7380\n","Epoch 9/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1987 - accuracy: 0.9336 - val_loss: 1.2978 - val_accuracy: 0.7351\n","Epoch 10/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1819 - accuracy: 0.9396 - val_loss: 1.1970 - val_accuracy: 0.7364\n","Epoch 11/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1550 - accuracy: 0.9485 - val_loss: 1.2181 - val_accuracy: 0.7373\n","Epoch 12/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1579 - accuracy: 0.9484 - val_loss: 1.4370 - val_accuracy: 0.7362\n","Epoch 13/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1553 - accuracy: 0.9495 - val_loss: 1.2673 - val_accuracy: 0.7442\n","Epoch 14/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1399 - accuracy: 0.9546 - val_loss: 1.3940 - val_accuracy: 0.7340\n","Epoch 15/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1352 - accuracy: 0.9568 - val_loss: 1.3336 - val_accuracy: 0.7398\n","Epoch 16/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1223 - accuracy: 0.9607 - val_loss: 1.3739 - val_accuracy: 0.7414\n","Epoch 17/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1221 - accuracy: 0.9607 - val_loss: 1.4020 - val_accuracy: 0.7393\n","Epoch 18/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1289 - accuracy: 0.9592 - val_loss: 1.4296 - val_accuracy: 0.7356\n","Epoch 19/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1059 - accuracy: 0.9667 - val_loss: 1.4520 - val_accuracy: 0.7476\n","Epoch 20/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1182 - accuracy: 0.9629 - val_loss: 1.3591 - val_accuracy: 0.7396\n","Epoch 21/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1193 - accuracy: 0.9637 - val_loss: 1.4495 - val_accuracy: 0.7315\n","Epoch 22/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1248 - accuracy: 0.9613 - val_loss: 1.3470 - val_accuracy: 0.7410\n","Epoch 23/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1017 - accuracy: 0.9681 - val_loss: 1.6820 - val_accuracy: 0.7447\n","Epoch 24/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1091 - accuracy: 0.9662 - val_loss: 1.3193 - val_accuracy: 0.7415\n","Epoch 25/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1085 - accuracy: 0.9673 - val_loss: 1.3611 - val_accuracy: 0.7442\n","Epoch 26/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0907 - accuracy: 0.9725 - val_loss: 1.5863 - val_accuracy: 0.7519\n","Epoch 27/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1028 - accuracy: 0.9689 - val_loss: 1.4576 - val_accuracy: 0.7440\n","Epoch 28/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1016 - accuracy: 0.9687 - val_loss: 1.4112 - val_accuracy: 0.7574\n","Epoch 29/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1069 - accuracy: 0.9675 - val_loss: 1.4350 - val_accuracy: 0.7396\n","Epoch 30/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0935 - accuracy: 0.9717 - val_loss: 1.4874 - val_accuracy: 0.7494\n","Epoch 31/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0902 - accuracy: 0.9740 - val_loss: 1.5565 - val_accuracy: 0.7473\n","Epoch 32/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0989 - accuracy: 0.9704 - val_loss: 1.4026 - val_accuracy: 0.7489\n","Epoch 33/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0818 - accuracy: 0.9756 - val_loss: 1.5816 - val_accuracy: 0.7488\n","Epoch 34/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1085 - accuracy: 0.9690 - val_loss: 1.4932 - val_accuracy: 0.7382\n","Epoch 35/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1051 - accuracy: 0.9688 - val_loss: 1.4807 - val_accuracy: 0.7375\n","Epoch 36/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0959 - accuracy: 0.9730 - val_loss: 1.4500 - val_accuracy: 0.7485\n","Epoch 37/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0847 - accuracy: 0.9756 - val_loss: 1.5020 - val_accuracy: 0.7426\n","Epoch 38/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1055 - accuracy: 0.9696 - val_loss: 1.3559 - val_accuracy: 0.7513\n","Epoch 39/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0792 - accuracy: 0.9770 - val_loss: 1.5683 - val_accuracy: 0.7567\n","Epoch 40/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0836 - accuracy: 0.9761 - val_loss: 1.4985 - val_accuracy: 0.7498\n","Epoch 41/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0900 - accuracy: 0.9752 - val_loss: 1.5694 - val_accuracy: 0.7517\n","Epoch 42/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1033 - accuracy: 0.9706 - val_loss: 1.5012 - val_accuracy: 0.7481\n","Epoch 43/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0982 - accuracy: 0.9729 - val_loss: 1.5708 - val_accuracy: 0.7483\n","Epoch 44/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.1017 - accuracy: 0.9719 - val_loss: 1.5775 - val_accuracy: 0.7499\n","Epoch 45/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0734 - accuracy: 0.9801 - val_loss: 1.6178 - val_accuracy: 0.7520\n","Epoch 46/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0838 - accuracy: 0.9780 - val_loss: 1.3590 - val_accuracy: 0.7530\n","Epoch 47/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0869 - accuracy: 0.9765 - val_loss: 1.7828 - val_accuracy: 0.7535\n","Epoch 48/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0883 - accuracy: 0.9760 - val_loss: 1.6746 - val_accuracy: 0.7523\n","Epoch 49/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0989 - accuracy: 0.9734 - val_loss: 1.7166 - val_accuracy: 0.7485\n","Epoch 50/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0916 - accuracy: 0.9761 - val_loss: 1.8093 - val_accuracy: 0.7364\n","Epoch 51/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0949 - accuracy: 0.9755 - val_loss: 1.6305 - val_accuracy: 0.7508\n","Epoch 52/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0825 - accuracy: 0.9783 - val_loss: 1.6430 - val_accuracy: 0.7520\n","Epoch 53/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0760 - accuracy: 0.9805 - val_loss: 1.6498 - val_accuracy: 0.7479\n","Epoch 54/100\n","391/391 [==============================] - 9s 23ms/step - loss: 0.0908 - accuracy: 0.9767 - val_loss: 1.7021 - val_accuracy: 0.7498\n","Epoch 55/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0997 - accuracy: 0.9754 - val_loss: 1.7119 - val_accuracy: 0.7427\n","Epoch 56/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1044 - accuracy: 0.9737 - val_loss: 1.7590 - val_accuracy: 0.7555\n","Epoch 57/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0826 - accuracy: 0.9798 - val_loss: 1.6697 - val_accuracy: 0.7456\n","Epoch 58/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0976 - accuracy: 0.9767 - val_loss: 1.6420 - val_accuracy: 0.7500\n","Epoch 59/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0736 - accuracy: 0.9817 - val_loss: 1.6500 - val_accuracy: 0.7532\n","Epoch 60/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0925 - accuracy: 0.9773 - val_loss: 1.6658 - val_accuracy: 0.7518\n","Epoch 61/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0794 - accuracy: 0.9809 - val_loss: 1.7612 - val_accuracy: 0.7555\n","Epoch 62/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0974 - accuracy: 0.9757 - val_loss: 1.8546 - val_accuracy: 0.7549\n","Epoch 63/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0865 - accuracy: 0.9784 - val_loss: 1.8601 - val_accuracy: 0.7522\n","Epoch 64/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1299 - accuracy: 0.9685 - val_loss: 1.6181 - val_accuracy: 0.7419\n","Epoch 65/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0816 - accuracy: 0.9800 - val_loss: 1.7128 - val_accuracy: 0.7570\n","Epoch 66/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0948 - accuracy: 0.9770 - val_loss: 1.7610 - val_accuracy: 0.7498\n","Epoch 67/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0915 - accuracy: 0.9785 - val_loss: 1.8548 - val_accuracy: 0.7566\n","Epoch 68/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0720 - accuracy: 0.9831 - val_loss: 1.7618 - val_accuracy: 0.7670\n","Epoch 69/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0960 - accuracy: 0.9776 - val_loss: 1.6976 - val_accuracy: 0.7520\n","Epoch 70/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1365 - accuracy: 0.9701 - val_loss: 1.7201 - val_accuracy: 0.7615\n","Epoch 71/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0662 - accuracy: 0.9847 - val_loss: 1.9136 - val_accuracy: 0.7550\n","Epoch 72/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1510 - accuracy: 0.9674 - val_loss: 1.6776 - val_accuracy: 0.7437\n","Epoch 73/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0975 - accuracy: 0.9775 - val_loss: 1.8032 - val_accuracy: 0.7576\n","Epoch 74/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0796 - accuracy: 0.9818 - val_loss: 1.8186 - val_accuracy: 0.7553\n","Epoch 75/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0759 - accuracy: 0.9837 - val_loss: 1.8332 - val_accuracy: 0.7513\n","Epoch 76/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1066 - accuracy: 0.9753 - val_loss: 1.7023 - val_accuracy: 0.7571\n","Epoch 77/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0790 - accuracy: 0.9818 - val_loss: 1.9569 - val_accuracy: 0.7557\n","Epoch 78/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1090 - accuracy: 0.9763 - val_loss: 1.7515 - val_accuracy: 0.7442\n","Epoch 79/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0937 - accuracy: 0.9797 - val_loss: 1.7356 - val_accuracy: 0.7520\n","Epoch 80/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1377 - accuracy: 0.9704 - val_loss: 1.9946 - val_accuracy: 0.7590\n","Epoch 81/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0838 - accuracy: 0.9817 - val_loss: 2.3230 - val_accuracy: 0.7404\n","Epoch 82/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1189 - accuracy: 0.9743 - val_loss: 1.8608 - val_accuracy: 0.7460\n","Epoch 83/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1184 - accuracy: 0.9744 - val_loss: 1.8045 - val_accuracy: 0.7418\n","Epoch 84/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0747 - accuracy: 0.9843 - val_loss: 1.8698 - val_accuracy: 0.7616\n","Epoch 85/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1471 - accuracy: 0.9680 - val_loss: 1.6305 - val_accuracy: 0.7591\n","Epoch 86/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0924 - accuracy: 0.9806 - val_loss: 1.9039 - val_accuracy: 0.7547\n","Epoch 87/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0698 - accuracy: 0.9845 - val_loss: 1.9096 - val_accuracy: 0.7536\n","Epoch 88/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1047 - accuracy: 0.9783 - val_loss: 1.8736 - val_accuracy: 0.7431\n","Epoch 89/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0869 - accuracy: 0.9817 - val_loss: 1.8150 - val_accuracy: 0.7586\n","Epoch 90/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0973 - accuracy: 0.9802 - val_loss: 2.1544 - val_accuracy: 0.7524\n","Epoch 91/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1434 - accuracy: 0.9705 - val_loss: 2.0622 - val_accuracy: 0.7242\n","Epoch 92/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.2620 - accuracy: 0.9450 - val_loss: 1.9206 - val_accuracy: 0.7366\n","Epoch 93/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1051 - accuracy: 0.9773 - val_loss: 1.9901 - val_accuracy: 0.7486\n","Epoch 94/100\n","391/391 [==============================] - 10s 24ms/step - loss: 0.0603 - accuracy: 0.9870 - val_loss: 1.9249 - val_accuracy: 0.7494\n","Epoch 95/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.0708 - accuracy: 0.9863 - val_loss: 1.8832 - val_accuracy: 0.7616\n","Epoch 96/100\n","391/391 [==============================] - 10s 24ms/step - loss: 0.0864 - accuracy: 0.9820 - val_loss: 2.3619 - val_accuracy: 0.7605\n","Epoch 97/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1460 - accuracy: 0.9719 - val_loss: 1.7610 - val_accuracy: 0.7275\n","Epoch 98/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1040 - accuracy: 0.9789 - val_loss: 1.8938 - val_accuracy: 0.7518\n","Epoch 99/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1044 - accuracy: 0.9784 - val_loss: 1.8115 - val_accuracy: 0.7531\n","Epoch 100/100\n","391/391 [==============================] - 9s 24ms/step - loss: 0.1652 - accuracy: 0.9643 - val_loss: 2.1433 - val_accuracy: 0.7320\n","Accuracy of model 3:  0.7319999933242798\n","Epoch 1/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.6671 - accuracy: 0.7972 - val_loss: 1.0083 - val_accuracy: 0.7450\n","Epoch 2/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.3300 - accuracy: 0.8912 - val_loss: 1.0477 - val_accuracy: 0.7352\n","Epoch 3/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.3039 - accuracy: 0.8985 - val_loss: 1.1328 - val_accuracy: 0.7232\n","Epoch 4/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.2796 - accuracy: 0.9073 - val_loss: 1.0800 - val_accuracy: 0.7211\n","Epoch 5/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.2622 - accuracy: 0.9142 - val_loss: 1.1082 - val_accuracy: 0.7255\n","Epoch 6/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.2373 - accuracy: 0.9215 - val_loss: 1.2339 - val_accuracy: 0.7339\n","Epoch 7/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.2415 - accuracy: 0.9185 - val_loss: 1.2246 - val_accuracy: 0.7355\n","Epoch 8/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.2203 - accuracy: 0.9276 - val_loss: 1.2809 - val_accuracy: 0.7267\n","Epoch 9/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.2025 - accuracy: 0.9347 - val_loss: 1.2823 - val_accuracy: 0.7308\n","Epoch 10/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1796 - accuracy: 0.9417 - val_loss: 1.3337 - val_accuracy: 0.7335\n","Epoch 11/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1721 - accuracy: 0.9440 - val_loss: 1.3277 - val_accuracy: 0.7353\n","Epoch 12/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1629 - accuracy: 0.9469 - val_loss: 1.3888 - val_accuracy: 0.7345\n","Epoch 13/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1699 - accuracy: 0.9447 - val_loss: 1.2085 - val_accuracy: 0.7371\n","Epoch 14/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1482 - accuracy: 0.9526 - val_loss: 1.2922 - val_accuracy: 0.7398\n","Epoch 15/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1556 - accuracy: 0.9507 - val_loss: 1.3815 - val_accuracy: 0.7424\n","Epoch 16/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1550 - accuracy: 0.9508 - val_loss: 1.4764 - val_accuracy: 0.7373\n","Epoch 17/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1384 - accuracy: 0.9571 - val_loss: 1.2435 - val_accuracy: 0.7250\n","Epoch 18/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1307 - accuracy: 0.9595 - val_loss: 1.4742 - val_accuracy: 0.7444\n","Epoch 19/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1167 - accuracy: 0.9643 - val_loss: 1.5708 - val_accuracy: 0.7432\n","Epoch 20/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1264 - accuracy: 0.9600 - val_loss: 1.4899 - val_accuracy: 0.7395\n","Epoch 21/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1290 - accuracy: 0.9592 - val_loss: 1.3725 - val_accuracy: 0.7430\n","Epoch 22/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1204 - accuracy: 0.9632 - val_loss: 1.5895 - val_accuracy: 0.7361\n","Epoch 23/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1290 - accuracy: 0.9606 - val_loss: 1.3992 - val_accuracy: 0.7314\n","Epoch 24/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0996 - accuracy: 0.9685 - val_loss: 1.4262 - val_accuracy: 0.7395\n","Epoch 25/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1430 - accuracy: 0.9573 - val_loss: 1.4238 - val_accuracy: 0.7453\n","Epoch 26/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1026 - accuracy: 0.9682 - val_loss: 1.7158 - val_accuracy: 0.7446\n","Epoch 27/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1072 - accuracy: 0.9670 - val_loss: 1.5201 - val_accuracy: 0.7420\n","Epoch 28/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1228 - accuracy: 0.9637 - val_loss: 1.5947 - val_accuracy: 0.7451\n","Epoch 29/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1112 - accuracy: 0.9678 - val_loss: 1.6677 - val_accuracy: 0.7446\n","Epoch 30/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1095 - accuracy: 0.9673 - val_loss: 1.4516 - val_accuracy: 0.7452\n","Epoch 31/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0899 - accuracy: 0.9740 - val_loss: 1.6621 - val_accuracy: 0.7397\n","Epoch 32/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0933 - accuracy: 0.9725 - val_loss: 1.6563 - val_accuracy: 0.7413\n","Epoch 33/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1197 - accuracy: 0.9646 - val_loss: 1.6222 - val_accuracy: 0.7444\n","Epoch 34/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0954 - accuracy: 0.9720 - val_loss: 1.7157 - val_accuracy: 0.7447\n","Epoch 35/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1222 - accuracy: 0.9648 - val_loss: 1.4930 - val_accuracy: 0.7493\n","Epoch 36/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1180 - accuracy: 0.9667 - val_loss: 1.6314 - val_accuracy: 0.7449\n","Epoch 37/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0840 - accuracy: 0.9753 - val_loss: 1.9041 - val_accuracy: 0.7491\n","Epoch 38/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0899 - accuracy: 0.9749 - val_loss: 1.5707 - val_accuracy: 0.7409\n","Epoch 39/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1195 - accuracy: 0.9656 - val_loss: 1.4298 - val_accuracy: 0.7368\n","Epoch 40/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0785 - accuracy: 0.9777 - val_loss: 1.5982 - val_accuracy: 0.7496\n","Epoch 41/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0892 - accuracy: 0.9747 - val_loss: 1.4914 - val_accuracy: 0.7470\n","Epoch 42/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0850 - accuracy: 0.9763 - val_loss: 1.6393 - val_accuracy: 0.7461\n","Epoch 43/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0861 - accuracy: 0.9763 - val_loss: 1.6065 - val_accuracy: 0.7483\n","Epoch 44/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1362 - accuracy: 0.9625 - val_loss: 1.6947 - val_accuracy: 0.7473\n","Epoch 45/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0708 - accuracy: 0.9799 - val_loss: 1.5507 - val_accuracy: 0.7458\n","Epoch 46/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0847 - accuracy: 0.9763 - val_loss: 1.6614 - val_accuracy: 0.7471\n","Epoch 47/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0929 - accuracy: 0.9747 - val_loss: 1.8010 - val_accuracy: 0.7477\n","Epoch 48/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1472 - accuracy: 0.9599 - val_loss: 1.4326 - val_accuracy: 0.7309\n","Epoch 49/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.2239 - accuracy: 0.9391 - val_loss: 1.5093 - val_accuracy: 0.7523\n","Epoch 50/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0715 - accuracy: 0.9804 - val_loss: 1.7204 - val_accuracy: 0.7462\n","Epoch 51/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0535 - accuracy: 0.9849 - val_loss: 1.9460 - val_accuracy: 0.7370\n","Epoch 52/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0868 - accuracy: 0.9765 - val_loss: 1.7009 - val_accuracy: 0.7499\n","Epoch 53/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0870 - accuracy: 0.9774 - val_loss: 1.5876 - val_accuracy: 0.7492\n","Epoch 54/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0892 - accuracy: 0.9764 - val_loss: 1.4598 - val_accuracy: 0.7452\n","Epoch 55/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0686 - accuracy: 0.9821 - val_loss: 1.7769 - val_accuracy: 0.7493\n","Epoch 56/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0745 - accuracy: 0.9807 - val_loss: 1.6640 - val_accuracy: 0.7458\n","Epoch 57/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1033 - accuracy: 0.9721 - val_loss: 1.8357 - val_accuracy: 0.7421\n","Epoch 58/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0964 - accuracy: 0.9749 - val_loss: 1.6466 - val_accuracy: 0.7417\n","Epoch 59/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0671 - accuracy: 0.9817 - val_loss: 1.9752 - val_accuracy: 0.7469\n","Epoch 60/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0843 - accuracy: 0.9786 - val_loss: 1.5161 - val_accuracy: 0.7504\n","Epoch 61/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0827 - accuracy: 0.9784 - val_loss: 1.5751 - val_accuracy: 0.7511\n","Epoch 62/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0814 - accuracy: 0.9790 - val_loss: 1.7071 - val_accuracy: 0.7541\n","Epoch 63/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0886 - accuracy: 0.9781 - val_loss: 1.7001 - val_accuracy: 0.7480\n","Epoch 64/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0819 - accuracy: 0.9795 - val_loss: 1.6663 - val_accuracy: 0.7486\n","Epoch 65/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0856 - accuracy: 0.9780 - val_loss: 1.6322 - val_accuracy: 0.7462\n","Epoch 66/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0597 - accuracy: 0.9855 - val_loss: 1.9005 - val_accuracy: 0.7459\n","Epoch 67/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0775 - accuracy: 0.9802 - val_loss: 1.6684 - val_accuracy: 0.7557\n","Epoch 68/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0799 - accuracy: 0.9791 - val_loss: 2.0726 - val_accuracy: 0.7363\n","Epoch 69/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1363 - accuracy: 0.9661 - val_loss: 1.4908 - val_accuracy: 0.7370\n","Epoch 70/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0881 - accuracy: 0.9775 - val_loss: 1.8706 - val_accuracy: 0.7524\n","Epoch 71/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1069 - accuracy: 0.9751 - val_loss: 1.6347 - val_accuracy: 0.7499\n","Epoch 72/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1189 - accuracy: 0.9702 - val_loss: 1.5157 - val_accuracy: 0.7435\n","Epoch 73/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0939 - accuracy: 0.9769 - val_loss: 1.6267 - val_accuracy: 0.7536\n","Epoch 74/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0894 - accuracy: 0.9788 - val_loss: 1.7211 - val_accuracy: 0.7470\n","Epoch 75/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0649 - accuracy: 0.9834 - val_loss: 1.8469 - val_accuracy: 0.7504\n","Epoch 76/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1625 - accuracy: 0.9608 - val_loss: 1.6852 - val_accuracy: 0.7560\n","Epoch 77/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0523 - accuracy: 0.9870 - val_loss: 1.6663 - val_accuracy: 0.7575\n","Epoch 78/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0523 - accuracy: 0.9874 - val_loss: 1.7950 - val_accuracy: 0.7529\n","Epoch 79/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1638 - accuracy: 0.9566 - val_loss: 1.7485 - val_accuracy: 0.7536\n","Epoch 80/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0947 - accuracy: 0.9756 - val_loss: 1.6289 - val_accuracy: 0.7548\n","Epoch 81/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0433 - accuracy: 0.9894 - val_loss: 1.8104 - val_accuracy: 0.7584\n","Epoch 82/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1289 - accuracy: 0.9699 - val_loss: 1.6078 - val_accuracy: 0.7478\n","Epoch 83/100\n","391/391 [==============================] - 11s 27ms/step - loss: 0.0689 - accuracy: 0.9845 - val_loss: 1.7671 - val_accuracy: 0.7552\n","Epoch 84/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1351 - accuracy: 0.9663 - val_loss: 1.7914 - val_accuracy: 0.7441\n","Epoch 85/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0769 - accuracy: 0.9820 - val_loss: 1.6532 - val_accuracy: 0.7556\n","Epoch 86/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0617 - accuracy: 0.9862 - val_loss: 2.0004 - val_accuracy: 0.7466\n","Epoch 87/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0785 - accuracy: 0.9811 - val_loss: 1.6367 - val_accuracy: 0.7596\n","Epoch 88/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0493 - accuracy: 0.9894 - val_loss: 2.2899 - val_accuracy: 0.7487\n","Epoch 89/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.2283 - accuracy: 0.9442 - val_loss: 1.6297 - val_accuracy: 0.7405\n","Epoch 90/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0956 - accuracy: 0.9772 - val_loss: 1.8080 - val_accuracy: 0.7537\n","Epoch 91/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0959 - accuracy: 0.9775 - val_loss: 1.9435 - val_accuracy: 0.7570\n","Epoch 92/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0995 - accuracy: 0.9796 - val_loss: 1.5682 - val_accuracy: 0.6668\n","Epoch 93/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.1224 - accuracy: 0.9694 - val_loss: 1.6667 - val_accuracy: 0.7482\n","Epoch 94/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0706 - accuracy: 0.9856 - val_loss: 2.2009 - val_accuracy: 0.7383\n","Epoch 95/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.1435 - accuracy: 0.9652 - val_loss: 1.6876 - val_accuracy: 0.7476\n","Epoch 96/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0958 - accuracy: 0.9779 - val_loss: 1.9766 - val_accuracy: 0.7524\n","Epoch 97/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.0484 - accuracy: 0.9893 - val_loss: 1.9594 - val_accuracy: 0.7590\n","Epoch 98/100\n","391/391 [==============================] - 10s 26ms/step - loss: 0.2339 - accuracy: 0.9421 - val_loss: 1.5771 - val_accuracy: 0.7305\n","Epoch 99/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0945 - accuracy: 0.9771 - val_loss: 1.8556 - val_accuracy: 0.7589\n","Epoch 100/100\n","391/391 [==============================] - 10s 27ms/step - loss: 0.0580 - accuracy: 0.9871 - val_loss: 1.7704 - val_accuracy: 0.7557\n","Accuracy of model 4:  0.7556999921798706\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pM1cIwzUTGyt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627292121610,"user_tz":-330,"elapsed":77,"user":{"displayName":"Aadyant Khatri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiH9dIKjEubney_sA4f0LUJ3Z1in-D5m7azN995=s64","userId":"04658209455805406207"}},"outputId":"d5dc5b37-aabd-49cf-eaf6-b28b4d7697c8"},"source":["accuracies_time"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['-------------',\n"," (0.6970999836921692, 88.56196389198303),\n"," (0.7070000171661377, 132.84294583797455),\n"," (0.708299994468689, 177.12392778396605),\n"," (0.7139999866485596, 221.40490972995758),\n"," (0.7124999761581421, 265.6858916759491),\n"," (0.7208999991416931, 309.96687362194064),\n"," (0.7113000154495239, 354.2478555679321),\n"," (0.7178999781608582, 398.52883751392363),\n"," (0.7109000086784363, 442.80981945991516),\n"," '-------------',\n"," (0.7142000198364258, 148.56122961044312),\n"," (0.7229999899864197, 222.84184441566467),\n"," (0.725600004196167, 297.12245922088624),\n"," (0.7224000096321106, 371.4030740261078),\n"," (0.7210999727249146, 445.68368883132933),\n"," (0.7297999858856201, 519.9643036365509),\n"," (0.7232999801635742, 594.2449184417725),\n"," (0.7275000214576721, 668.525533246994),\n"," (0.7335000038146973, 742.8061480522156),\n"," '-------------',\n"," (0.7396000027656555, 196.56296248435973),\n"," (0.7494000196456909, 294.8444437265396),\n"," (0.7498000264167786, 393.12592496871946),\n"," (0.7364000082015991, 491.40740621089935),\n"," (0.751800000667572, 589.6888874530792),\n"," (0.7615000009536743, 687.9703686952591),\n"," (0.7590000033378601, 786.2518499374389),\n"," (0.7523999810218811, 884.5333311796188),\n"," (0.7319999933242798, 982.8148124217987),\n"," '-------------',\n"," (0.7394999861717224, 208.58331623077393),\n"," (0.745199978351593, 312.8749743461609),\n"," (0.7495999932289124, 417.16663246154786),\n"," (0.7462000250816345, 521.4582905769348),\n"," (0.7504000067710876, 625.7499486923218),\n"," (0.7523999810218811, 730.0416068077087),\n"," (0.754800021648407, 834.3332649230957),\n"," (0.7537000179290771, 938.6249230384826),\n"," (0.7556999921798706, 1042.9165811538696)]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"Tejc-61PxwIW"},"source":[""],"execution_count":null,"outputs":[]}]}